# Azure Data Factory Deep Dive

> **Interview Frequency:** â­â­â­â­ (Azure-Specific)

## The Core Question

*"How would you design a production data pipeline in ADF with proper error handling?"*

---

## ðŸ—ï¸ ADF Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Azure Data Factory                            â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     PIPELINE                              â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ Lookup  â”‚â”€â”€â–ºâ”‚  Copy   â”‚â”€â”€â–ºâ”‚ Notebookâ”‚â”€â”€â–ºâ”‚ Stored  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚Activity â”‚   â”‚ Activityâ”‚   â”‚ Activityâ”‚   â”‚  Proc   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                    â–¼                   â–¼                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚         â”‚   Azure IR        â”‚  â”‚ Self-Hosted IR    â”‚            â”‚
â”‚         â”‚ (Azure resources) â”‚  â”‚ (On-prem/VNet)    â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”Œ Integration Runtimes

### Types of IR

| Type | Use Case | Network |
|------|----------|---------|
| **Azure IR** | Azure-to-Azure, public endpoints | Public |
| **Self-Hosted IR** | On-prem, private network | Private |
| **Azure-SSIS IR** | Run SSIS packages | Either |

### When to Use Self-Hosted IR

```
Scenario: Copy from on-premises SQL Server to ADLS

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ On-Prem SQL    â”‚â—„â”€â”€â”€â”€â–ºâ”‚ Self-Hosted IR â”‚â—„â”€â”€â”€â”€â–ºâ”‚     ADLS      â”‚
â”‚ (private)      â”‚      â”‚ (your network) â”‚      â”‚ (public/pvt)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The IR machine must:
- Have network access to SQL Server
- Have outbound access to Azure
- Have enough CPU/memory for data movement
```

---

## ðŸ”„ Retry Policies

### Activity-Level Retry

```json
{
    "name": "Copy_Orders",
    "type": "Copy",
    "policy": {
        "retry": 3,                    // Retry up to 3 times
        "retryIntervalInSeconds": 30,  // Wait 30s between retries
        "secureOutput": false,
        "timeout": "01:00:00"          // 1 hour max per attempt
    }
}
```

### Error Categories

| Category | Retry? | Examples |
|----------|--------|----------|
| **Transient** | Yes | Network timeout, 429 rate limit |
| **User Error** | No | Invalid credentials, wrong path |
| **System Error** | Maybe | Service unavailable |

---

## ðŸ“Š Error Handling Patterns

### Pattern 1: Try-Catch with Failure Activities

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PIPELINE                             â”‚
â”‚                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Success  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Success  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Copy   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚Transformâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Load   â”‚   â”‚
â”‚   â”‚ Source  â”‚           â”‚  Data   â”‚           â”‚ Target  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â”‚                     â”‚                              â”‚
â”‚        â”‚ Failure             â”‚ Failure                      â”‚
â”‚        â–¼                     â–¼                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚   â”‚  Log    â”‚           â”‚  Log    â”‚                         â”‚
â”‚   â”‚ Error   â”‚           â”‚ Error   â”‚                         â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                         â”‚
â”‚        â”‚                     â”‚                              â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                   â–¼                                         â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚             â”‚  Send   â”‚                                     â”‚
â”‚             â”‚  Alert  â”‚                                     â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pattern 2: Execute Pipeline (Child Pipeline)

```json
{
    "name": "ProcessFile",
    "type": "ExecutePipeline",
    "inputs": [],
    "pipeline": {
        "referenceName": "GenericFileProcessor",
        "type": "PipelineReference"
    },
    "parameters": {
        "sourceFile": "@item().name",
        "targetPath": "/processed/"
    },
    "waitOnCompletion": true
}
```

---

## âš™ï¸ Parameterized Pipelines

### Pipeline Parameters

```json
{
    "name": "DynamicCopyPipeline",
    "parameters": {
        "sourceSystem": {
            "type": "String",
            "defaultValue": "SalesDB"
        },
        "tableName": {
            "type": "String"
        },
        "watermarkColumn": {
            "type": "String",
            "defaultValue": "LastModified"
        }
    }
}
```

### Using Parameters in Activities

```json
{
    "name": "Copy_DynamicTable",
    "type": "Copy",
    "source": {
        "type": "SqlSource",
        "sqlReaderQuery": "SELECT * FROM @{pipeline().parameters.tableName} WHERE @{pipeline().parameters.watermarkColumn} > '@{activity('Lookup_Watermark').output.firstRow.lastWatermark}'"
    },
    "sink": {
        "type": "ParquetSink",
        "storeSettings": {
            "type": "AzureBlobFSWriteSettings"
        },
        "formatSettings": {
            "type": "ParquetWriteSettings"
        }
    }
}
```

---

## ðŸ” Incremental Load Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INCREMENTAL COPY PIPELINE                       â”‚
â”‚                                                              â”‚
â”‚  1. â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚   Lookup     â”‚  â† Get last watermark from control     â”‚
â”‚     â”‚  Watermark   â”‚    table                               â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚            â”‚                                                â”‚
â”‚            â–¼                                                â”‚
â”‚  2. â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚  Copy Data   â”‚  â† WHERE ModifiedDate > @lastWatermark â”‚
â”‚     â”‚ (Incremental)â”‚                                        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚            â”‚                                                â”‚
â”‚            â–¼                                                â”‚
â”‚  3. â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚   Stored     â”‚  â† Update control table with new       â”‚
â”‚     â”‚   Procedure  â”‚    watermark = MAX(ModifiedDate)       â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Control Table

```sql
CREATE TABLE WatermarkControl (
    TableName VARCHAR(100) PRIMARY KEY,
    LastWatermark DATETIME,
    LastRunTime DATETIME,
    RowsProcessed INT
);
```

### Lookup Activity

```json
{
    "name": "Lookup_Watermark",
    "type": "Lookup",
    "source": {
        "type": "SqlSource",
        "sqlReaderQuery": "SELECT LastWatermark FROM WatermarkControl WHERE TableName = '@{pipeline().parameters.tableName}'"
    }
}
```

---

## ðŸ“§ Alerting Configuration

### Web Activity to Send Alert

```json
{
    "name": "SendAlertOnFailure",
    "type": "WebActivity",
    "method": "POST",
    "url": "https://prod-xx.westus.logic.azure.com:443/workflows/...",
    "body": {
        "pipelineName": "@{pipeline().Pipeline}",
        "runId": "@{pipeline().RunId}",
        "status": "Failed",
        "errorMessage": "@{activity('Copy_Data').error.message}",
        "triggeredTime": "@{pipeline().TriggerTime}"
    }
}
```

---

## ðŸŽ¯ Interview Answer Framework

When asked about ADF design:

> **Integration Runtime selection:**
> *"Use Azure IR for Azure-to-Azure. Use Self-Hosted IR for on-premises or private network access. Size the IR based on data volume and parallel copy operations."*

> **Error handling:**
> *"Implement retry policies at activity level (3 retries with 30s intervals). Use upon-failure paths for logging and alerting. Don't let transient errors fail the pipeline."*

> **Parameterization:**
> *"Make pipelines reusable with parameters for source/target, table names, and watermark columns. One pipeline can process multiple tables."*

> **Incremental loading:**
> *"Use control table to track watermarks. Lookup last watermark â†’ Copy new/changed records â†’ Update watermark. This pattern handles late-arriving data."*

---

## ðŸ“– Next Section

Move to [04 - OOP Design Patterns](../04-oop-design-patterns/README.md) for software engineering LLD topics.
