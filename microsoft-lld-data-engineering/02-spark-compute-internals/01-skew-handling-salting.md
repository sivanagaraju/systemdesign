# Skew Handling & Salting

> **Interview Frequency:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Top Spark Question)

## The Core Question

*"Your Spark job is running for hours while most executors are idle but one is at 100%. What's happening?"*

This is **data skew** - the #1 performance killer in distributed data processing.

---

## ü§î What Is Data Skew?

Data skew occurs when data is **unevenly distributed** across partitions, causing some tasks to process much more data than others.

```
SKEWED DISTRIBUTION (Bad)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Partition 1: ‚ñà‚ñà                          (1% of data)      ‚îÇ
‚îÇ Partition 2: ‚ñà‚ñà‚ñà                         (2% of data)      ‚îÇ
‚îÇ Partition 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (70% of data) ‚îÇ ‚Üê Straggler!
‚îÇ Partition 4: ‚ñà‚ñà‚ñà‚ñà‚ñà                       (5% of data)      ‚îÇ
‚îÇ Partition 5: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      (22% of data)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Job completes when the SLOWEST task finishes ‚Üí 70% task dominates runtime!
```

### Common Causes

| Cause | Example |
|-------|---------|
| **Popular keys** | 50% of orders from "Amazon" in retailer analysis |
| **Null values** | Millions of rows with `customer_id = NULL` |
| **Date skew** | Black Friday has 10x normal traffic |
| **Default values** | All errors have `error_code = -1` |

---

## üîç How to Detect Skew

### Method 1: Spark UI

Look at the **Summary Metrics** in the Stages tab:

```
Task Duration Summary:
  Min: 2 seconds
  25th percentile: 5 seconds
  Median: 8 seconds
  75th percentile: 15 seconds
  Max: 45 MINUTES  ‚Üê This is the straggler!
```

### Method 2: Key Distribution Analysis

```python
# Check key distribution before join/groupBy
df.groupBy("customer_id") \
  .count() \
  .orderBy(desc("count")) \
  .show(10)

# Output shows skew:
# +-------------+--------+
# |customer_id  |count   |
# +-------------+--------+
# |AMAZON       |5000000 |  ‚Üê 50x larger than others!
# |WALMART      |100000  |
# |TARGET       |95000   |
# +-------------+--------+
```

### Method 3: Partition Size Check

```python
from pyspark.sql.functions import spark_partition_id

# Check data per partition
df.withColumn("partition_id", spark_partition_id()) \
  .groupBy("partition_id") \
  .count() \
  .orderBy("partition_id") \
  .show()
```

---

## üßÇ The Salting Technique

### Concept

**Salting** adds a random suffix to skewed keys, spreading them across multiple partitions.

```
Before Salting:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Key: "AMAZON"    ‚Üí Partition 3 (via hash("AMAZON"))  ‚îÇ
‚îÇ Key: "AMAZON"    ‚Üí Partition 3                       ‚îÇ
‚îÇ Key: "AMAZON"    ‚Üí Partition 3  (all 5M rows here!)  ‚îÇ
‚îÇ Key: "WALMART"   ‚Üí Partition 7                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

After Salting:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Key: "AMAZON_0"  ‚Üí Partition 2                       ‚îÇ
‚îÇ Key: "AMAZON_1"  ‚Üí Partition 5                       ‚îÇ
‚îÇ Key: "AMAZON_2"  ‚Üí Partition 8  (distributed!)       ‚îÇ
‚îÇ Key: "AMAZON_3"  ‚Üí Partition 1                       ‚îÇ
‚îÇ Key: "WALMART"   ‚Üí Partition 7                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Implementation: Salted Join

```python
from pyspark.sql.functions import col, concat, lit, floor, rand, explode, array

# Parameters
SALT_BUCKETS = 10  # Number of salt values

# ============================================
# STEP 1: Salt the LARGE (skewed) table
# ============================================
large_df_salted = large_df.withColumn(
    "salted_key",
    concat(
        col("customer_id"),
        lit("_"),
        floor(rand() * SALT_BUCKETS).cast("string")
    )
)

# ============================================
# STEP 2: Explode the SMALL table
# ============================================
# Create array of salt values [0, 1, 2, ..., 9]
salt_values = [str(i) for i in range(SALT_BUCKETS)]

small_df_exploded = small_df.withColumn(
    "salt",
    explode(array([lit(s) for s in salt_values]))
).withColumn(
    "salted_key",
    concat(col("customer_id"), lit("_"), col("salt"))
)

# ============================================
# STEP 3: Join on salted keys
# ============================================
result = large_df_salted.join(
    small_df_exploded,
    on="salted_key",
    how="inner"
).drop("salted_key", "salt")
```

### Visualization of Salted Join

```
Large Table (5M AMAZON rows):                Small Table (reference):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ customer_id ‚îÇ amount    ‚îÇ                  ‚îÇ customer_id ‚îÇ region‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ AMAZON      ‚îÇ 100       ‚îÇ                  ‚îÇ AMAZON      ‚îÇ US    ‚îÇ
‚îÇ AMAZON      ‚îÇ 200       ‚îÇ                  ‚îÇ WALMART     ‚îÇ US    ‚îÇ
‚îÇ AMAZON      ‚îÇ 150       ‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ ...         ‚îÇ ...       ‚îÇ                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ EXPLODE with salts
           ‚îÇ                                        ‚ñº
           ‚îÇ ADD random salt              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚ñº                              ‚îÇ salted_key    ‚îÇ region  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ salted_key    ‚îÇ amount    ‚îÇ             ‚îÇ AMAZON_0      ‚îÇ US      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§             ‚îÇ AMAZON_1      ‚îÇ US      ‚îÇ
‚îÇ AMAZON_3      ‚îÇ 100       ‚îÇ             ‚îÇ AMAZON_2      ‚îÇ US      ‚îÇ
‚îÇ AMAZON_7      ‚îÇ 200       ‚îÇ             ‚îÇ ...           ‚îÇ ...     ‚îÇ
‚îÇ AMAZON_1      ‚îÇ 150       ‚îÇ             ‚îÇ AMAZON_9      ‚îÇ US      ‚îÇ
‚îÇ ...           ‚îÇ ...       ‚îÇ             ‚îÇ WALMART_0     ‚îÇ US      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ ...           ‚îÇ ...     ‚îÇ
           ‚îÇ                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                                        ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ JOIN on salted_key
                          ‚ñº
                   EVENLY DISTRIBUTED!
```

---

## üîß Salting for GroupBy/Aggregations

For aggregations, use a **two-phase approach**:

```python
from pyspark.sql.functions import sum as spark_sum

# Phase 1: Partial aggregation with salt
partial_agg = df.withColumn(
    "salt",
    floor(rand() * SALT_BUCKETS)
).groupBy("customer_id", "salt") \
 .agg(spark_sum("amount").alias("partial_sum"))

# Phase 2: Final aggregation (removes salt)
final_agg = partial_agg.groupBy("customer_id") \
    .agg(spark_sum("partial_sum").alias("total_amount"))
```

---

## ‚ö° Adaptive Query Execution (AQE)

### Spark 3.0+ Built-in Skew Handling

Spark 3.0 introduced **Adaptive Query Execution** which can automatically detect and handle skew!

```python
# Enable AQE (often on by default in Databricks)
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.skewJoin.enabled", "true")

# Configure thresholds
spark.conf.set("spark.sql.adaptive.skewJoin.skewedPartitionFactor", "5")  
spark.conf.set("spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes", "256MB")
```

### How AQE Skew Handling Works

```
Without AQE:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Task 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (skewed)   ‚îÇ 45 min
‚îÇ Task 2: ‚ñà‚ñà                                   ‚îÇ 2 min
‚îÇ Task 3: ‚ñà‚ñà‚ñà                                  ‚îÇ 3 min
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Total time: 45 minutes (waiting for Task 1)

With AQE Skew Handling:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Task 1a: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            ‚îÇ 10 min
‚îÇ Task 1b: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (auto-split!)              ‚îÇ 10 min
‚îÇ Task 1c: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           ‚îÇ 12 min
‚îÇ Task 2:  ‚ñà‚ñà                                  ‚îÇ 2 min
‚îÇ Task 3:  ‚ñà‚ñà‚ñà                                 ‚îÇ 3 min
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Total time: 12 minutes!
```

### When AQE Isn't Enough

AQE handles **join skew** well, but you might still need manual salting for:
- Aggregation skew (`groupBy` on skewed keys)
- Very extreme skew (single key is 90% of data)
- Custom business logic requirements

---

## üéØ Interview Answer Framework

### Step 1: Identify the Problem

> *"First, I'd check the Spark UI for straggler tasks. If task duration has high variance (e.g., median 5 seconds, max 45 minutes), that indicates skew."*

### Step 2: Analyze the Root Cause

> *"I'd analyze key distribution to find the hot keys:*
> ```python
> df.groupBy("key").count().orderBy(desc("count")).show(10)
> ```
> *This reveals if one key dominates the data."*

### Step 3: Choose Solution

> *"For Spark 3.0+, I'd first enable AQE skew handling. If that's insufficient, I'd use manual salting."*

### Step 4: Explain Salting

> *"Salting adds a random suffix (0-9) to hot keys, spreading them across partitions. The small table is exploded to match all salt values."*

### Step 5: Trade-offs

> *"The trade-off is:*
> - *Small table grows 10x (one row per salt)*
> - *Extra shuffle for the salt join*
> - *But execution time drops from hours to minutes*"

---

## ‚ö†Ô∏è Common Interview Traps

### Trap 1: "Just increase partitions"

**Response:** More partitions doesn't help. If one key has 5M rows and goes to one partition, adding more partitions won't split that key.

### Trap 2: "Use broadcast join"

**Response:** Broadcast works for small tables, but doesn't solve skew when joining two large tables.

### Trap 3: "Filter out the hot key"

**Response:** Sometimes valid (e.g., remove nulls), but usually the hot key contains important business data.

---

## üí° Quick Reference: Skew Solutions

| Scenario | Solution |
|----------|----------|
| Join skew, Spark 3.0+ | Enable AQE skew handling |
| Join skew, Spark 2.x | Manual salting |
| GroupBy skew | Two-phase aggregation with salt |
| Null key skew | Filter nulls first, process separately |
| Known hot keys | Broadcast just the hot keys |

---

## üìñ Next Topic

Continue to [Broadcast vs Shuffle Joins](./02-broadcast-vs-shuffle-joins.md) to understand join strategies.
