# 02 - Spark & Compute Internals

> **Core LLD Skill:** Understanding Spark execution model for performance optimization

Microsoft relies heavily on **Apache Spark** (via Azure Databricks & Synapse). They won't just ask "how to code it" - they'll ask "how it works under the hood."

---

## ğŸ“š Topics in This Section

| File | Topic | Key Concepts |
|------|-------|--------------|
| [01-skew-handling-salting.md](./01-skew-handling-salting.md) | Data Skew | Salting, AQE skew handling |
| [02-broadcast-vs-shuffle-joins.md](./02-broadcast-vs-shuffle-joins.md) | Join Strategies | Broadcast, Sort-Merge, Shuffle Hash |
| [03-catalyst-optimizer.md](./03-catalyst-optimizer.md) | Query Optimization | Logical/Physical plans, explain() |
| [04-file-formats-deep-dive.md](./04-file-formats-deep-dive.md) | Storage Formats | Parquet, Avro, ORC, Delta |
| [05-debugging-oom-errors.md](./05-debugging-oom-errors.md) | Troubleshooting | OOM analysis, memory tuning |
| [06-advanced-performance-optimization.md](./06-advanced-performance-optimization.md) | **Performance Master Guide** | SPAMS framework, all optimization techniques |

---

## ğŸ¯ Common Interview Questions

1. *"Your Spark job is failing with an OOM error. How do you debug it?"*
2. *"We have a 10TB table and a 50MB table. How does Spark join them?"*
3. *"What is data skew and how do you fix it?"*
4. *"Explain how Spark optimizes your SQL query"*

---

## ğŸ—ï¸ Spark Execution Model Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DRIVER                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚ â”‚ Logical     â”‚â”€â–ºâ”‚ Catalyst    â”‚â”€â–ºâ”‚ Physical    â”‚              â”‚
â”‚ â”‚ Plan        â”‚  â”‚ Optimizer   â”‚  â”‚ Plan        â”‚              â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                          â”‚                     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                    â”‚            DAG Scheduler           â”‚      â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                               â–¼                           â”‚
           â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
           â”‚ â”‚  Executor 1 â”‚  â”‚  Executor 2 â”‚  â”‚  Executor 3 â”‚         â”‚
           â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚
           â”‚ â”‚ â”‚ Task 1  â”‚ â”‚  â”‚ â”‚ Task 4  â”‚ â”‚  â”‚ â”‚ Task 7  â”‚ â”‚         â”‚
           â”‚ â”‚ â”‚ Task 2  â”‚ â”‚  â”‚ â”‚ Task 5  â”‚ â”‚  â”‚ â”‚ Task 8  â”‚ â”‚         â”‚
           â”‚ â”‚ â”‚ Task 3  â”‚ â”‚  â”‚ â”‚ Task 6  â”‚ â”‚  â”‚ â”‚ Task 9  â”‚ â”‚         â”‚
           â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚
           â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
           â”‚                        CLUSTER                             â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Concepts Quick Reference

### Shuffle Operations
Operations that redistribute data across the cluster:
- `groupBy()`, `reduceByKey()`
- `join()` (except broadcast)
- `distinct()`, `repartition()`

**Why it matters:** Shuffles are expensive (network I/O). Minimize them!

### Stages & Tasks
- **Job** = Triggered by action (collect, save, count)
- **Stage** = Sequence of transformations without shuffle
- **Task** = Work unit on a single partition

### Memory Areas
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Executor Memory            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚     Execution Memory (60%)       â”‚   â”‚  â† Shuffles, joins, sorts
â”‚  â”‚         (Unified Pool)           â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚     Storage Memory (40%)         â”‚   â”‚  â† Cached RDDs, broadcasts
â”‚  â”‚         (Unified Pool)           â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚     User Memory                  â”‚   â”‚  â† Your code's objects
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚     Reserved (300MB)             â”‚   â”‚  â† System overhead
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Performance Optimization Checklist

| Category | Optimization | How |
|----------|--------------|-----|
| **Joins** | Use broadcast for small tables | `.hint("broadcast")` |
| **Skew** | Salt skewed keys | Add random suffix |
| **Files** | Target 128MB-1GB files | OPTIMIZE, coalesce |
| **Partitions** | 2-3x cores for parallelism | `spark.sql.shuffle.partitions` |
| **Caching** | Cache frequently used DataFrames | `.cache()` or `.persist()` |
| **Serialization** | Use Kryo serializer | `spark.serializer` config |

---

## ğŸ“– Start Here

Begin with [Skew Handling & Salting](./01-skew-handling-salting.md) to understand the most common performance killer.
