# Table of Contents

- https://www.educative.io/courses/distributed-systems-practitioners
- https://www.educative.io/courses/distributed-systems-practitioners/introduction
- https://www.educative.io/courses/distributed-systems-practitioners/getting-started
- https://www.educative.io/courses/distributed-systems-practitioners/fallacies-of-distributed-computing
- https://www.educative.io/courses/distributed-systems-practitioners/difficulties-designing-distributed-systems
- https://www.educative.io/courses/distributed-systems-practitioners/measures-of-correctness-in-distributed-systems
- https://www.educative.io/courses/distributed-systems-practitioners/system-models
- https://www.educative.io/courses/distributed-systems-practitioners/types-of-failures
- https://www.educative.io/courses/distributed-systems-practitioners/the-tale-of-exactly-once-semantics
- https://www.educative.io/courses/distributed-systems-practitioners/failure-in-the-world-of-distributed-systems
- https://www.educative.io/courses/distributed-systems-practitioners/stateless-and-stateful-systems
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-essentials-of-distributed-systems
- https://www.educative.io/courses/distributed-systems-practitioners/partitioning
- https://www.educative.io/courses/distributed-systems-practitioners/algorithms-for-horizontal-partitioning
- https://www.educative.io/courses/distributed-systems-practitioners/replication
- https://www.educative.io/courses/distributed-systems-practitioners/primary-backup-replication-algorithm
- https://www.educative.io/courses/distributed-systems-practitioners/multi-primary-replication-algorithm
- https://www.educative.io/courses/distributed-systems-practitioners/quorums-in-distributed-systems
- https://www.educative.io/courses/distributed-systems-practitioners/let-ai-evaluate-your-understanding-of-replication-algorithms
- https://www.educative.io/courses/distributed-systems-practitioners/safety-guarantees-in-distributed-systems
- https://www.educative.io/courses/distributed-systems-practitioners/acid-transactions
- https://www.educative.io/courses/distributed-systems-practitioners/the-cap-theorem
- https://www.educative.io/courses/distributed-systems-practitioners/consistency-models
- https://www.educative.io/courses/distributed-systems-practitioners/cap-theorems-consistency-model
- https://www.educative.io/courses/distributed-systems-practitioners/isolation-levels-and-anomalies
- https://www.educative.io/courses/distributed-systems-practitioners/prevention-of-anomalies-in-isolation-levels
- https://www.educative.io/courses/distributed-systems-practitioners/consistency-and-isolation
- https://www.educative.io/courses/distributed-systems-practitioners/hierarchy-of-models
- https://www.educative.io/courses/distributed-systems-practitioners/why-all-the-formalities
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-system-concepts-and-theorems
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-to-distributed-transactions
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-transactions
- https://www.educative.io/courses/distributed-systems-practitioners/achieving-serializability
- https://www.educative.io/courses/distributed-systems-practitioners/pessimistic-concurrency-control-pcc
- https://www.educative.io/courses/distributed-systems-practitioners/optimistic-concurrency-control-occ
- https://www.educative.io/courses/distributed-systems-practitioners/achieving-snapshot-isolation
- https://www.educative.io/courses/distributed-systems-practitioners/achieving-full-serializable-snapshot-isolation
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-isolation
- https://www.educative.io/courses/distributed-systems-practitioners/hard-to-guarantee-atomicity
- https://www.educative.io/courses/distributed-systems-practitioners/2-phase-commit-2pc
- https://www.educative.io/courses/distributed-systems-practitioners/3-phase-commit-3pc
- https://www.educative.io/courses/distributed-systems-practitioners/quorum-based-commit-protocol
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-atomicity
- https://www.educative.io/courses/distributed-systems-practitioners/how-it-all-fits-together
- https://www.educative.io/courses/distributed-systems-practitioners/long-lived-transactions-and-sagas
- https://www.educative.io/courses/distributed-systems-practitioners/defining-the-consensus-problem
- https://www.educative.io/courses/distributed-systems-practitioners/flp-impossibility
- https://www.educative.io/courses/distributed-systems-practitioners/the-paxos-algorithm
- https://www.educative.io/courses/distributed-systems-practitioners/intricacies-of-paxos
- https://www.educative.io/courses/distributed-systems-practitioners/paxos-in-real-life
- https://www.educative.io/courses/distributed-systems-practitioners/replicated-state-machine-via-consensus
- https://www.educative.io/courses/distributed-systems-practitioners/distributed-transactions-via-consensus
- https://www.educative.io/courses/distributed-systems-practitioners/an-introduction-to-raft
- https://www.educative.io/courses/distributed-systems-practitioners/communication-among-raft-nodes
- https://www.educative.io/courses/distributed-systems-practitioners/rafts-implementation
- https://www.educative.io/courses/distributed-systems-practitioners/standing-on-the-shoulders-of-giants
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-consensus
- https://www.educative.io/courses/distributed-systems-practitioners/what-is-different-in-a-distributed-system
- https://www.educative.io/courses/distributed-systems-practitioners/a-practical-perspective
- https://www.educative.io/courses/distributed-systems-practitioners/a-theoretical-perspective
- https://www.educative.io/courses/distributed-systems-practitioners/logical-clocks
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-clocks
- https://www.educative.io/courses/distributed-systems-practitioners/total-and-partial-ordering
- https://www.educative.io/courses/distributed-systems-practitioners/the-concept-of-causality
- https://www.educative.io/courses/distributed-systems-practitioners/lamport-clocks
- https://www.educative.io/courses/distributed-systems-practitioners/vector-clocks
- https://www.educative.io/courses/distributed-systems-practitioners/version-vectors
- https://www.educative.io/courses/distributed-systems-practitioners/dotted-version-vectors
- https://www.educative.io/courses/distributed-systems-practitioners/distributed-snapshot-problem
- https://www.educative.io/courses/distributed-systems-practitioners/solving-the-distributed-snapshot-problem
- https://www.educative.io/courses/distributed-systems-practitioners/physical-and-logical-time-closing-thoughts
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-event-ordering
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-BnQAzgxvLLQ
- https://www.educative.io/courses/distributed-systems-practitioners/the-physical-layer
- https://www.educative.io/courses/distributed-systems-practitioners/the-link-layer-services
- https://www.educative.io/courses/distributed-systems-practitioners/the-link-layer-protocols
- https://www.educative.io/courses/distributed-systems-practitioners/the-network-layer
- https://www.educative.io/courses/distributed-systems-practitioners/the-transport-layer
- https://www.educative.io/courses/distributed-systems-practitioners/the-application-layer
- https://www.educative.io/courses/distributed-systems-practitioners/taking-a-step-back
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-networking
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-R1GWOMpN7DR
- https://www.educative.io/courses/distributed-systems-practitioners/authentication
- https://www.educative.io/courses/distributed-systems-practitioners/confidentiality
- https://www.educative.io/courses/distributed-systems-practitioners/integrity
- https://www.educative.io/courses/distributed-systems-practitioners/a-cryptography-primer
- https://www.educative.io/courses/distributed-systems-practitioners/symmetric-asymmetric-encryption-and-digital-signatures
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-security
- https://www.educative.io/courses/distributed-systems-practitioners/transport-layer-security-tls
- https://www.educative.io/courses/distributed-systems-practitioners/public-key-infrastructure-pki
- https://www.educative.io/courses/distributed-systems-practitioners/web-of-trust-pgp
- https://www.educative.io/courses/distributed-systems-practitioners/oauth-protocol
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-security-protocols
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-YQWmpxVMA9K
- https://www.educative.io/courses/distributed-systems-practitioners/hadoop-distributed-file-system-and-google-file-system
- https://www.educative.io/courses/distributed-systems-practitioners/creating-and-reading-files
- https://www.educative.io/courses/distributed-systems-practitioners/writing-and-deleting-files
- https://www.educative.io/courses/distributed-systems-practitioners/gfs-consistency-model
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-file-systems
- https://www.educative.io/courses/distributed-systems-practitioners/coordination-service
- https://www.educative.io/courses/distributed-systems-practitioners/zookeeper
- https://www.educative.io/courses/distributed-systems-practitioners/guarantees-provided-by-zookeeper
- https://www.educative.io/courses/distributed-systems-practitioners/zookeepers-zab-protocol
- https://www.educative.io/courses/distributed-systems-practitioners/examples-of-powerful-primitives-by-zookeeper-api
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-coordination-service
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-BnVjkO71Npx
- https://www.educative.io/courses/distributed-systems-practitioners/bigtable-hbase-architecture
- https://www.educative.io/courses/distributed-systems-practitioners/appends-and-read-operations-in-hbase
- https://www.educative.io/courses/distributed-systems-practitioners/guarantees-provided-by-hbase
- https://www.educative.io/courses/distributed-systems-practitioners/cassandras-data-model
- https://www.educative.io/courses/distributed-systems-practitioners/cassandras-cluster-internode-communication
- https://www.educative.io/courses/distributed-systems-practitioners/cassandras-consistency-levels
- https://www.educative.io/courses/distributed-systems-practitioners/linearizability-violations-in-cassandra
- https://www.educative.io/courses/distributed-systems-practitioners/linearizability-guarantees-by-cassandra
- https://www.educative.io/courses/distributed-systems-practitioners/cassandra-performing-queries-efficiently
- https://www.educative.io/courses/distributed-systems-practitioners/spanners-data-model
- https://www.educative.io/courses/distributed-systems-practitioners/spanners-architecture
- https://www.educative.io/courses/distributed-systems-practitioners/spanner-using-truetime
- https://www.educative.io/courses/distributed-systems-practitioners/spanner-operations
- https://www.educative.io/courses/distributed-systems-practitioners/faunadb
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-data-stores
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-to-kafka
- https://www.educative.io/courses/distributed-systems-practitioners/kafka-levers
- https://www.educative.io/courses/distributed-systems-practitioners/kafkas-messaging-guarantees
- https://www.educative.io/courses/distributed-systems-practitioners/transactions-storage-layout-and-other-guarantees
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-messaging-queue
- https://www.educative.io/courses/distributed-systems-practitioners/kubernetes
- https://www.educative.io/courses/distributed-systems-practitioners/components-of-manager-and-worker-nodes
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-N7JEvkLBVy8
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-to-corda
- https://www.educative.io/courses/distributed-systems-practitioners/cordas-data-model
- https://www.educative.io/courses/distributed-systems-practitioners/cordas-architecture
- https://www.educative.io/courses/distributed-systems-practitioners/backwards-compatibility-provided-by-corda
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-ledger
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-myoGZDZ3v8n
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-to-mapreduce
- https://www.educative.io/courses/distributed-systems-practitioners/mapreduces-manager-worker-architecture
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-to-apache-spark
- https://www.educative.io/courses/distributed-systems-practitioners/dag-of-stages-in-apache-spark
- https://www.educative.io/courses/distributed-systems-practitioners/perks-of-apache-spark
- https://www.educative.io/courses/distributed-systems-practitioners/apache-flink
- https://www.educative.io/courses/distributed-systems-practitioners/time-and-watermarks-in-flink
- https://www.educative.io/courses/distributed-systems-practitioners/failure-recovery-in-flink
- https://www.educative.io/courses/distributed-systems-practitioners/quiz-on-distributed-data-processing-systems
- https://www.educative.io/courses/distributed-systems-practitioners/introduction-N85xZn5O8gm
- https://www.educative.io/courses/distributed-systems-practitioners/creating-and-parsing-data
- https://www.educative.io/courses/distributed-systems-practitioners/transfer-of-data
- https://www.educative.io/courses/distributed-systems-practitioners/datastores-for-asynchronous-communication
- https://www.educative.io/courses/distributed-systems-practitioners/communication-models
- https://www.educative.io/courses/distributed-systems-practitioners/coordination-patterns
- https://www.educative.io/courses/distributed-systems-practitioners/data-synchronisation
- https://www.educative.io/courses/distributed-systems-practitioners/event-sourcing
- https://www.educative.io/courses/distributed-systems-practitioners/change-data-capture-cdc
- https://www.educative.io/courses/distributed-systems-practitioners/sharing-problems-and-their-solution
- https://www.educative.io/courses/distributed-systems-practitioners/benefits-and-drawbacks
- https://www.educative.io/courses/distributed-systems-practitioners/leases-in-distributed-systems
- https://www.educative.io/courses/distributed-systems-practitioners/preventing-safety-risks-in-leases
- https://www.educative.io/courses/distributed-systems-practitioners/backwards-compatibility
- https://www.educative.io/courses/distributed-systems-practitioners/maintaining-backwards-compatibility
- https://www.educative.io/courses/distributed-systems-practitioners/failure-handling-techniques
- https://www.educative.io/courses/distributed-systems-practitioners/applying-failure-handling-techniques
- https://www.educative.io/courses/distributed-systems-practitioners/retries
- https://www.educative.io/courses/distributed-systems-practitioners/containing-impact-of-failure
- https://www.educative.io/courses/distributed-systems-practitioners/backpressure
- https://www.educative.io/courses/distributed-systems-practitioners/reacting-to-backpressure
- https://www.educative.io/courses/distributed-systems-practitioners/recording-programs-execution
- https://www.educative.io/courses/distributed-systems-practitioners/recap-of-the-course
- https://www.educative.io/courses/distributed-systems-practitioners/some-more-things-to-discover

---


# Distributed Systems for Practitioners - AI-Powered Course

[Home](/)[Courses](/search?tab=courses)Distributed Systems for Practitioners

4.4

Beginner

9h 30min

Updated yesterday

# Distributed Systems for Practitioners

Delve into distributed systems, exploring core principles, key algorithms, and protocols. Gain insights into design decisions, trade-offs, and practical implementation.

[Unlock Full Access](/unlimited)[Continue Learning](/courses/distributed-systems-practitioners/introduction)

Join 2.8M developers at

[](/static/imgs/Code-Feedback.webm)[](/static/imgs/Explain-with-Ai-v2.webm)[](/static/imgs/AI-Prompts.webm)

This course includes

Personalized Learning, Powered by AI

Personalized Learning

Powered by AI

167 Lessons

17 Quizzes

Certificate of Completion

Developed by MAANG Engineers

Course

Distributed Systems for Practitioners

[Unlock Full Access](/unlimited)[Continue Learning](/courses/distributed-systems-practitioners/introduction)

Overview

Content

Reviews

This course is about establishing the basic principles of distributed systems. It explains the scope of their functionality by discussing what they can and cannot achieve. It also covers the basic algorithms and protocols of distributed systems through easy-to-follow examples and diagrams that illustrate the thinking behind some design decisions and expand on how they can be practiced. This course also discusses some of the issues that might arise when doing so, eliminates confusion around some terms (e.g., consistency), and fosters thinking about trade-offs when designing distributed systems. Moreover, it provides plenty of additional resources for those who want to invest more time in gaining a deeper understanding of the theoretical aspects of distributed systems.

This course is about establishing the basic principles of distributed systems. It explains the scope of their functionality by d...Show More

WHAT YOU'LL LEARN

Learn some of the complexities inherent in distributed systems.

Learn the key design problems in distributed systems.

Learn the key algorithms used in distributed systems.

Study the design of some real-life distributed systems.

Establish the concepts every system designer needs to know for efficient design of large-scale systems.

Learn the concepts software engineers need to know to make good use of distributed systems.

Learn some of the complexities inherent in distributed systems.

Show more

TAKEAWAY SKILLS

Distributed Systems

## Content

167 Lessons17 Quizzes

Expand All

[1.

### Before Getting Started

1 Lessons

Get familiar with the basics of distributed systems and core concepts for beginners.](/courses/distributed-systems-practitioners/introduction)

[Introduction](/courses/distributed-systems-practitioners/introduction)

2.

### Introduction to Distributed Systems

10 Lessons

Get started with the essentials of distributed systems, including benefits, challenges, and failure handling.

[Getting Started](/courses/distributed-systems-practitioners/getting-started)[Fallacies of Distributed Computing](/courses/distributed-systems-practitioners/fallacies-of-distributed-computing)[Difficulties Designing Distributed Systems](/courses/distributed-systems-practitioners/difficulties-designing-distributed-systems)[Measures of Correctness in Distributed Systems](/courses/distributed-systems-practitioners/measures-of-correctness-in-distributed-systems)[System Models](/courses/distributed-systems-practitioners/system-models)[Types of Failures](/courses/distributed-systems-practitioners/types-of-failures)[The Tale of Exactly-Once Semantics](/courses/distributed-systems-practitioners/the-tale-of-exactly-once-semantics)[Failure in the World of Distributed Systems](/courses/distributed-systems-practitioners/failure-in-the-world-of-distributed-systems)[Stateless and Stateful Systems](/courses/distributed-systems-practitioners/stateless-and-stateful-systems)[Quiz on Essentials of Distributed Systems](/courses/distributed-systems-practitioners/quiz-on-essentials-of-distributed-systems)

3.

### Basic Concepts and Theorems

18 Lessons

Examine key distributed systems concepts: partitioning, replication, algorithms, CAP theorem, consistency, and isolation.

4.

### Distributed Transactions

2 Lessons

Break down complex ideas in distributed transactions and their challenges across multiple nodes.

5.

### Achieving Isolation

6 Lessons

Map out the steps for achieving isolation in concurrent transactions using various control mechanisms.

6.

### Achieving Atomicity

5 Lessons

Focus on achieving atomicity in distributed transactions through 2PC, 3PC, and quorum protocols.

7.

### Concluding Distributed Transactions

2 Lessons

Test your understanding of distributed transactions, ACID guarantees, and the saga pattern.

8.

### Consensus

12 Lessons

Learn how to use consensus algorithms like Paxos and Raft in distributed systems.

9.

### Time

5 Lessons

Walk through time handling in distributed systems, addressing event order without global clocks.

10.

### Order

10 Lessons

Work your way through event ordering, causality, and time synchronization in distributed systems.

11.

### Networking

9 Lessons

Grasp the fundamentals of networking layers, protocols, and their roles in distributed systems.

12.

### Security

7 Lessons

Take a look at key security challenges in distributed systems, including authentication, confidentiality, and integrity.

13.

### Security Protocols

5 Lessons

Follow the process of ensuring secure communication and validating entities in distributed systems.

[14.

### From Theory to Practice

1 Lessons

Master the steps to categorizing distributed systems and applying previously learned principles.](/courses/distributed-systems-practitioners/introduction-YQWmpxVMA9K)

[Introduction](/courses/distributed-systems-practitioners/introduction-YQWmpxVMA9K)

15.

### Case Study 1: Distributed File Systems

5 Lessons

Step through the design, operations, and consistency models of distributed file systems.

16.

### Case Study 2: Distributed Coordination Service

6 Lessons

Get started with Zookeeper for distributed coordination, ensuring reliable, efficient service management.

17.

### Case Study 3: Distributed Data Stores

16 Lessons

Examine diverse distributed data stores including their architecture, performance, and consistency guarantees.

18.

### Case Study 4: Distributed Messaging System

5 Lessons

Break down the steps to optimize, configure, and ensure messaging guarantees in Kafka.

19.

### Case Study 5: Distributed Cluster Management

3 Lessons

Solve problems in distributed cluster management using Kubernetes components and resource coordination.

20.

### Case Study 6: Distributed Ledger

5 Lessons

Focus on Corda's distributed ledger, its architecture, data model, and ensuring backwards compatibility.

21.

### Case Study 7: Distributed Data Processing Systems

10 Lessons

Master distributed data processing with MapReduce, Apache Spark, and Apache Flink frameworks.

[22.

### Practices & Patterns

1 Lessons

Get familiar with fundamental practices and patterns for effective distributed systems.](/courses/distributed-systems-practitioners/introduction-N85xZn5O8gm)

[Introduction](/courses/distributed-systems-practitioners/introduction-N85xZn5O8gm)

23.

### Communication Patterns

4 Lessons

Discover the logic behind communication patterns, data transfer, and models in distributed systems.

[24.

### Coordination Patterns

1 Lessons

Break apart key coordination patterns, orchestration vs. choreography, and ensure atomic operations.](/courses/distributed-systems-practitioners/coordination-patterns)

[Coordination Patterns](/courses/distributed-systems-practitioners/coordination-patterns)

25.

### Data Synchronization

3 Lessons

Grasp the fundamentals of data synchronization, event sourcing, and Change Data Capture.

26.

### Shared-nothing Architectures

2 Lessons

Take a closer look at shared-nothing architectures, optimizing scalability, availability, and fault tolerance in distributed systems.

27.

### Distributed Locking

2 Lessons

Tackle distributed locking challenges and ensure safe operations using leases and fencing techniques.

28.

### Compatibility Patterns

2 Lessons

Master techniques for maintaining backwards compatibility in evolving distributed systems.

29.

### Dealing with Failure

6 Lessons

Solve problems in handling and minimizing failures in distributed systems effectively.

[30.

### Distributed Tracing

1 Lessons

Get started with distributed tracing, logging execution, and optimizing performance in complex systems.](/courses/distributed-systems-practitioners/recording-programs-execution)

[Recording Program's Execution](/courses/distributed-systems-practitioners/recording-programs-execution)

31.

### Concluding this Course

2 Lessons

Go hands-on with performance, scalability, security, and practical applications in distributed systems.

Show more

Certificate of Completion

Showcase your accomplishment by sharing your certificate of completion.

Course Author:

[Dimos Raptis](/profile/view/5899688388067328)

[Unlock Full Access](/unlimited)[Continue Learning](/courses/distributed-systems-practitioners/introduction)

Developed by MAANG Engineers

Every Educative lesson is designed by a team of ex-MAANG software engineers and PhD computer science educators, and developed in consultation with developers and data scientists working at Meta, Google, and more. Our mission is to get you hands-on with the necessary skills to stay ahead in a constantly changing industry. No video, no fluff. Just interactive, project-based learning with personalized feedback that adapts to your goals and experience.

Trusted by 2.8 million developers working at companies

"These are high-quality courses. Trust me. I own around 10 and the price is worth it for the content quality. EducativeInc came at the right time in my career. I'm understanding topics better than with any book or online video tutorial I've done. Truly made for developers. Thanks"

Anthony Walker

@\_webarchitect\_

"Just finished my first full #ML course: Machine learning for Software Engineers from Educative, Inc. ... Highly recommend!"

Evan Dunbar

ML Engineer

"You guys are the gold standard of crash-courses... Narrow enough that it doesn't need years of study or a full blown book to get the gist, but broad enough that an afternoon of Googling doesn't cut it."

Software Developer

Carlos Matias La Borde

"I spend my days and nights on Educative. It is indispensable. It is such a unique and reader-friendly site"

Souvik Kundu

Front-end Developer

"Your courses are simply awesome, the depth they go into and the breadth of coverage is so good that I don't have to refer to 10 different websites looking for interview topics and content."

Vinay Krishnaiah

Software Developer

Hands-on Learning Powered by AI

See how Educative uses AI to make your learning more immersive than ever before.

### Personalized Interview Prep

[Skip the LeetCode grind with a custom roadmap that adapts to your goals. Hands-on practice for Coding Interviews, System Design, and more.

Get Your Free Roadmap](/interview)

[](/static/imgs/Personalized-recommendations-v2.webm)

### Mock Interviews

[Test your skills in a simulated interview setting. Receive personalized feedback based on your performance. Available for Coding Interviews, System Design, and more.

Explore Mock Interviews](/mock-interview)

[](/static/imgs/Mock-Interviews-v2.webm)

### AI Prompt

Build prompt engineering skills. Practice implementing AI-informed solutions.

[](/static/imgs/AI-Prompts.webm)

### Code Feedback

Evaluate and debug your code with the click of a button. Get real-time feedback on test cases, including time and space complexity of your solutions.

[](/static/imgs/Code-Feedback.webm)

### Explain with AI

Select any text within any Educative course, and get an instant explanation — without ever leaving your browser.

[](/static/imgs/Explain-with-Ai-v2.webm)

### AI Code Mentor

AI Code Mentor helps you quickly identify errors in your code, learn from your mistakes, and nudge you in the right direction — just like a 1:1 tutor!

[](/static/imgs/AI-Mentor.webm)

[](/static/imgs/Personalized-recommendations-v2.webm)

Free Resources

FOR TEAMS

Interested in this course for your business or team?

Unlock this course (and 1,000+ more) for your entire org with DevPath

[Train your team](https://devpath.com/pricing?__hstc=10449898.917873385a68d94167273cd3aedc4b91.1764832752258.1764832752258.1764832752258.1&__hssc=10449898.3.1764832752258&__hsfp=2385172338)

Learn in-demand tech skills in half the time

PRODUCTS

[Mock Interview](/mock-interview)

New

[Courses](/explore)

[Cloud Labs](/cloudlabs)

[Skill Paths](/paths)

[Projects](/projects)

[Assessments](/assessments)

[Newsletter](/newsletter)

[Fenzo](/fenzo)

TRENDING TOPICS

[Learn to Code](/learn-to-code)

[Tech Interview Prep](/interview)

[Generative AI](/generative-ai)

[Data Science](/data-science)

[Machine Learning](/data-science/machine-learning)

[GitHub Students Scholarship](/github-students)

[Early Access Courses](/explore/early-access)

[Blind 75](/blind75)

[Layoffs](/tech-layoffs)

Pricing

[For Individuals](/unlimited)

[Try for Free](/trial)

[Gift a Subscription](/unlimited#buyNowAnnual-200)

[For Students](/student)

CONTRIBUTE

[Become an Author](https://educative.io/m/become-an-educative-author)

[Become an Affiliate](https://learn.educative.io/affiliate-program)

[Earn Referral Credits](/refer-a-friend)

RESOURCES

[Blog](/blog)

[Cheatsheets](/cheatsheets)

[Webinars](https://www.youtube.com/@Educativeinc)

[Answers](/answers)

[Guides](/guides)

[Compilers](/compilers)

ABOUT US

[Our Team](/team)

[Careers](/careers)

Hiring

[Frequently Asked Questions](/faq/general-faq)

[Contact Us](/contactUs)

[Press](/press)

LEGAL

[Privacy Policy](/privacy)

[Cookie Policy](/cookie-policy)

Cookie Settings

[Terms of Service](/terms)

[Business Terms of Service](/enterprise-terms)

[Data & Privacy](/privacy-center)

[Data Processing Agreement](/data-processing-agreement)

INTERVIEW PREP COURSES

[Grokking the Modern System Design Interview](/courses/grokking-the-system-design-interview)

[Grokking the Product Architecture Design Interview](/courses/grokking-the-api-design-interview)

[Grokking the Coding Interview Patterns](/courses/grokking-coding-interview)

[Machine Learning System Design](/courses/machine-learning-system-design)

[Tiktok Streamline Icon: https://streamlinehq.com](//www.tiktok.com/@educativeinc)

Copyright ©2025 Educative, Inc. All rights reserved.

![soc2](images/soc2.svg)

---


# Introduction

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction

# Introduction

Let's look at some prerequisites and what you can expect from this course.

We'll cover the following...

* [Target audience](#Target-audience)
* [What to expect](#What-to-expect)
* [What not to expect](#What-not-to-expect)

To take this course, you don’t need any prior knowledge of the concepts and algorithms for distributed systems.

## Target audience[#](#Target-audience)

This course is for:

* Software engineers with little to no experience with distributed systems
* People that don’t develop software, but want to learn about the field of distributed systems

![](images/4709193159409664.png)

## What to expect[#](#What-to-expect)

This course will help you get the underlying logic behind a concept or an algorithm.

It also provides the necessary references to the original papers, so that you can study other parts of interest in greater depth.

It offers a gradual introduction to all necessary terms, as well as explanations of the basic algorithms, with the help of diagrams and examples.

## What not to expect[#](#What-not-to-expect)

This course does not aim to provide a full analysis or proof of every single algorithm.

CompletedCompleted

Next

Getting Started

Ask

[Target audience](#Target-audience)

[What to expect](#What-to-expect)

[What not to expect](#What-not-to-expect)

---


# Getting Started

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Getting Started

# Getting Started

Learn what a distributed system is and why we need it.

We'll cover the following...

* [What is a distributed system?](#What-is-a-distributed-system)
  + [Parts of a distributed system](#Parts-of-a-distributed-system)
* [Why we need a distributed system](#Why-we-need-a-distributed-system)
  + [Performance](#Performance)
    - [Problem with a single computer](#Problem-with-a-single-computer)
    - [Solution](#Solution)
  + [Scalability](#Scalability)
    - [Problem with a single computer](#Problem-with-a-single-computer)
    - [Solution](#Solution)
  + [Availability](#Availability)
    - [Problem with a single computer](#Problem-with-a-single-computer)
    - [Solution](#Solution)

## What is a distributed system?[#](#What-is-a-distributed-system)

According to Coulouris et al., “A **distributed system** is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another.”

The components of this system can be thought of as software programs that run on physical hardware, such as computers. These components take many forms; e.g., they can be web servers, routers, web browsers, etc. To keep a generic view, we assume that each program runs on a separate machine. We refer to each of these machines as a **node**.

A distributed system

The above illustration shows that the network either consists of direct connections between the distributed system components, or more components that form the backbone of the network (e.g., if communication is done through the Internet).

> While the generic node view is helpful to understand the diagram above, sometimes real-life examples of how the nodes work may be more helpful… In these cases, we explain the role of each node in the system in detail.

### Parts of a distributed system[#](#Parts-of-a-distributed-system)

There are two categories of the central parts that help distributed systems function:

* The various parts that compose a distributed system: These are located remotely and are separated by a network
* The network that separates the various parts of a distributed system: It acts as a communication mechanism that lets them exchange messages.

> We will see the individual parts in detail later in this course.

## Why we need a distributed system[#](#Why-we-need-a-distributed-system)

There are three main benefits of distributed systems, as shown in the illustration below.

The three main benefits of a distributed system

Let’s explain each one separately.

### Performance[#](#Performance)

According to Mohan et al., “**Performance** is the degree to which a software system or component meets its objectives for timeliness.”

#### Problem with a single computer[#](#Problem-with-a-single-computer)

The physical constraints of its hardware impose certain limits on the performance of a single computer. Moreover, it is extremely expensive to improve a single computer’s performance after a certain point.

#### Solution[#](#Solution)

We can achieve the same performance with two or more low-spec computers as with a single, high-end computer. So, distributed systems allow us to achieve better performance at a lower cost.

> Note that better performance can translate to different things depending on the context, such as lower latency per request, higher throughput, etc.

### Scalability[#](#Scalability)

According to Bondi et al., “Scalability is the capability of a system, network, or process to handle a growing amount of work, or its potential to be enlarged to accommodate that growth.”

#### Problem with a single computer[#](#Problem-with-a-single-computer)

Data storage and processing are responsible for most of the value that software systems impart in the real world. As a system’s customer base grows, the system needs to handle more traffic and store larger amounts of data. However, a system that comprises a single computer can only scale up to a certain point, as explained earlier.

#### Solution[#](#Solution)

If we build a distributed system, we can split and store the data in multiple computers, and distribute the processing work.

> **Vertical scaling** refers to the approach of scaling a system by adding resources (memory, CPU, disk, etc.) to a single node. Meanwhile, **horizontal scaling** refers to the approach of scaling by adding more nodes to the system.

As a result of this, we can scale our systems to sizes that we could not imagine with a single computer system.

### Availability[#](#Availability)

In the context of software systems, **availability** is the probability of a system to work as required, when required, during a mission.

#### Problem with a single computer[#](#Problem-with-a-single-computer)

Nowadays, most online services need to operate all the time (also known as “24/7 service”), which is a huge challenge. When a service states that it has five-nine availability, it usually operates 99.999% of the time. This implies that it can be down for only 5 minutes at most per year to satisfy this guarantee.

If we consider how unreliable hardware can be, we can easily understand how big an undertaking this is. Of course, it would be infeasible to provide this kind of guarantee with a single computer.

#### Solution[#](#Solution)

**Redundancy** is one of the widely used mechanisms to achieve higher availability. It refers to storing data into multiple, redundant computers. So, when one computer fails, we can efficiently switch to another one. This way, we’ll prevent our customers from experiencing this failure.

Given that data are stored now in multiple computers, we end up with a distributed system!

> If we leverage a distributed system, we get all of the above benefits. However, as we will see later on, there is tension between them and several other properties. So, in most cases, we have to make a trade-off. To do this, we must understand the basic constraints and limitations of distributed systems. The first part of this course will help us with this.

If distributed systems help overcome the hardware limits of single computers, why might adding more nodes not always improve performance indefinitely? Write your answer in the widget below with proper reasoning.

Want to know the correct answer?

Why More Nodes Don’t Always Boost Performance?

Enter your answer here

﻿

Evaluate

Beta

727 characters left

Save

Reset

Certainly! Adding more nodes in a distributed system doesn’t always improve performance indefinitely because of the communication overhead and coordination complexity that come with managing multiple nodes. As you add more nodes, the time spent on communication and synchronization can outweigh the benefits of distributing the workload, leading to diminishing returns and eventually making the system less efficient. Keep exploring!

Did you find this helpful?

Backlesson

CompletedCompleted

Next

Introduction

Fallacies of Distributed Computing

Ask

[What is a distributed system?](#What-is-a-distributed-system)

[Parts of a distributed system](#Parts-of-a-distributed-system)

[Why we need a distributed system](#Why-we-need-a-distributed-system)

[Performance](#Performance)

[Problem with a single computer](#Problem-with-a-single-computer)

[Solution](#Solution)

[Scalability](#Scalability)

[Problem with a single computer](#Problem-with-a-single-computer)

[Solution](#Solution)

[Availability](#Availability)

[Problem with a single computer](#Problem-with-a-single-computer)

[Solution](#Solution)

---


# Fallacies of Distributed Computing

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Fallacies of Distributed Computing

# Fallacies of Distributed Computing

Let's see what false assumptions developers make while developing software for the distributed systems.

We'll cover the following...

* [The difference in developing software for distributed systems](#The-difference-in-developing-software-for-distributed-systems)
* [Fallacies](#Fallacies)
  + [The network is reliable](#The-network-is-reliable)
  + [Latency is zero](#Latency-is-zero)
  + [Bandwidth is infinite](#Bandwidth-is-infinite)
  + [The network is secure](#The-network-is-secure)
  + [Topology doesn’t change](#Topology-doesnt-change)
  + [Transport cost is zero](#Transport-cost-is-zero)
* [The global clock fallacy](#The-global-clock-fallacy)

## The difference in developing software for distributed systems[#](#The-difference-in-developing-software-for-distributed-systems)

Distributed systems are subject to many more constraints than software systems that run on a single computer. As a result, the development of software for distributed systems is also very different. However, those who are new to distributed systems make assumptions based on their experience with software development for systems that run on a single computer. Of course, this creates a lot of problems down the road in the systems they build.

To eliminate this confusion and help people build better systems, L Peter Deutsch and others at Sun Microsystems created a collection of these false assumptions. These are the [fallacies of distributed computing](https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing).

## Fallacies[#](#Fallacies)

There are eight such fallacies of distributed computing. The following illustration lists them.

False assumptions made by developers while developing software for distributed systems

As you progress through the course, you’ll gain a deeper understanding of why these statements are fallacious.

However, we’ll give you a sneak preview here by quickly going over them and explaining where they fall short.

### The network is reliable[#](#The-network-is-reliable)

The abstractions developers learn from various technologies and protocols often enforce this common fallacy. As we will see in a later chapter, networking protocols like [TCP](https://www.educative.io/collection/page/10370001/4891237377638400/5278678164963328#tcp) can make us believe that the network is reliable and never fails. However, this is just an illusion with significant repercussions. Also, we build network connections on top of hardware that will also fail at some point. Hence, we should design our systems accordingly.

### Latency is zero[#](#Latency-is-zero)

Libraries that attempt to model remote procedure calls as local calls, such as [gRPC](https://grpc.io/) or [Thrift](https://thrift.apache.org/), enforce this assumption. We should always remember that there’s a large difference (from milliseconds to nanoseconds) in latency between a call to a remote system and that to local memory access. This gets even worse when we consider calls between data centers on different continents. Thus, this is another thing to keep in mind when deciding how to geo-distribute our system.

### Bandwidth is infinite[#](#Bandwidth-is-infinite)

This fallacy is weaker nowadays. This is because the bandwidth we can achieve has significantly improved in the last few decades. For instance, we can now build high-bandwidth connections in our own data centers. However, this does not mean we can use all of it if our traffic needs to cross the Internet. This is important to consider when we make decisions about our distributed system’s topology, and when requests travel through the Internet.

### The network is secure[#](#The-network-is-secure)

This fallacy shows that the wider network used by two nodes to communicate is not necessarily under their control. Thus, we should consider it insecure.

![](images/5851657748480000.png)

![](images/image_1764832862.6198654.svg)![](images/6455170446786560.svg)

The course dedicates a portion to security, where it explains the various techniques we can use to securely utilize an insecure network.

### Topology doesn’t change[#](#Topology-doesnt-change)

Network also comprises many different parts that different organizations may manage with different hardware. Moreover, failures in some parts of this network may require us to change its topology to keep it functional. This also highlights the other two fallacies i.e **there is one administrator** and **the network is homogeneous**

### Transport cost is zero[#](#Transport-cost-is-zero)

The transportation of data between two points incurs financial costs. We should factor this in when we build a distributed system.

## The global clock fallacy[#](#The-global-clock-fallacy)

There’s one fallacy that’s not a part of the above set, but still often causes confusion amongst people new to distributed systems. . If we follow the same style as above, we can phrase this fallacy as:

“Distributed systems have a global clock, which we can use to identify when events happen.”

This assumption is quite deceiving since it’s somewhat intuitive and holds true even in non-distributed systems. For instance, an application that runs on a single computer can use the computer’s local clock to decide when events happen, and in what order. However, this is not true in a distributed system, where every node in the system has its own local clock that runs at a unique rate.

While there are ways to keep the clocks in sync, some are very expensive and don’t completely eliminate these differences. [Physical laws](https://en.wikipedia.org/wiki/Time_dilation) also bind this limitation. An example of this is the TrueTime API built by Google, which exposes the clock uncertainty explicitly as a first-class citizen.

> However, as we’ll see in the upcoming lessons that discuss cause and effects, there are other ways to reason about time using logical clocks.

Backlesson

CompletedCompleted

Next

Getting Started

Difficulties Designing Distributed Systems

Ask

[The difference in developing software for distributed systems](#The-difference-in-developing-software-for-distributed-systems)

[Fallacies](#Fallacies)

[The network is reliable](#The-network-is-reliable)

[Latency is zero](#Latency-is-zero)

[Bandwidth is infinite](#Bandwidth-is-infinite)

[The network is secure](#The-network-is-secure)

[Topology doesn’t change](#Topology-doesnt-change)

[Transport cost is zero](#Transport-cost-is-zero)

[The global clock fallacy](#The-global-clock-fallacy)

---


# Difficulties Designing Distributed Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Difficulties Designing Distributed Systems

# Difficulties Designing Distributed Systems

Let's see what makes distributed systems hard to design.

We'll cover the following...

* [Why distributed systems are hard to design](#Why-distributed-systems-are-hard-to-design)
  + [Properties that make distributed systems challenging](#Properties-that-make-distributed-systems-challenging)
    - [Network asynchrony](#Network-asynchrony)
    - [Partial failures](#Partial-failures)
    - [Concurrency](#Concurrency)

## Why distributed systems are hard to design[#](#Why-distributed-systems-are-hard-to-design)

In general, distributed systems are hard to design, build, and reason about. This increases the risk of error.

It’s worth questioning this: why are distributed systems so hard to design? The answer to this question will help us eliminate our blind spots, and provide guidance on some aspects we should pay attention to.

Give it a try yourself. Think why are distributed systems so hard to design. Write your answer in the widget provided below with proper reasoning.

Want to know the correct answer?

Why are distributed systems so hard to design?

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

### Properties that make distributed systems challenging[#](#Properties-that-make-distributed-systems-challenging)

The following illustration shows the main properties that make distributed systems challenging to reason about.

Main properties of distributed systems

Let’s look at each property.

#### Network asynchrony[#](#Network-asynchrony)

**Network asynchrony** is a property of communication networks that cannot provide strong guarantees around delivering events, e.g., a maximum amount of time a message requires for delivery. This can create a lot of counter-intuitive behaviors that are not present in non-distributed systems. This contrasts to memory operations that provide much [stricter guarantees](https://en.wikipedia.org/wiki/CAS_latency). For instance, messages might take extremely long to deliver in a distributed system. They may even deliver out of order—or not at all.

Clocks with different times

#### Partial failures[#](#Partial-failures)

**Partial failures** are the cases where only some components of a distributed system fail. This behavior can contrast with certain kinds of applications a single server deploys. These applications work under the assumption that either everything is working fine, or there has been a server crash. It introduces significant complexity when it requires atomicity across components in a distributed system. Thus, we must ensure that we either apply an operation to all the nodes of a system, or to none of them.

Failures of two nodes in a distributed system of six nodes

> The chapter about [achieving atomicity](https://www.educative.io/courses/distributed-systems-practitioners/hard-to-guarantee-atomicity) analyses this problem.

#### Concurrency[#](#Concurrency)

**Concurrency** is the execution of multiple computations at the same time, and potentially on the same piece of data. These computations interleave with each other. This introduces additional complexity since these computations can interfere with each other and create unexpected behaviors. This is, again, in contrast to simplistic applications with no concurrency, where the program runs in the order the sequence of commands in the source code defined.

Two processes writing to the same resource concurrently

> The chapter that talks about [isolation](https://www.educative.io/courses/distributed-systems-practitioners/achieving-serializability) explains the various types of problematic behaviors that arise from concurrency.

Network asynchrony, partial failures, and concurrency are the major contributors to complexity in the field of distributed systems. So, we should keep them in mind when we build distributed systems in real life. Doing so would help us anticipate edge cases and handle them appropriately.

What role does **concurrency** play in the challenges associated with designing distributed systems? Write your answer in the widget provided below with proper reasoning.

Want to know the correct answer?

What role does concurrency play?

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

CompletedCompleted

Next

Fallacies of Distributed Computing

Measures of Correctness in Distributed Systems

Ask

[Why distributed systems are hard to design](#Why-distributed-systems-are-hard-to-design)

[Properties that make distributed systems challenging](#Properties-that-make-distributed-systems-challenging)

[Network asynchrony](#Network-asynchrony)

[Partial failures](#Partial-failures)

[Concurrency](#Concurrency)

---


# Measures of Correctness in Distributed Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Measures of Correctness in Distributed Systems

# Measures of Correctness in Distributed Systems

Let's see how to measure the correctness of a distributed system.

We'll cover the following...

* [Correctness](#Correctness)
* [Measures of Correctness](#Measures-of-Correctness)
  + [Safety](#Safety)
  + [Liveness](#Liveness)
* [Example of a correct system](#Example-of-a-correct-system)

## Correctness[#](#Correctness)

We can define the correctness of a system in terms of the properties it must satisfy.

## Measures of Correctness[#](#Measures-of-Correctness)

The correctness measures for distributed systems are the two properties they must satisfy. These are the following:

* Safety property
* Liveness property

### Safety[#](#Safety)

A safety property defines something that must never happen in a correct system.

![](images/image_1764832892.445738.svg)![The oven temperature is exceeding the specified limit, this shouldn't happen](images/6419582347771904.svg "The oven temperature is exceeding the specified limit, this shouldn't happen")

The oven temperature is exceeding the specified limit, this shouldn't happen

### Liveness[#](#Liveness)

A liveness property defines something that must eventually happen in a correct system.

![](images/image_1764832892.6153848.svg)![Oven temperature eventually reaching the specified limit, it must happen](images/5539363713843200.svg "Oven temperature eventually reaching the specified limit, it must happen")

Oven temperature eventually reaching the specified limit, it must happen

## Example of a correct system[#](#Example-of-a-correct-system)

If we consider the correct properties of an oven, we can say that “the oven not exceeding a maximum temperature threshold” is a safety property. The property of “the oven eventually reaching the temperature we specified via the button” is a liveness property.

Similar to this example, it’s usually more important in distributed systems to ensure the system satisfies the safety property than the liveness one.

![](images/image_1764832892.7956595.svg)![The safety property weighs more than liveness in distributed systems](images/5367200067223552.svg "The safety property weighs more than liveness in distributed systems")

The safety property weighs more than liveness in distributed systems

> Throughout this course, it will become clear that there is an inherent tension between safety and liveness properties. Actually, as we will see later in this course, there are some problems that make it physically impossible to satisfy both kinds of properties. So, we need to compromise some liveness properties to maintain safety.

Backlesson

CompletedCompleted

Next

Difficulties Designing Distributed Systems

System Models

Ask

[Correctness](#Correctness)

[Measures of Correctness](#Measures-of-Correctness)

[Safety](#Safety)

[Liveness](#Liveness)

[Example of a correct system](#Example-of-a-correct-system)

---


# System Models

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

System Models

# System Models

Let's see the distributed system models.

We'll cover the following...

* [Nature of real-life distributed systems](#Nature-of-real-life-distributed-systems)
* [Making a generic model](#Making-a-generic-model)
  + [Properties each system follows](#Properties-each-system-follows)
* [Categories of distributed systems](#Categories-of-distributed-systems)
  + [Synchronous system](#Synchronous-system)
  + [Asynchronous system](#Asynchronous-system)

## Nature of real-life distributed systems[#](#Nature-of-real-life-distributed-systems)

Real-life distributed systems can differ drastically in many dimensions. These differences depend on factors like the network that deploys them, the hardware they run on, etc.

Thus, we need a common framework to solve problems generically. This way, we don’t need to repeat the reasoning for the different variations of these systems.

## Making a generic model[#](#Making-a-generic-model)

To create a model of a distributed system, we must define several properties it must satisfy. If we prove an algorithm is correct for this model, we can be sure that it’ll also be correct for all the systems that satisfy these properties.

### Properties each system follows[#](#Properties-each-system-follows)

The main important properties in a distributed system concern the following:

* How the nodes of a distributed system interact with each other
* How the nodes of a distributed system can fail

## Categories of distributed systems[#](#Categories-of-distributed-systems)

There are two main categories of distributed systems that depend on the nature of communication:

1. Synchronous systems
2. Asynchronous systems

### Synchronous system[#](#Synchronous-system)

A **synchronous system** is one where each node has an accurate clock, and there is a known upper bound on the message transmission delay and processing time. As a result, the execution is split into rounds. This way, every node sends a message to another node, the messages deliver, and every node computes based on the messages it receives. During this, all nodes run in lock-step.

### Asynchronous system[#](#Asynchronous-system)

An **asynchronous system** is one where there is no fixed upper bound on how long it takes for a node to deliver a message, or how much time elapses between consecutive steps of a node. The system nodes do not have a common notion of time and, thus, run at independent rates.

> The [previous lesson](https://www.educative.io/courses/distributed-systems-practitioners/measures-of-correctness-in-distributed-systems) discussed the challenges arising from network asynchrony.

So, it should be clear by now that the *synchronous* model is much easier to describe, program, and reason about. However, the *asynchronous* model is closer to real-life distributed systems, such as the Internet, where we cannot control all the components they involve. Also, there are minimal guarantees on the time it takes to send a message between two places.

> As a result, most of the algorithms we look at in this course assume an *asynchronous* system model.

How does **network asynchrony** contribute to the complexity of distributed systems? Write your answer in the widget below with proper reasoning.

Want to know the correct answer?

How does network asynchrony contribute to the complexity of distributed systems?

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

CompletedCompleted

Next

Measures of Correctness in Distributed Systems

Types of Failures

Ask

[Nature of real-life distributed systems](#Nature-of-real-life-distributed-systems)

[Making a generic model](#Making-a-generic-model)

[Properties each system follows](#Properties-each-system-follows)

[Categories of distributed systems](#Categories-of-distributed-systems)

[Synchronous system](#Synchronous-system)

[Asynchronous system](#Asynchronous-system)

---


# Types of Failures

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Types of Failures

# Types of Failures

Let's see the four basic types of failures.

We'll cover the following...

* [Fail-stop](#Fail-stop)
* [Crash](#Crash)
* [Omission](#Omission)
* [Byzantine](#Byzantine)

There are several different types of failures. The following illustration shows the most basic categories.

Four most common type of failures that occur in distributed systems

Let’s see these failures one by one.

## Fail-stop[#](#Fail-stop)

A node halts and remains halted permanently. Other nodes can detect that the node has failed (i.e., by communicating with it).

## Crash[#](#Crash)

A node halts, but silently. So, other nodes may not be able to detect this state. They can only assume its failure when they are unable to communicate with it.

## Omission[#](#Omission)

A node fails to respond to incoming requests.

## Byzantine[#](#Byzantine)

A node exhibits arbitrary behavior: it may transmit arbitrary messages at arbitrary times, take incorrect steps, or stop.

Byzantine failures occur when a node does not behave according to its specific protocol or algorithm. This usually happens when a malicious actor or a software bug compromises the node.

To cope with these failures, we need complex solutions. However, most companies deploy distributed systems in environments that they assume to be private and secure.

Fail-stop failures are the simplest and the most convenient ones from the perspective of someone that builds distributed systems. However, they are not very realistic. This is because there are many cases in real-life systems where it’s not easy for us to identify whether another node crashes or not.

> Most of the algorithms we analyze in this course work under the assumption of crash failures.

Backlesson

CompletedCompleted

Next

System Models

The Tale of Exactly-Once Semantics

Ask

[Fail-stop](#Fail-stop)

[Crash](#Crash)

[Omission](#Omission)

[Byzantine](#Byzantine)

---


# The Tale of Exactly-Once Semantics

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Tale of Exactly-Once Semantics

# The Tale of Exactly-Once Semantics

Know the story behind the exactly-once semantics.

We'll cover the following...

* [Multiple deliveries of a message](#Multiple-deliveries-of-a-message)
  + [Example consequence](#Example-consequence)
* [Avoiding multiple deliveries of a message](#Avoiding-multiple-deliveries-of-a-message)
  + [Idempotent operations approach](#Idempotent-operations-approach)
    - [Example of idempotent operation](#Example-of-idempotent-operation)
    - [Example of non-idempotent operation](#Example-of-non-idempotent-operation)
  + [De-duplication approach](#De-duplication-approach)
    - [Example](#Example)
* [Difference between delivery and processing](#Difference-between-delivery-and-processing)
* [Other delivery semantics](#Other-delivery-semantics)

## Multiple deliveries of a message[#](#Multiple-deliveries-of-a-message)

Various nodes of a distributed system communicate with each other through the exchange of messages.

As the network is not reliable, these messages might get lost. Of course, to cope with this, nodes can retry with the hope that the network will recover at some point and deliver the message.

However, this means that the nodes may deliver messages multiple times because the sender can’t know what really happens.

The following illustration shows what happens when a node doesn’t deliver a message at all.

The following illustration shows a message that a node delivers twice.

Created with Fabric.js 3.6.6

1 / 5

Created with Fabric.js 3.6.6

1 / 5

Created with Fabric.js 3.6.6

1 / 5

Created with Fabric.js 3.6.6

1 / 5

Created with Fabric.js 3.6.6

1 / 5

This duplicate delivery of a message can create disastrous side effects.

### Example consequence[#](#Example-consequence)

Think about what would happen if the message is supposed to signal the transfer of money between two bank accounts as part of a purchase. The bank may charge a customer twice for a product.

## Avoiding multiple deliveries of a message[#](#Avoiding-multiple-deliveries-of-a-message)

To handle scenarios like the one above, we can take multiple approaches to ensure that the nodes only process a message once, even though it may be delivered multiple times. Let’s see these approaches.

### Idempotent operations approach[#](#Idempotent-operations-approach)

**Idempotent** is an operation we can apply multiple times without changing the result beyond the initial application.

#### Example of idempotent operation[#](#Example-of-idempotent-operation)

An example of an idempotent operation is to add a value in a set of values. Even if we apply this operation multiple times, the operations that run after the first will have no effect, since the value will already be added to the set. Of course, we assume here that other operations cannot remove values from the set. Otherwise, the retried operation may add a value that was removed.

#### Example of non-idempotent operation[#](#Example-of-non-idempotent-operation)

An example of a non-idempotent operation is to increase a counter by one, where the operation will have additional side effects every time it’s applied.

By using idempotent operations, we can have the guarantee that even if a node delivers a message multiple times and repeats the operation, the result will be the same.

However, idempotent operations commonly impose tight constraints on the system. So, in many cases, we cannot build our system so that all operations are idempotent by nature. In these cases, we can use another approach: the de-duplication approach.

### De-duplication approach[#](#De-duplication-approach)

In the de-duplication approach, we give every message a unique identifier, and every retried message contains the same identifier as the original. In this way, the recipient can remember the set of identifiers it received and executed already. It will also avoid executing operations that are executed.

It is important to note that in order to do this, we must have control on both sides of the system: sender and receiver. This is because the ID generation occurs on the sender side, but the de-duplication process occurs on the receiver side.

#### Example[#](#Example)

Imagine a scenario where an application sends emails as part of an operation. To send an email is not an idempotent operation. If the email protocol does not support de-duplication on the receiver side, we can’t be sure that every email displays exactly once to the recipient.

## Difference between delivery and processing[#](#Difference-between-delivery-and-processing)

When we think about **exactly-once semantics**, it’s useful to distinguish between the notions of delivery and processing.

In the context of the above discussion, let’s consider **delivery** to be the arrival of the message at the destination node, at the hardware level.

Then, we consider **processing** to be the handling of this message from the software application layer of the node.

In most cases, we care more about how many times a node processes a message, than about how many times it delivers it. For instance, in our previous email example, we were mainly interested in whether the application would display the same email twice, and not whether it would receive it twice.

As the previous examples demonstrated, it’s impossible to have *exactly-once delivery* in a distributed system. However, it’s still sometimes possible to have *exactly-once processing.*

In the end, it’s important for us to understand the difference between these two notions, and clarify what we refer to when we talk about exactly-once semantics.

## Other delivery semantics[#](#Other-delivery-semantics)

As a last note, it’s easy to see that we can easily implement **at-most-once** delivery semantics and **at-least-once** delivery semantics.

We can achieve the *at-most-once* delivery when we send every message only one time, no matter what happens. Meanwhile, we can achieve the *at-least-once* delivery when we send a message continuously until we get an acknowledgment from the recipient.

If a distributed system’s network were perfectly reliable, would the concept of idempotent operations still matter? Why or why not? Write your answer in the widget below with proper reasoning.

Want to know the correct answer?

Does Idempotency Matter in a Perfectly Reliable Network?

Enter your answer here

﻿

Evaluate

Beta

750 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Types of Failures

Failure in the World of Distributed Systems

Ask

[Multiple deliveries of a message](#Multiple-deliveries-of-a-message)

[Example consequence](#Example-consequence)

[Avoiding multiple deliveries of a message](#Avoiding-multiple-deliveries-of-a-message)

[Idempotent operations approach](#Idempotent-operations-approach)

[Example of idempotent operation](#Example-of-idempotent-operation)

[Example of non-idempotent operation](#Example-of-non-idempotent-operation)

[De-duplication approach](#De-duplication-approach)

[Example](#Example)

[Difference between delivery and processing](#Difference-between-delivery-and-processing)

[Other delivery semantics](#Other-delivery-semantics)

---


# Failure in the World of Distributed Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Failure in the World of Distributed Systems

# Failure in the World of Distributed Systems

Let's see why failures occur in distributed systems, and how we can detect them.

We'll cover the following...

* [One reason for failure](#One-reason-for-failure)
* [One mechanism to detect failure](#One-mechanism-to-detect-failure)
  + [Trade-off for the small timeout value](#Trade-off-for-the-small-timeout-value)
  + [Trade-off for the large timeout value](#Trade-off-for-the-large-timeout-value)
* [Failure detector](#Failure-detector)
  + [Properties that categorize failure detectors](#Properties-that-categorize-failure-detectors)
  + [A perfect failure detector](#A-perfect-failure-detector)

We should understand that it is challenging to identify failure because of all the characteristics of a distributed system that the [Difficulties Designing Distributed Systems](https://www.educative.io/courses/distributed-systems-practitioners/difficulties-designing-distributed-systems) lesson described. One of them is the asynchronous nature of the network.

## One reason for failure[#](#One-reason-for-failure)

The asynchronous nature of the network in a distributed system can make it very hard for us to differentiate between a crashed node and a node that is just really slow to respond to requests.

## One mechanism to detect failure[#](#One-mechanism-to-detect-failure)

**Timeouts** is the main mechanism we can use to detect failures in distributed systems. Since an asynchronous network can infinitely delay messages, timeouts impose an artificial upper bound on these delays. As a result, we can assume that a node fails when it is slower than this bound. This is useful because otherwise, the assumption that the nodes are extremely slow would block the system that is waiting for the nodes that crashed.

However, a timeout does not represent an actual limit. Thus, it creates the following trade-off.

### Trade-off for the small timeout value[#](#Trade-off-for-the-small-timeout-value)

If we select a smaller value for the timeout, our system will waste less time waiting for the nodes that have crashed.

At the same time, the system might declare some nodes that have not crashed dead, while they are actually just a bit slower than expected.

The following illustration shows this trade-off phenomenon.

Created with Fabric.js 3.6.6

1 / 5

We set a small timeout value. If Node A is able to receive a response from Node B during this time duration, Node B is considered alive, otherwise dead

Created with Fabric.js 3.6.6

1 / 5

Node A asks Node B about its status by sending a "Are you alive?" message

Created with Fabric.js 3.6.6

1 / 5

Node B responds with the message, “I am alive!"

Created with Fabric.js 3.6.6

1 / 5

Node A declares Node B as a dead node because it didn’t receive a response during the timeout

Created with Fabric.js 3.6.6

1 / 5

Since Node A’s declaration/detection for Node B’s status was incorrect, we call it a false positive, assuming that the dead node refers to a positive class and the alive node refers to a negative class

### Trade-off for the large timeout value[#](#Trade-off-for-the-large-timeout-value)

If we select a larger value for the timeout, the system will be more lenient with slow nodes.

At the same time, the system will be slower in identifying crashed nodes, in some cases wasting time while waiting for them.

The following illustration shows this trade-off phenomenon.

Created with Fabric.js 3.6.6

1 / 7

We set a large timeout value. If Node A receives a response from Node B during this time duration, Node B is considered alive, otherwise dead

Created with Fabric.js 3.6.6

1 / 7

Node A asks Node B about its status by sending a "Are you alive?" message

Created with Fabric.js 3.6.6

1 / 7

Node B responds with the message, “I am alive!"

Created with Fabric.js 3.6.6

1 / 7

Node B crashed right after responding to Node A

Created with Fabric.js 3.6.6

1 / 7

Node A considers Node B alive because it received the response from Node B before the timeout and wouldn’t find that the node is crashed until the timeout duration completes

This is a fundamental problem in the field of distributed systems.

## Failure detector[#](#Failure-detector)

A failure detector is the component of a node that we can use to identify other nodes that have failed.

This component is essential for various algorithms that need to make progress in the presence of failures. There has been extensive research about failure detectors.

### Properties that categorize failure detectors[#](#Properties-that-categorize-failure-detectors)

We can distinguish the different categories of failure detectors through two basic properties that reflect the trade-off:

1. **Completeness** corresponds to the percentage of crashed nodes a failure detector successfully identifies in a certain period.
2. **Accuracy** corresponds to the number of mistakes a failure detector makes in a certain period.

### A perfect failure detector[#](#A-perfect-failure-detector)

A perfect failure detector is the one with the strongest form of *completeness* and *accuracy*. That is, it is one that successfully detects every faulty process without ever assuming a node has crashed before it actually does.

As expected, it is impossible to build a perfect failure detector in purely asynchronous systems. Still, we can even use imperfect failure detectors to solve difficult problems. One such example is the problem of consensus.

Backlesson

Mark As CompletedComplete

Next

The Tale of Exactly-Once Semantics

Stateless and Stateful Systems

Ask

[One reason for failure](#One-reason-for-failure)

[One mechanism to detect failure](#One-mechanism-to-detect-failure)

[Trade-off for the small timeout value](#Trade-off-for-the-small-timeout-value)

[Trade-off for the large timeout value](#Trade-off-for-the-large-timeout-value)

[Failure detector](#Failure-detector)

[Properties that categorize failure detectors](#Properties-that-categorize-failure-detectors)

[A perfect failure detector](#A-perfect-failure-detector)

---


# Stateless and Stateful Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Stateless and Stateful Systems

# Stateless and Stateful Systems

Let's see the difference between stateless and stateful systems.

We'll cover the following...

* [Stateless system](#Stateless-system)
  + [Examples](#Examples)
* [Stateful systems](#Stateful-systems)
  + [Example](#Example)
* [Some interesting observations](#Some-interesting-observations)
  + [Benefits of stateless systems over stateful systems](#Benefits-of-stateless-systems-over-stateful-systems)

We can say that a system belongs in one of the two following categories:

* Stateless systems
* Stateful systems

## Stateless system[#](#Stateless-system)

A stateless system maintains no state of what happened in the past and performs its capabilities purely based on the inputs we provide to it.

### Examples[#](#Examples)

A contrived stateless system receives a set of numbers as input, calculates their maximum, and returns it as a result. These inputs are either direct or indirect. *Direct inputs* are inputs that are included in the request, while *indirect inputs* are inputs that are potentially received from other systems to fulfill the request.

Imagine a service that calculates the price of a specific product by retrieving its initial price and any currently available discounts from some other services, and then performing the necessary calculations with this data. This service is still stateless.

Stateless systems

## Stateful systems[#](#Stateful-systems)

Stateful systems are responsible for maintaining and mutating a state. Their results depend on this state.

### Example[#](#Example)

Imagine a system that stores the ages of all the employees of a company, and we can ask it the maximum age. This system is stateful since the result depends on the employees we register in it.

Stateful systems

## Some interesting observations[#](#Some-interesting-observations)

* Stateful systems are beneficial in real life because computers are much more capable than humans of storing and processing data.
* Maintaining state involves additional complexity. For example, we must decide what’s the most efficient way to store and process it, how to perform back-ups, etc.
* As a result, it’s usually wise to create an architecture that contains clear boundaries between stateless components (which perform business capabilities) and stateful components (which handle data).

### Benefits of stateless systems over stateful systems[#](#Benefits-of-stateless-systems-over-stateful-systems)

Stateless distributed systems are much easier to design, build and scale, compared to stateful ones.

The main reason for this is that we consider all the nodes (e.g., servers) of a stateless system identical. This makes it a lot easier for us to balance traffic between them, and scale by adding or removing servers.

However, stateful systems present many more challenges. As different nodes can hold different pieces of data, they require additional work. They need to direct traffic to the right place and ensure each instance is in sync with the others.

> As a result, some of the course’s examples include stateless systems. However, the most challenging problems we cover in this course mainly concern stateful systems.

Backlesson

Mark As CompletedComplete

Next

Failure in the World of Distributed Systems

Quiz on Essentials of Distributed Systems

Ask

[Stateless system](#Stateless-system)

[Examples](#Examples)

[Stateful systems](#Stateful-systems)

[Example](#Example)

[Some interesting observations](#Some-interesting-observations)

[Benefits of stateless systems over stateful systems](#Benefits-of-stateless-systems-over-stateful-systems)

---


# Quiz on Essentials of Distributed Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Essentials of Distributed Systems

# Quiz on Essentials of Distributed Systems

We'll cover the following...

You are designing a distributed online store where multiple servers handle orders. Sometimes servers crash, messages are delayed, or requests are duplicated. How can you ensure the system behaves correctly despite these challenges?

Want to know the correct answer?

Quiz on distributed systems

Enter your answer here.

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Stateless and Stateful Systems

Partitioning

Ask

---


# Partitioning

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Partitioning

# Partitioning

See how we can make our system scalable by partitioning.

We'll cover the following...

* [Scalability](#Scalability)
* [Mechanism to achieve scalability](#Mechanism-to-achieve-scalability)
  + [Partitioning](#Partitioning)
    - [Vertical partitioning](#Vertical-partitioning)
    - [Horizontal partitioning](#Horizontal-partitioning)
* [Limitations of partitioning](#Limitations-of-partitioning)

One of the major benefits of distributed systems is **scalability**.

## Scalability[#](#Scalability)

Scalability lets us store and process datasets much larger than what we could with a single machine.

![](images/image_1764832987.9606802.svg)![Increasing resources](images/4697348797235200.svg "Increasing resources")

Increasing resources

## Mechanism to achieve scalability[#](#Mechanism-to-achieve-scalability)

One of the primary mechanisms of achieving scalability is **partitioning**.

### Partitioning[#](#Partitioning)

Partitioning is the process of splitting a dataset into multiple, smaller datasets, and then assigning the responsibility of storing and processing them to different nodes of a distributed system. This allows us to add more nodes to our system and increase the size of the data it can handle.

There are two different variations of partitioning:

1. Vertical partitioning
2. Horizontal partitioning (or **sharding**)

The terms “vertical” and “horizontal” originate from the era of relational databases that established the notion of a tabular view of data.

In this view, data consists of rows and columns, where each row is a different entry in the dataset, and each column is a different attribute for every entry.

The following illustration contains a visual depiction of the difference between **vertical partitioning** and **horizontal partitioning**.

Vertical partitioning vs. horizontal partitioning

#### Vertical partitioning[#](#Vertical-partitioning)

Vertical partitioning involves splitting a table into multiple tables with fewer columns and using additional tables to store columns that relate rows across tables. We commonly refer to this as a **join operation**. We can then store these different tables in different nodes.

[**Normalization**](https://en.wikipedia.org/wiki/Database_normalization) is one way to perform vertical partitioning. However, general vertical partitioning goes far beyond that: it splits a column, even when they are normalized.

A team wants to speed up queries that fetch complete student records, but they also want to scale their system. Why might choosing vertical partitioning work against their goal even though it helps with scalability? Write your answer in the widget below with proper reasoning.

Want to know the correct answer?

Why Vertical Partitioning can Slow Down Full-Record Queries?

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

#### Horizontal partitioning[#](#Horizontal-partitioning)

Horizontal partitioning involves splitting a table into multiple, smaller tables, where each table contains a percentage of the initial table’s rows. We can then store these different subtables in different nodes.

> We can perform this split through multiple strategies.

A simplistic approach for this is an alphabetical split. For instance, we can horizontally partition a table that contains the students of a school by using the students’ surnames. The following illustration shows how.

Horizontal partitioning using alphabetical split

## Limitations of partitioning[#](#Limitations-of-partitioning)

In a **vertically partitioned system**, requests that need to combine data from different tables (i.e., join operations) become less efficient. This is because these requests may now have to access data from multiple nodes.

In a **horizontally partitioned system**, we can usually avoid accessing data from multiple nodes because all the data for each row is located in the same node. However, we may still need to access data from multiple nodes for requests that are searching for a range of rows that belong to multiple nodes.

Another important implication of horizontal partitioning is the potential for loss of transactional semantics.

When we store data in a single machine, we can easily perform multiple operations in an atomic way, where either *all* or *none* of them succeed. However, this is much harder to achieve in a distributed system.

As a result, it’s much harder to perform atomic operations—when partitioning data horizontally—over data that resides in different nodes.

This is a common theme in distributed systems; there’s no silver bullet. We have to make trade-offs to achieve the property we desire.

> Vertical partitioning is mainly a data modeling practice, which can be performed by the engineers designing a system—sometimes independently of the storage systems used. However, horizontal partitioning is a common feature of distributed databases. So, to use these systems properly, engineers need to know how the system works under the hood. Therefore, we will mostly focus on horizontal partitioning.

Backlesson

Mark As CompletedComplete

Next

Quiz on Essentials of Distributed Systems

Algorithms for Horizontal Partitioning

Ask

[Scalability](#Scalability)

[Mechanism to achieve scalability](#Mechanism-to-achieve-scalability)

[Partitioning](#Partitioning)

[Vertical partitioning](#Vertical-partitioning)

[Horizontal partitioning](#Horizontal-partitioning)

[Limitations of partitioning](#Limitations-of-partitioning)

---


# Algorithms for Horizontal Partitioning

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Algorithms for Horizontal Partitioning

# Algorithms for Horizontal Partitioning

Let's look into the algorithms used for horizontal partitioning.

We'll cover the following...

* [Range partitioning](#Range-partitioning)
  + [Advantages of range partitioning](#Advantages-of-range-partitioning)
  + [Disadvantages of range partitioning](#Disadvantages-of-range-partitioning)
* [Hash partitioning](#Hash-partitioning)
  + [Advantages of hash partitioning](#Advantages-of-hash-partitioning)
  + [Disadvantages of hash partitioning](#Disadvantages-of-hash-partitioning)
* [Consistent hashing](#Consistent-hashing)
  + [Advantages of consistent hashing](#Advantages-of-consistent-hashing)
  + [Disadvantages of consistent hashing](#Disadvantages-of-consistent-hashing)

There are a lot of different algorithms we can use to perform horizontal partitioning. We will study some of these algorithms, and discuss their advantages and drawbacks.

## Range partitioning[#](#Range-partitioning)

**Range partitioning** is a technique where we split a dataset into ranges according to the value of a specific attribute. We then store each range in a separate node. The case we described [in the previous lesson](https://www.educative.io/collection/page/10370001/4891237377638400/4736079922462720#horizontal-partitioning)—with the alphabetical split—is an example of range partitioning.

Range partitioning

Of course, the system should store and maintain a list of all these ranges and map which node stores a specific range. In this way, the system consults this node map whenever the system receives a request for a specific value (or a range of values) to identify which node (or nodes, respectively) the request should be redirected to.

### Advantages of range partitioning[#](#Advantages-of-range-partitioning)

Some advantages of range partitioning include:

* Simplicity and ease of implementation.
* The ability to perform range queries using the partitioning key value.
* A good performance for range queries that use the partitioning key, when the queried range is small and resides in a single node.
* Makes adjusting ranges (repartitioning) easier and more efficient. One range can be increased or decreased, which exchanges data only between two nodes.

### Disadvantages of range partitioning[#](#Disadvantages-of-range-partitioning)

Some disadvantages of range partitioning include:

* The inability to perform range queries using keys other than the partitioning key
* A bad performance for range queries that use the partitioning key when the queried range is big and resides in multiple nodes
* An uneven distribution of the traffic or data, which causes some nodes to overload. For example, while range partitioning through an alphabetical split, we may find that some alphabetical letters appear as the initial letters in surnames more frequently than other letters. This means some nodes may have to store more data and process more requests than others.

Some systems that leverage a range partitioning technique are Google’s BigTable, and [Apache HBase](https://hbase.apache.org/).

## Hash partitioning[#](#Hash-partitioning)

**Hash partitioning** is a technique where we apply a hash function to a specific attribute of each row. This results in a number that determines which partition—and, thus, node—this row belongs to.

For the sake of simplicity, let’s assume we have one partition per node, as in the previous example, and a hash function that returns an integer. If we have `n` number of nodes in our system and try to identify which node locates a student record with a surname `s`, we’ll calculate it with the formula `hash(s) mod n`.

This mapping process will take place both when we write a new record, and when we receive a request to find a record for a specific value of this attribute.

Created with Fabric.js 3.6.6

1 / 5

There are four nodes in a distributed system

Created with Fabric.js 3.6.6

1 / 5

For each key, we calculate mod of corresponding hash value with numbers of nodes

Created with Fabric.js 3.6.6

1 / 5

By looking at the mod for each key, we assign keys to the nodes, the keys with mod value 2 are assigned to Node 2, the keys with mod value 1 are assigned to Node 1, the keys with mod value 3 are assigned to Node 3, there is no key with mod value 0, so the Node 0 is left empty

Created with Fabric.js 3.6.6

1 / 5

One of the nodes, say Node 3 fails

Created with Fabric.js 3.6.6

1 / 5

Number of nodes decreases to 3, so we recalculated the mod value with the new number of nodes, since the mod value has changed for 5 keys out of 6, so 5 keys need to be reassigned

### Advantages of hash partitioning[#](#Advantages-of-hash-partitioning)

Some advantages of hash partitioning include:

* The ability to calculate the partitioning mapping at runtime with no need to store and maintain the mapping. This is beneficial both in terms of data storage needs and performance, as we don’t need any additional requests to find the mapping
* A greater chance that the hash function will uniformly distribute the data across our system’s nodes, and prevent some nodes from overloading

### Disadvantages of hash partitioning[#](#Disadvantages-of-hash-partitioning)

Some disadvantages of hash partitioning include:

* The inability to perform range queries at all—even for the attribute we use as a partitioning key—without storing additional data or querying all the nodes
* Adding or removing nodes from the system causes it to repartition. This results in significant data movement across all nodes of the system

## Consistent hashing[#](#Consistent-hashing)

**Consistent hashing** is a partitioning technique that is very similar to hash partitioning, but solves the increased data movement problem caused by hash partitioning.

This is how it works: each node in the system is randomly assigned an integer in a range of `[0, L]`. This range is called ring (for example, `[0, 360]`). Then, the system uses a record with an attribute value `s` as a partitioning key to locating the node after the point `hash(s) mod L` in the ring.

As a result, when a new node enters the ring, it receives data only from the next node in the ring. The other nodes don’t need to exchange any more data. Similarly, when a node leaves the ring, its data transfer to the next node in the ring.

The following illustration depicts this behavior and the difference between these two different algorithms.

Created with Fabric.js 3.6.6

1 / 5

There are four nodes in the system, we randomly assign an integer to each node in a range [0, 360], called ring

Created with Fabric.js 3.6.6

1 / 5

For each key, we calculate mod of corresponding hash value with 360

Created with Fabric.js 3.6.6

1 / 5

By looking at the mod of each key, we assign each key to the node that is the next one after the mod value

Created with Fabric.js 3.6.6

1 / 5

One of the nodes, say Node 3 fails

Created with Fabric.js 3.6.6

1 / 5

The number of nodes decreases to three and only two keys need to be reassigned to the next node in the ring

### Advantages of consistent hashing[#](#Advantages-of-consistent-hashing)

Consistent hashing has one main advantage, when compared to hash partitioning:

* Reduced data movement when nodes are added or removed in the system

### Disadvantages of consistent hashing[#](#Disadvantages-of-consistent-hashing)

Some disadvantages of consistent hashing include:

* The potential for the data’s nonuniform distribution because of the random assignment of nodes in the ring
* The potential for more imbalanced data distribution as nodes are added or removed. E.g., a node’s dataset is not distributed evenly across the system when it is removed but is instead transferred to a single node

We can mitigate these issues through the concept of “virtual nodes,” where we assign each physical node multiple locations in the ring. These locations are known as **virtual nodes**.

> For further discussion on this concept, feel free to read the Dynamo paper. Another widely used system that uses consistent hashing is Apache Cassandra.

If range partitioning can easily handle range queries but risks uneven data distribution, could a hybrid approach using both range and hash partitioning help mitigate this issue? Write your answer in the widget below with proper reasoning.

Want to know the correct answer?

Can Hybrid Range-Hash Partitioning Solve Skewed Data?

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Partitioning

Replication

Ask

[Range partitioning](#Range-partitioning)

[Advantages of range partitioning](#Advantages-of-range-partitioning)

[Disadvantages of range partitioning](#Disadvantages-of-range-partitioning)

[Hash partitioning](#Hash-partitioning)

[Advantages of hash partitioning](#Advantages-of-hash-partitioning)

[Disadvantages of hash partitioning](#Disadvantages-of-hash-partitioning)

[Consistent hashing](#Consistent-hashing)

[Advantages of consistent hashing](#Advantages-of-consistent-hashing)

[Disadvantages of consistent hashing](#Disadvantages-of-consistent-hashing)

---


# Replication

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Replication

# Replication

Learn what replication is and why it is used in distributed systems.

We'll cover the following...

* [Availability](#Availability)
* [Mechanism to achieve availability](#Mechanism-to-achieve-availability)
  + [Replication](#Replication)
    - [Pessimistic replication](#Pessimistic-replication)
    - [Optimistic replication](#Optimistic-replication)

Partitioning can improve the scalability and performance of a system by distributing data and request load to multiple nodes.

Another dimension that benefits from using a distributed system is known as **availability**.

## Availability[#](#Availability)

Availability refers to the ability of the system to remain functional despite failures in parts of it.

## Mechanism to achieve availability[#](#Mechanism-to-achieve-availability)

The technique we use to achieve availability is **replication**.

### Replication[#](#Replication)

Replication is the main technique used in distributed systems to increase availability. It consists of storing the same piece of data in multiple nodes (called replicas) so that if one of them crashes, data is not lost, and requests can be served from the other nodes in the meanwhile.

Copies of the same data

However, the benefit of increased availability from replication comes with a set of new complications.

Replication implies that the system now has multiple copies of every piece of data. These copies must be maintained and kept in sync with each other on every update.

Ideally, replication should function transparently to the end user, or engineer. This is to create the illusion that there’s only one copy of every piece of data. This makes a distributed system look like a simple, centralized system of a single node that is much easier to reason about and develop software around.

Of course, this is not always possible. We may require significant hardware resources or need to give up other desirable properties to achieve this ideal. For instance, engineers sometimes willingly accept a system that provides much higher performance, but occasionally gives an inconsistent view of the data. Hence, they only do this under specific conditions—and in a specific way—they can account for when they design the application.

Therefore, there are two main strategies for replication:

1. Pessimistic replication
2. Optimistic replication

#### Pessimistic replication[#](#Pessimistic-replication)

**Pessimistic replication** tries to guarantee from the beginning that all the replicas are identical to each other—as if there was only one copy of the data all along.

#### Optimistic replication[#](#Optimistic-replication)

**Optimistic replication**, or lazy replication, allows the different replicas to diverge. This guarantees that they will converge again if the system does not receive any updates, or enters a quiesced state, for a period of time.

> Replication is a very active field in research, so there are many different algorithms for it.

What’s the main difference between replication and partitioning in distributed systems, and how do they impact system functionality?

Want to know the correct answer?

What's the main difference between replication and partitioning in distributed systems?

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Algorithms for Horizontal Partitioning

Primary-Backup Replication Algorithm

Ask

[Availability](#Availability)

[Mechanism to achieve availability](#Mechanism-to-achieve-availability)

[Replication](#Replication)

[Pessimistic replication](#Pessimistic-replication)

[Optimistic replication](#Optimistic-replication)

---


# Primary-Backup Replication Algorithm

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Primary-Backup Replication Algorithm

# Primary-Backup Replication Algorithm

Learn about primary-backup replication, and its practical application, advantages, and disadvantages.

We'll cover the following...

* [Primary-backup replication](#Primary-backup-replication)
  + [Techniques for propagating updates](#Techniques-for-propagating-updates)
    - [Synchronous replication](#Synchronous-replication)
    - [Asynchronous replication](#Asynchronous-replication)
* [Advantages of primary-backup replication](#Advantages-of-primary-backup-replication)
* [Disadvantages of primary-backup replication](#Disadvantages-of-primary-backup-replication)
* [Failover](#Failover)
  + [Managing failover](#Managing-failover)
    - [Manual approach](#Manual-approach)
    - [Automated approach](#Automated-approach)

## Primary-backup replication[#](#Primary-backup-replication)

Primary-backup replication is a technique where we designate a single node amongst the replicas as the **leader**, or primary, that receives all the updates.

> This technique is also known as **single-master replication**.

We commonly refer to the remaining replicas as **followers** or secondaries. These can only handle read requests. Every time the leader receives an update, it executes it locally and also propagates the update to the other nodes. This ensures that all the replicas maintain a consistent view of the data.

![](images/image_1764833029.5522265.svg)

Four replica nodes, where node B is designated as the leader node and the remaining three nodes are followers

### Techniques for propagating updates[#](#Techniques-for-propagating-updates)

There are two ways to propagate the updates: synchronously and asynchronously.

#### Synchronous replication[#](#Synchronous-replication)

In **synchronous replication**, the node replies to the client to indicate the update is complete—only after receiving acknowledgments from the other replicas that they’ve also performed the update on their local storage. This guarantees that the client is able to view the update in a subsequent read after acknowledging it, no matter which replica the client reads from.

Furthermore, synchronous replication provides increased **durability**. This is because the update is not lost even if the leader crashes right after it acknowledges the update.

However, this technique can make writing requests slower. This is because the leader has to wait until it receives responses from all the replicas.

Created with Fabric.js 3.6.6

1 / 7

A distributed system with a leader-follower architecture

Created with Fabric.js 3.6.6

1 / 7

Client sends a Write request to Leader node

Created with Fabric.js 3.6.6

1 / 7

Leader node performs Write request locally

Created with Fabric.js 3.6.6

1 / 7

Leader node propagates the Write request to the Follower nodes

Created with Fabric.js 3.6.6

1 / 7

Follower I performs Write request and sends acknowledgement to the Leader node

#### Asynchronous replication[#](#Asynchronous-replication)

In **asynchronous replication**, the node replies to the client as soon as it performs the update in its local storage, without waiting for responses from the other replicas.

This technique increases performance significantly for write requests. This is because the client no longer pays the penalty of the network requests to the other replicas.

However, this comes at the cost of reduced consistency and decreased **durability**. After a client receives a response for an update request, the client might read older (stale) values in a subsequent read. This is only possible if the operation happens in one of the replicas that have not yet performed the update. Moreover, if the leader node crashes right after it acknowledges an update, and the propagation requests to the other replicas are lost, any acknowledged update is eventually lost.

Created with Fabric.js 3.6.6

1 / 7

A distributed system with leader-follower architecture

Created with Fabric.js 3.6.6

1 / 7

Client sends a Write request to Leader node

Created with Fabric.js 3.6.6

1 / 7

Leader node performs Write request locally

Created with Fabric.js 3.6.6

1 / 7

Asynchronous replication: Leader node sends acknowledgement to the Client right after performing update in its local storage without waiting to send and perform updates to other replica nodes (followers)

Created with Fabric.js 3.6.6

1 / 7

Leader node propagates the Write request to the follower nodes

> Most widely used databases, such as [PostgreSQL](https://www.postgresql.org/) or [MySQL](https://www.mysql.com/), use a primary-backup replication technique that supports both asynchronous and synchronous replication.

## Advantages of primary-backup replication[#](#Advantages-of-primary-backup-replication)

* It is simple to understand and implement
* Concurrent operations serialized in the leader node remove the need for more complicated, distributed concurrency protocols. In general, this property also makes it easier to support transactional operations
* It is scalable for read-heavy workloads because the capacity for reading requests can be increased by adding more read replicas

## Disadvantages of primary-backup replication[#](#Disadvantages-of-primary-backup-replication)

* It is not very scalable for write-heavy workloads because a single node’s capacity (the leader’s capacity) determines the capacity for writes
* It imposes an obvious trade-off between performance, durability, and consistency
* Scaling the read capacity by adding more follower nodes can create a bottleneck in the network bandwidth of the leader node, if there’s a large number of followers listening for updates
* The process of failing over to a follower node when the leader node crashes is not instant. This may create some downtime and also introduce the risk of errors

## Failover[#](#Failover)

**Failover** is when the leader node crashes and a follower node takes over.

Created with Fabric.js 3.6.6

1 / 3

Node B is the leader, while Node C, D, and A are followers.

Created with Fabric.js 3.6.6

1 / 3

Leader node crashes.

Created with Fabric.js 3.6.6

1 / 3

Amongst the followers, Node C is selected randomly to play the role of leader.

When the *leader* node crashes, we need to choose another *leader* node. Following are the approaches to perform *failover*.

### Managing failover[#](#Managing-failover)

In general, there are two approaches to perform a failover: **manual** and **automated**.

#### Manual approach[#](#Manual-approach)

In the manual approach, the operator selects the new leader node and instructs all the nodes accordingly. This is the safest approach, but it incurs significant downtime.

#### Automated approach[#](#Automated-approach)

An alternative is an automated approach, where follower nodes detect that the leader node has crashed (e.g., via periodic heartbeats), and attempt to elect a new leader node. This is faster but is quite risky. This is because there are many different ways in which the nodes can get confused and arrive at an incorrect state.

> The chapter about consensus will cover this topic, called [leader election](https://www.educative.io/collection/page/10370001/4891237377638400/4827224044208128#leader-election), in more detail.

Backlesson

Mark As CompletedComplete

Next

Replication

Multi-Primary Replication Algorithm

Ask

[Primary-backup replication](#Primary-backup-replication)

[Techniques for propagating updates](#Techniques-for-propagating-updates)

[Synchronous replication](#Synchronous-replication)

[Asynchronous replication](#Asynchronous-replication)

[Advantages of primary-backup replication](#Advantages-of-primary-backup-replication)

[Disadvantages of primary-backup replication](#Disadvantages-of-primary-backup-replication)

[Failover](#Failover)

[Managing failover](#Managing-failover)

[Manual approach](#Manual-approach)

[Automated approach](#Automated-approach)

---


# Multi-Primary Replication Algorithm

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Multi-Primary Replication Algorithm

# Multi-Primary Replication Algorithm

Look at the multi-primary algorithm for replication.

We'll cover the following...

* [Multi-primary replication](#Multi-primary-replication)
  + [Conflict resolution](#Conflict-resolution)
  + [Approaches to conflict resolution](#Approaches-to-conflict-resolution)
    - [Exposing conflict resolution to the clients](#Exposing-conflict-resolution-to-the-clients)
    - [Last-write-wins conflict resolution](#Last-write-wins-conflict-resolution)
    - [Causality tracking algorithms](#Causality-tracking-algorithms)

As we saw in the previous lesson, primary-backup replication is a technique that is easy to implement and operate. It can easily support transactions and hide the distributed nature of the underlying system, i.e., when using synchronous replication.

However, primary-backup replication has some limitations in terms of performance, scalability, and availability.

As we’ve already discussed, there are many applications where availability and performance are much more important than data consistency or transactional semantics.

A frequently cited example is that of an e-commerce shopping cart, where the most important thing is for customers to be able to access their cart at all times and add items quickly and easily. It is acceptable to compromise consistency to achieve this, as long as there is data reconciliation at some point. For instance, if two replicas diverge because of intermittent failures, the customer can still resolve conflicts during the checkout process.

## Multi-primary replication[#](#Multi-primary-replication)

**Multi-primary replication** is an alternative replication technique that favors higher availability and performance over data consistency.

> This technique is also known as **multi-master replication**.

In this technique, all replicas are equal and can accept write requests. They are also responsible for propagating the data modifications to the rest of the group.

Multi-primary replication has a significant difference from primary-backup replication. In multi-primary replication, there is no single leader node that serializes the requests and imposes a single order, as write requests are concurrently handled by all the nodes. This means that nodes might disagree on what is the right order for some requests. We usually refer to this as a **conflict**.

For the system to remain operational, the nodes need to resolve this conflict when it occurs by agreeing on a single order from the available ones.

The following illustration depicts an instance where two write requests can potentially result in a conflict, depending on the latency of the propagation requests between the nodes of the system.

Created with Fabric.js 3.6.6

1 / 14

A client and three replicated nodes A, B, and C

Created with Fabric.js 3.6.6

1 / 14

Client sends a write request to Node A

Created with Fabric.js 3.6.6

1 / 14

Node A receives the write request

Created with Fabric.js 3.6.6

1 / 14

Node A writes the value of X locally

Created with Fabric.js 3.6.6

1 / 14

Node A propagates the value of X to Nodes B and C

In the case of a conflict, a subsequent read request could receive different results depending on the node that handles the request—unless we resolve the conflict so that all the nodes converge again to a single value.

### Conflict resolution[#](#Conflict-resolution)

There are many different ways to resolve conflicts, depending on the guarantees the system wants to provide.

An important aspect of different approaches to resolving conflicts is whether they do it *eagerly* or *lazily*.

* In the **eagerly** case, the conflict is resolved during the write operation.
* In the **lazily** case, the write operation proceeds to maintain multiple, alternative versions of the data record that are eventually resolved to a single version later on, i.e., during a subsequent read operation.

### Approaches to conflict resolution[#](#Approaches-to-conflict-resolution)

Here are some common approaches to conflict resolution:

#### Exposing conflict resolution to the clients[#](#Exposing-conflict-resolution-to-the-clients)

When there is a conflict, the multiple available versions return to the client. The client then selects the right version and returns it to the system. This resolves the conflict.

An example of this is the shopping cart application, where the customer selects the correct version of their cart.

#### Last-write-wins conflict resolution[#](#Last-write-wins-conflict-resolution)

Each node in the system tags each version with a timestamp, using a local clock. During a conflict, the version with the latest timestamp is selected.

However, this technique can lead to some unexpected behaviors, as there is no global notion of time. For example, write A can override write B, even though B happened “as a result” of A.

#### Causality tracking algorithms[#](#Causality-tracking-algorithms)

The system uses an algorithm that keeps track of causal relationships between different requests. When there is a conflict between two writes (A, B) and one is determined to be the cause of the other one (suppose A is the cause of B), then the resulting write (B) is retained.

However, there can still be writes that are not causally related, i.e., requests are actually concurrent. In such cases, the system cannot make an easy decision.

> We’ll elaborate more on some of these approaches later in the chapters about time and order.

Backlesson

Mark As CompletedComplete

Next

Primary-Backup Replication Algorithm

Quorums in Distributed Systems

Ask

[Multi-primary replication](#Multi-primary-replication)

[Conflict resolution](#Conflict-resolution)

[Approaches to conflict resolution](#Approaches-to-conflict-resolution)

[Exposing conflict resolution to the clients](#Exposing-conflict-resolution-to-the-clients)

[Last-write-wins conflict resolution](#Last-write-wins-conflict-resolution)

[Causality tracking algorithms](#Causality-tracking-algorithms)

---


# Quorums in Distributed Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quorums in Distributed Systems

# Quorums in Distributed Systems

Look at the concept of quorums and see how they solve low availability problems in synchronous replication.

We'll cover the following...

* [The problem in synchronous replication](#The-problem-in-synchronous-replication)
* [Possible solution](#Possible-solution)
  + [Quorums](#Quorums)

The main pattern we’ve seen so far is this: writes are performed to all the replica nodes, while reads are performed to one of them. When we ensure that writes are performed to all of them *synchronously* before replying to the client, we guarantee that the subsequent reads see all the previous writes—regardless of the node that processes the read operation.

> Note that, in the above paragraph, we have used the term “performed”. While one node receives a write request in either of the replication algorithms discussed earlier, the data is updated on all the nodes as a result of this request. Similarly, when a node receives a read request, it reads it from its local storage rather than performing a read on all the nodes. In the case of multi-primary replication, reads may be performed on all the nodes to handle write conflicts, but that is one possible solution and can’t be generalized as a pattern.

## The problem in synchronous replication[#](#The-problem-in-synchronous-replication)

Availability is quite low for write operations, because the failure of a single node makes the system unable to process writes until the node recovers.

## Possible solution[#](#Possible-solution)

To solve this problem, we can use the reverse strategy. That is, we write data only to the node that is responsible for processing a write operation, but process read operations by reading from all the nodes and returning the latest value.

This increases the availability of *writes* significantly but decreases the availability of *reads* at the same time. So, we have a trade-off that needs a mechanism to achieve a balance. Let’s see that mechanism.

### Quorums[#](#Quorums)

A useful mechanism to achieve a balance in this trade-off is to use **quorums**.

Let’s consider an example. In a system of three replicas, we can say that writes need to complete in two nodes (as a quorum of two), while reads need to retrieve data from two nodes. This way, we can be sure that the reads will read the latest value. This is because at least one of the nodes in the *read quorum* will also be included in the latest *write quorum*.

> This is based on the fact that in a set of three elements, two subsets of two elements must have at least one common element.

A past paper introduced this technique as a **quorum-based voting protocol** for replica control.

In general, in a system that has a total of VVV replicas, every read operation should obtain a read quorum of VrV\_rVr​ replicas. Meanwhile, a write operation should obtain a write quorum of VwV\_wVw​ replicas. The values of these quorums should obey the following properties:

* Vr+Vw>VV\_r +V\_w > VVr​+Vw​>V
* Vw>V/2V\_w > V/2Vw​>V/2

The first rule ensures that a data item is not read and written by two operations concurrently.

The second rule ensures that at least one node receives both of the two write operations and imposes an order on them. This means that two write operations from two different operations cannot occur concurrently on the same data item.

Both of the rules together guarantee that the associated distributed database behaves as a centralized, one-replica database system.

The concept of a quorum is really useful in distributed systems that have multiple nodes.

> The concept of a quorum is used extensively in other areas, like distributed transactions or consensus protocols.

Backlesson

Mark As CompletedComplete

Next

Multi-Primary Replication Algorithm

Let AI Evaluate Your Understanding of Replication Algorithms

Ask

[The problem in synchronous replication](#The-problem-in-synchronous-replication)

[Possible solution](#Possible-solution)

[Quorums](#Quorums)

---


# Let AI Evaluate Your Understanding of Replication Algorithms

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Let AI Evaluate Your Understanding of Replication Algorithms

# Let AI Evaluate Your Understanding of Replication Algorithms

Test your knowledge of different replication algorithms.

We'll cover the following...

* [Assessment 1](#Assessment-1)
* [Assessment 2](#Assessment-2)
* [Assessment 3](#Assessment-3)

We have now covered different replication algorithms such as primary-backup algorithm and multi-primary algorithm. Take the following AI-powered assessments to solidify and test your knowledge. Don't worry; our AI mentor will guide you along the way.

## 

### Assessment 1[#](#Assessment-1)

During a network partition, the primary node becomes temporarily unreachable. Describe the potential impact on the overall system and the actions that the read replicas might take to maintain **consistency**.

Want to know the correct answer?

Describe the potential impact on the overall system.

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

### Assessment 2[#](#Assessment-2)

If two nodes simultaneously receive **conflicting write requests**, explain how a multi-primary replication algorithm resolves the conflict and ensures data **consistency** across the distributed system.

Want to know the correct answer?

Explain how a multi-primary replication algorithm resolves the conflict.

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

### Assessment 3[#](#Assessment-3)

If the system is configured with a quorum size of **three**, and a write operation requires acknowledgment from at least **two** nodes, describe how this **ensures consistency** in the face of network partitions and potential node failures.

Want to know the correct answer?

Describe how this ensures consistency.

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Quorums in Distributed Systems

Safety Guarantees in Distributed Systems

Ask

[Assessment 1](#Assessment-1)

[Assessment 2](#Assessment-2)

[Assessment 3](#Assessment-3)

---


# Safety Guarantees in Distributed Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Safety Guarantees in Distributed Systems

# Safety Guarantees in Distributed Systems

In this lesson, we will explore the properties that guarantee safety in distributed systems, and their relation with difficulties in designing distributed systems.

We'll cover the following...

* [Safety guarantors](#Safety-guarantors)
  + [Achieving atomicity](#Achieving-atomicity)
  + [Achieving consistency](#Achieving-consistency)
  + [Achieving isolation](#Achieving-isolation)

Since distributed systems involve a lot of complexity, some safety guarantees ensure that the system will behave in specific, predictable ways. This makes it easier for people to reason about a system and any potential anomalies that can occur. This will allow them to build proper safeguards to prevent these anomalies from occurring.

## Safety guarantors[#](#Safety-guarantors)

The main safety guarantees that systems provide are around the three properties shown in the illustration.

![](images/image_1764833077.0653822.svg)

Three properties which guarantee safety in a distributed system

The concepts of **atomicity** and **isolation** originate from database research and ACID transactions. When we mention **consistency** in this course, we will mostly refer to the notion of consistency made popular by the CAP theorem.

Before going any further, it is useful to look at these topics. We will study these two topics in detail in the next two lessons.

It is interesting to observe that each of these safety guarantees is tightly related to the [aforementioned reasons](https://www.educative.io/courses/distributed-systems-practitioners/difficulties-designing-distributed-systems) that make distributed systems hard to design.

### Achieving atomicity[#](#Achieving-atomicity)

It is challenging to achieve atomicity in a distributed system because of the possibility of **partial failures**.

A partial failure occurs when some components in the system fail. The following illustration shows this.

Partial failures

### Achieving consistency[#](#Achieving-consistency)

It is challenging to achieve consistency because of the **network asynchrony**.

Network asynchrony occurs when different nodes in a network have different values for the current time. The following illustration shows this.

Network asynchrony

### Achieving isolation[#](#Achieving-isolation)

It is challenging to achieve isolation because of the inherent concurrency of distributed systems.

Concurrency occurs when multiple things happen at the same time. The following illustration shows this.

Concurrency

In the above illustration, two pens are trying to write on a single resource at the same time.

Backlesson

Mark As CompletedComplete

Next

Let AI Evaluate Your Understanding of Replication Algorithms

ACID Transactions

Ask

[Safety guarantors](#Safety-guarantors)

[Achieving atomicity](#Achieving-atomicity)

[Achieving consistency](#Achieving-consistency)

[Achieving isolation](#Achieving-isolation)

---


# ACID Transactions

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

ACID Transactions

# ACID Transactions

Let's see the ACID properties.

We'll cover the following...

* [Atomicity (A)](#Atomicity-A)
* [Consistency (C)](#Consistency-C)
* [Isolation (I)](#Isolation-I)
* [Durability (D)](#Durability-D)

**ACID** is a set of properties of traditional database transactions that provide guarantees around the expected behavior of transactions during errors, power failures, etc. More specifically, these properties are the following.

## Atomicity (A)[#](#Atomicity-A)

**Atomicity** guarantees that a transaction that comprises multiple operations is treated as a single unit. This means that either *all* operations of the transaction are executed or *none* of them are.

This concept of atomicity extends to distributed systems, where the system might need to execute the same operation in multiple nodes of the system in an atomic way. So, the operation is either executed to all the nodes or none.

## Consistency (C)[#](#Consistency-C)

**Consistency** guarantees that a transaction only transitions the database from one valid state to another valid state, while maintaining any database invariants. However, these invariants are application-specific and defined by every application accordingly.

For example, consider an application that has a table A with records that refer to records in table B through a [foreign key relationship](https://en.wikipedia.org/wiki/Foreign_key). The database prevents a transaction from deleting a record from table A, unless any records in table B referenced from this record are already deleted.

> Note that this is not the concept of consistency we refer to in the context of distributed systems.

## Isolation (I)[#](#Isolation-I)

**Isolation** guarantees that even though transactions might run concurrently and have data dependencies, the result is as if one of them was executed at a time and there was no interference between them. This prevents a large number of anomalies.

## Durability (D)[#](#Durability-D)

**Durability** guarantees that once a transaction is committed, it remains committed even in the case of failure.

In the context of single-node, centralized systems, this usually means that completed transactions and their effects are recorded in non-volatile storage.

In the context of distributed systems, this means that transactions need to be durably stored in multiple nodes. This way, recovery is possible even in the presence of total failures of a node, alongside its storage facilities.

Backlesson

Mark As CompletedComplete

Next

Safety Guarantees in Distributed Systems

The CAP Theorem

Ask

[Atomicity (A)](#Atomicity-A)

[Consistency (C)](#Consistency-C)

[Isolation (I)](#Isolation-I)

[Durability (D)](#Durability-D)

---


# The CAP Theorem

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The CAP Theorem

# The CAP Theorem

In this lesson, we explain the CAP theorem with its proof and its extended PACELC theorem.

We'll cover the following...

* [Initial statement of the CAP theorem](#Initial-statement-of-the-CAP-theorem)
  + [Consistency](#Consistency)
  + [Availability](#Availability)
  + [Partition Tolerance](#Partition-Tolerance)
* [Final statement of the CAP theorem](#Final-statement-of-the-CAP-theorem)
  + [Proof](#Proof)
* [Importance of the CAP theorem](#Importance-of-the-CAP-theorem)
* [Categorization of distributed systems based on the CAP theorem](#Categorization-of-distributed-systems-based-on-the-CAP-theorem)
* [Trade-off between latency and consistency](#Trade-off-between-latency-and-consistency)
* [PACELC theorem](#PACELC-theorem)
* [Categorization of distributed systems based on PACELC theorem](#Categorization-of-distributed-systems-based-on-PACELC-theorem)

The **CAP Theorem** is one of the most fundamental theorems in the field of distributed systems. It outlines an inherent trade-off in the design of distributed systems.

## Initial statement of the CAP theorem[#](#Initial-statement-of-the-CAP-theorem)

According to the initial statement of the CAP theorem, it is impossible for a distributed data store to provide more than two of the following properties simultaneously: **consistency**, **availability**, and **partition tolerance**.

### Consistency[#](#Consistency)

Consistency means that every successful read request receives the result of the most recent write request.

> The concept of consistency in the CAP theorem is completely different from the concept of consistency in ACID transactions. The notion of consistency as presented in the CAP theorem is more important for distributed systems.

### Availability[#](#Availability)

Availability means that every request receives a non-error response, without any guarantees on whether it reflects the most recent write request.

### Partition Tolerance[#](#Partition-Tolerance)

Partition tolerance means that the system can continue to operate despite an arbitrary number of messages being dropped by the network between nodes due to a **network partition**.

> It is very important to understand that *partition tolerance* is not a property we can abandon.

In a distributed system, there is always the risk of a network partition. If this happens, the system needs to decide either to continue operating and compromise *data consistency*, or stop operating and compromise *availability*.

However, there is no such thing as trading off *partition tolerance* to maintain both *consistency* and *availability*. As a result, what this theorem really states is the following.

## Final statement of the CAP theorem[#](#Final-statement-of-the-CAP-theorem)

According to the final statement of the CAP theorem, a distributed system can be either *consistent* or *available* in the presence of a network partition.

### Proof[#](#Proof)

Let’s attempt to prove this theorem simplistically and schematically. Let’s imagine a distributed system consisting of two nodes, as shown in the illustration.

Handling a network partition in a distributed system

This distributed system can act as a plain register with the value of a variable *X*.

Now, let’s assume that there is a network failure that results in a network partition between the two nodes of the system at some point. A user of the system performs a write, and then a read—even two different users may perform these operations.

We will examine the case where a different node of the system processes each operation. In that case, the system has two options:

* It can fail one of the operations, and break the *availability* property.
* It can process both the operations, which will return a stale value from the read and break the *consistency* property.

It cannot process both of the operations successfully, while also ensuring that the read returns the latest value that is written by the write operation. This is because the results of the write operation cannot be propagated from node A to node B due to the network partition.

## Importance of the CAP theorem[#](#Importance-of-the-CAP-theorem)

The CAP theorem is really important because it helped establish the basic limitations of all distributed systems.

The CAP theorem forces designers of distributed systems to make explicit trade-offs between *availability* and *consistency*. Once the engineers become aware of these properties, they choose the appropriate system.

## Categorization of distributed systems based on the CAP theorem[#](#Categorization-of-distributed-systems-based-on-the-CAP-theorem)

When we read the literature and documentation of distributed systems, we notice that systems are usually classified into two basic categories: **CP** and **AP**. This classification depends on which property the system violates during a network partition.

Categories of distributed systems according to the CAP theorem

> There is another important thing to note about the CAP theorem: the choice between *consistency* and *availability* needs to be made *only* during a network partition.

Both *consistency* and *availability* properties can be satisfied when the network partition is not present.

## Trade-off between latency and consistency[#](#Trade-off-between-latency-and-consistency)

When no network partition is present during normal operation, there’s a different trade-off between *latency* and *consistency*.

To guarantee *data consistency*, the system will have to delay write operations until the data has been propagated across the system successfully, thus taking a *latency* hit.

An example of this trade-off is the primary-backup replication scheme. In this setting, the *synchronous replication* approach would favor *consistency* over *latency*. Meanwhile, *asynchronous replication* would reduce *latency* at the cost of *consistency*.

Imagine a distributed system that consists of three nodes, each hosting a portion of the application’s data. The system aims to provide high availability and partition tolerance. During a network partition event, where communication between two sets of nodes is temporarily lost, how would the system respond based on **CAP** theorem principles? Explain the trade-offs and potential consequences for consistency, availability, and partition tolerance in this scenario.

Want to know the correct answer?

How would the system respond based on CAP theorem principles?

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

## PACELC theorem[#](#PACELC-theorem)

The **PACELC theorem** is an extension of the CAP theorem that is captured in a separate article. It states the following:

> “In the case of a *network partition* (P), the system has to choose between *availability* (A) and *consistency* (C) but *else* (E), when the system operates normally in the absence of network partitions, the system has to choose between *latency* (L) and *consistency* (C).”

## Categorization of distributed systems based on PACELC theorem[#](#Categorization-of-distributed-systems-based-on-PACELC-theorem)

Each branch of the PACELC theorem creates two sub-categories of systems.

The first part of the theorem defines the two categories we have already seen: CP and AP.

The second part defines two new categories: **EL** and **EC**.

These sub-categories are combined to form the following four categories:

* AP/EL
* CP/EL
* AP/EC
* CP/EC

A system from the AP/EL category prioritizes *availability* during a network partition and *latency* during a normal operation.

In most cases, systems are designed with an overarching principle in mind: usually either performance and availability, or data consistency. As a result, most of the systems fall into the AP/EL or CP/EC categories.

> There are still systems we cannot strictly classify into these categories. This is because they have various levers that can tune the system differently when needed. Still, this theorem serves as a good indicator of the various forces at play in a distributed system.

We can find a table with the categorization of several distributed systems along these dimensions in the associated Wikipedia page on the [PACELC theorem](https://en.wikipedia.org/wiki/PACELC_theorem).

Consider a distributed database system deployed in a cloud environment with multiple data centers. The system is designed to prioritize consistency and partition tolerance under normal operation. However, due to network latency between data centers, users experience delays in accessing the most up-to-date data. In response to this challenge, the team considers adopting an “eventual consistency” model.

Discuss how the **PACELC** theorem applies to this situation, outlining the potential trade-offs between consistency, availability, and partition tolerance and the implications for end users in terms of data access and system responsiveness during network partitions.

Want to know the correct answer?

Discuss how the PACELC theorem applies to this situation.

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

ACID Transactions

Consistency Models

Ask

[Initial statement of the CAP theorem](#Initial-statement-of-the-CAP-theorem)

[Consistency](#Consistency)

[Availability](#Availability)

[Partition Tolerance](#Partition-Tolerance)

[Final statement of the CAP theorem](#Final-statement-of-the-CAP-theorem)

[Proof](#Proof)

[Importance of the CAP theorem](#Importance-of-the-CAP-theorem)

[Categorization of distributed systems based on the CAP theorem](#Categorization-of-distributed-systems-based-on-the-CAP-theorem)

[Trade-off between latency and consistency](#Trade-off-between-latency-and-consistency)

[PACELC theorem](#PACELC-theorem)

[Categorization of distributed systems based on PACELC theorem](#Categorization-of-distributed-systems-based-on-PACELC-theorem)

---


# Consistency Models

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Consistency Models

# Consistency Models

In this lesson, we will learn the different forms of consistency.

We'll cover the following...

* [Consistency model](#Consistency-model)
  + [A strong consistency model](#A-strong-consistency-model)
  + [List of consistency models](#List-of-consistency-models)
    - [Linearizability](#Linearizability)
      * [Benefits](#Benefits)
    - [Sequential consistency](#Sequential-consistency)
      * [Example](#Example)
    - [Causal consistency](#Causal-consistency)
      * [Example](#Example)
    - [Eventual consistency](#Eventual-consistency)
      * [Example](#Example)

According to the [CAP Theorem](https://www.educative.io/courses/distributed-systems-practitioners/the-cap-theorem), consistency means that every successful read request will return the result of the most recent write. In fact, this is an oversimplification, because there are many different forms of consistency.

In this lesson, we introduce the forms of consistency that are most relevant to us.

To accurately define all these forms really, we need to build a formal model. This is usually the **consistency model**.

## Consistency model[#](#Consistency-model)

The consistency model defines the set of execution histories that are valid in a system.

In layperson’s terms, a model formally defines the behaviors that are possible in a distributed system.

Consistency models are extremely useful for many reasons:

* They help us formalize the behaviors of systems. Systems can then provide guarantees about their behavior.
* Software engineers can confidently use a distributed system (i.e., a distributed database) in a way that does not violate any safety properties they care about.

In essence, software engineers can treat a distributed system as an opaque box that provides a set of properties. Moreover, they can do this without knowing of all the complexity the system internally assumes to provide these properties.

### A strong consistency model[#](#A-strong-consistency-model)

We consider consistency model A stronger than model B when the first allows fewer histories. Alternatively, we say model A makes more assumptions about or poses more restrictions on the system’s possible behaviors.

Usually, the stronger the consistency model a system satisfies, the easier it is to build an application on top of it. This is because the developer can rely on stricter guarantees.

### List of consistency models[#](#List-of-consistency-models)

There are many different consistency models used across the modern system design field. We will focus on the most fundamental ones. These are the following:

* Linearizability
* Sequential Consistency
* Causal Consistency
* Eventual Consistency

#### Linearizability[#](#Linearizability)

A system that supports the consistency model of **linearizability** is one where operations appear to be instantaneous to the external client. This means that they happen at a specific point—from the point the client invokes the operation to the point the client receives the acknowledgment by the system the operation has been completed.

Furthermore, once an operation is complete and the acknowledgment is delivered to the client, it is visible to all other clients. This implies that if a client C2 invokes a read operation after a client C1 receives the completion of its write operation, C2 should see the result of this (or a subsequent) write operation. It may be obvious to some that operations are *instantaneous* and *visible* after they’re completed.

In a centralized system, linearizability is obvious. The following illustration shows this.

Created with Fabric.js 3.6.6

1 / 6

There is a client and a single node centralized system

Created with Fabric.js 3.6.6

1 / 6

Client sends a write request to the system for setting value of X equals 10

Created with Fabric.js 3.6.6

1 / 6

Systems receives the write request, and sets value of X = 10 locally

Created with Fabric.js 3.6.6

1 / 6

System sends an ack message to the client that the write request has been performed

Created with Fabric.js 3.6.6

1 / 6

Client node send a read request to the system to read value of X

However, there is no such thing as instantaneity in a distributed system.

The following illustration shows why linearizability is not obvious in a distributed system.

Created with Fabric.js 3.6.6

1 / 9

A client is using a distributed system of three nodes, A, B, and C, which are asynchronous replicas, for each node X is initialized to 0

Created with Fabric.js 3.6.6

1 / 9

Client sends a write request to Node A for updating value of X to 10

Created with Fabric.js 3.6.6

1 / 9

Node A receives the write request, and updates the value of X locally

Created with Fabric.js 3.6.6

1 / 9

Node a sends an ack message to the client that the write request has been performed

Created with Fabric.js 3.6.6

1 / 9

Node A forwards the write request to Node B, and C

When we think of a distributed system as a single node, it seems obvious that every operation happens at a specific instant of time and is immediately visible to everyone. However, when we think of a distributed system as a set of cooperating nodes, we realize that we should not take this for granted.

For instance, the system in the above illustration is not linearizable since T4 > T3. However, still, the second client won’t observe the read because it has not yet propagated to the node that processes the read operation. The **non-linearizability** comes from the use of *asynchronous replication*.

When we use a *synchronous replication* technique, we make the system linearizable. However, that means that the first write operation takes longer until the new value has propagated to the rest of the nodes. Remember the latency-consistency trade-off from the PACELC theorem.

##### Benefits[#](#Benefits)

As a result of the above discussion, we realize that linearizability is a very powerful consistency model. It helps us treat complex distributed systems as much simpler, single-node data stores and reason about our applications more efficiently. Moreover, by leveraging atomic instructions provided by hardware (such as [CAS operations](https://en.wikipedia.org/wiki/Compare-and-swap)), we can build more sophisticated logic on top of distributed systems, such as mutexes, semaphores, counters, and so on. This is not possible under weaker consistency models.

#### Sequential consistency[#](#Sequential-consistency)

**Sequential consistency** is a weaker consistency model, where operations are allowed to take effect before their invocation or after their completion.

As a result, it provides no real-time guarantees. However, operations from different clients have to be seen in the same order by all other clients, and operations of every single client preserve the order specified by its program (in this global order). This allows many more histories than linearizability but still poses some constraints that can help real-life applications.

##### Example[#](#Example)

For example, in a social networking application, we usually do not care what’s the ordering of posts between some of our friends. However, we still expect posts from a single friend to be displayed in the right order (i.e., the one they published them at). Following the same logic, we usually expect our friends’ comments in a post to appear in the order that they submitted them. These are all properties that the sequential consistency model captures.

![](images/image_1764833121.8536515.svg)![Alice performs a transaction T1 to create a post X](images/4806815697469440.svg "Alice performs a transaction T1 to create a post X")

1 / 7

Alice performs a transaction T1 to create a post X

![](images/image_1764833122.054984.svg)![Bob performs a transaction T2 to create a post Y](images/6348640186925056.svg "Bob performs a transaction T2 to create a post Y")

1 / 7

Bob performs a transaction T2 to create a post Y

![](images/image_1764833122.254236.svg)![Alice performs a transaction T3 to comment on a post X](images/4892636324691968.svg "Alice performs a transaction T3 to comment on a post X")

1 / 7

Alice performs a transaction T3 to comment on a post X

![](images/image_1764833122.4579256.svg)![Bob performs a transaction T4 to like a post Y](images/6671561245720576.svg "Bob performs a transaction T4 to like a post Y")

1 / 7

Bob performs a transaction T4 to like a post Y

![](images/image_1764833122.6288753.svg)![Alice performs a transaction T5 to delete a post X](images/5901346320809984.svg "Alice performs a transaction T5 to delete a post X")

1 / 7

Alice performs a transaction T5 to delete a post X

#### Causal consistency[#](#Causal-consistency)

In some cases, we don’t need to preserve the ordering specified by each client’s program—as long as causally related operations are displayed in the right order. This is the **causal consistency** model, which requires that only operations that are causally related need to be seen in the same order by all the nodes.

##### Example[#](#Example)

Consider the same scenario as our previous comments example. We may want to display comments out of chronological order if it means that every comment is displayed after the comment it replies to. This is expected since there is a [cause-and-effect](https://en.wikipedia.org/wiki/Causality) relationship between a comment and the comments that constitute replies to it.

Thus, unlike in sequential consistency, the operations that are not causally related can be seen in different orders in the various clients of the system without the need to maintain the order of each client’s program. Of course, to achieve that, each operation needs to contain some information that signals whether it depends on other operations or not. This does not need to be related to time and can be an application-specific property.

> Causal consistency is a weaker consistency model that prevents a common class of unintuitive behaviors.

![](images/image_1764833122.8060715.svg)![Example of causal consistency](images/5019657554755584.svg "Example of causal consistency")

Example of causal consistency

Now that you’ve seen both sequential and causal consistency, challenge yourself to a quick question.

How comments and replies would look on a news feed when using causal consistency, compared to other consistency models. Specifically, how would replies to comments appear across different users’ devices?

Provide your answer in the widget given below.

Want to know the correct answer?

Causal Ordering In Feeds

Enter your answer here

﻿

Evaluate

Beta

1000 characters left

Save

Reset

#### Eventual consistency[#](#Eventual-consistency)

There are still even simpler applications that do not have the notion of a cause-and-effect and require an even simpler consistency model. The **eventual consistency** model is beneficial here.

##### Example[#](#Example)

For instance, we could accept that the order of operations can be different between the multiple clients of the system and reads do not need to return the latest write as long as the system eventually arrives at a stable state. In this state, if no more write operations are performed, read operations will return the same result. This is the model of eventual consistency.

> It is one of the weakest forms of consistency since it does not really provide any guarantees around the perceived order of operations or the final state the system converges to.

It can still be a useful model for some applications, which do not require stronger assumptions or can detect and resolve inconsistencies at the application level.

Created with Fabric.js 3.6.6

1 / 5

Client performs a write operation on Node A to update the value of X to 15; Node A updates the value of X to 15

Created with Fabric.js 3.6.6

1 / 5

Client performs a read operation on Node B to read the value of X

Created with Fabric.js 3.6.6

1 / 5

Client receives a stale value 10 in response to the read request on X

Created with Fabric.js 3.6.6

1 / 5

Node A propagates the write request to Node B. Node B on receiving this request also updates value of X to 15

Created with Fabric.js 3.6.6

1 / 5

The replica nodes, A and B, become eventually consistent, and the read requests on any replica gets the latest write

> Note that there are many more [consistency models](https://en.wikipedia.org/wiki/Consistency_model) besides the ones we explained here.

Backlesson

Mark As CompletedComplete

Next

The CAP Theorem

CAP Theorem's Consistency Model

Ask

[Consistency model](#Consistency-model)

[A strong consistency model](#A-strong-consistency-model)

[List of consistency models](#List-of-consistency-models)

[Linearizability](#Linearizability)

[Benefits](#Benefits)

[Sequential consistency](#Sequential-consistency)

[Example](#Example)

[Causal consistency](#Causal-consistency)

[Example](#Example)

[Eventual consistency](#Eventual-consistency)

[Example](#Example)

---


# CAP Theorem's Consistency Model

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

CAP Theorem's Consistency Model

# CAP Theorem's Consistency Model

In this lesson, we will explore the consistency model that is used by the CAP theorem.

We'll cover the following...

* [Consistency model used by the CAP theorem](#Consistency-model-used-by-the-CAP-theorem)
* [Categorization of consistency models](#Categorization-of-consistency-models)
  + [Strong consistency models](#Strong-consistency-models)
  + [Weak consistency models](#Weak-consistency-models)
* [Two commonly supported consistency models](#Two-commonly-supported-consistency-models)
  + [Reasons](#Reasons)

In the [previous](https://www.educative.io/collection/page/10370001/4891237377638400/4728805791367168#list-of-consistency-models) lesson, we saw the four fundamental consistency models. When explaining the CAP theorem, we encountered the term consistency. Let’s explore that now.

## Consistency model used by the CAP theorem[#](#Consistency-model-used-by-the-CAP-theorem)

The “C” property in the CAP theorem refers to the linearizability model we previously described. This means it’s impossible to build a system that will be *available* during a network partition while also being *linearizable*.

In fact, there is research that shows that even some weaker forms of consistency, such as sequential consistency, cannot be supported in tandem with availability under a network partition.

This vast number of different consistency models creates a significant amount of complexity.

As we explained previously, modeling consistency is supposed to help us reason about these systems. However, the explosion of consistency models can have the opposite effect.

## Categorization of consistency models[#](#Categorization-of-consistency-models)

The CAP theorem can conceptually draw a line between all these consistency models and separate them into two major categories:

* Strong consistency models
* Weak consistency models

### Strong consistency models[#](#Strong-consistency-models)

Strong consistency models correspond to the “C” in the CAP theorem and cannot be supported in systems that need to be *available* during *network partitions*.

### Weak consistency models[#](#Weak-consistency-models)

Weak consistency models are the ones that can be supported while also preserving *availability* during a network partition.

## Two commonly supported consistency models[#](#Two-commonly-supported-consistency-models)

Considering the guarantees provided by several popular distributed systems nowadays (i.e., Apache Cassandra, DynamoDB, etc.), two models are commonly supported.

* Strong consistency, specifically *linearizability*
* Weak consistency, specifically *eventual consistency*

### Reasons[#](#Reasons)

Most probably, the reasons most of the systems converged to the above two models are the following:

* **Linearizability** was selected amongst the available strong consistency models because a system needs to give up availability as part of the CAP theorem to support a strong consistency model. It then seems reasonable to provide the strongest model amongst the available ones, facilitating the software engineers’ work with it.
* **Eventual Consistency** was selected amongst the available weak consistency models thanks to its simplicity and performance. Along the same lines, given the application relinquishes the strict guarantees of strong consistency for increased performance, it might as well accept the weakest guarantees possible to get the biggest performance boost it can. This makes it much easier for people to design and build applications on top of distributed systems, and to decide which side of the CAP theorem they prefer to build their application on.

Backlesson

Mark As CompletedComplete

Next

Consistency Models

Isolation Levels and Anomalies

Ask

[Consistency model used by the CAP theorem](#Consistency-model-used-by-the-CAP-theorem)

[Categorization of consistency models](#Categorization-of-consistency-models)

[Strong consistency models](#Strong-consistency-models)

[Weak consistency models](#Weak-consistency-models)

[Two commonly supported consistency models](#Two-commonly-supported-consistency-models)

[Reasons](#Reasons)

---


# Isolation Levels and Anomalies

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Isolation Levels and Anomalies

# Isolation Levels and Anomalies

Let's see a list of Isolation levels and a detailed explanation of anomalies that may occur in distributed systems due to inherent concurrency.

We'll cover the following...

* [Anomalies](#Anomalies)
  + [Dirty write](#Dirty-write)
  + [Dirty read](#Dirty-read)
  + [Fuzzy or non-repeatable read](#Fuzzy-or-non-repeatable-read)
  + [Phantom read](#Phantom-read)
  + [Lost update](#Lost-update)
  + [Read skew](#Read-skew)
  + [Write skew](#Write-skew)

The inherent **concurrency** in distributed systems creates the potential for **anomalies** and unexpected behaviors. Specifically, transactions that comprise multiple operations and run concurrently can lead to different results depending on how their operations are interleaved.

![](images/4908275228344320.png)

As a result, there is still a need for some formal models that define what is possible and what is not in a system’s behavior. These are called **isolation levels**.

We will study the most common ones here, which are the following:

* **Serializability:**
  It essentially states that two transactions, when executed concurrently, should give the same result as though executed sequentially.
* **Repeatable read:**
  It ensures that the data once read by a transaction will not change throughout its course.
* **Snapshot isolation:**
  It guarantees that all reads made in a transaction will see a consistent snapshot of the database from the point it started, and the transaction will successfully commit if no other transaction has updated the same data since that snapshot.
* **Read committed:**
  It does not allow transactions to read data that has not yet been committed by another transaction.
* **Read uncommitted:**
  It is the lowest isolation level and allows the transaction to read uncommitted data by other transactions.

Unlike the consistency models presented in the [Consistency Models lesson](https://www.educative.io/courses/distributed-systems-practitioners/consistency-models), some of these isolation levels do not define what is possible via some formal specification. Instead, they define what is not possible, i.e., which anomalies of the already known ones are prevented.

Of course, stronger isolation levels prevent more anomalies at the cost of performance. Let’s first have a look at the possible anomalies before examining the various levels.

The origin of the isolation levels above and the associated anomalies was essentially the ANSI SQL-92 standard. However, the definitions in this standard were ambiguous and missed some possible anomalies.

> Subsequent research examines more anomalies extensively and attempts a stricter definition of these levels. The basic parts will be covered in this lesson, but please refer to this paper for a deeper analysis.

## Anomalies[#](#Anomalies)

The anomalies covered here are the following:

* Dirty writes
* Dirty reads
* (Fuzzy) non-repeatable reads
* Phantom reads
* Lost updates
* Read skew
* Write skew

### Dirty write[#](#Dirty-write)

A **dirty write** occurs when a transaction overwrites a value that was previously written by another transaction that is still in-flight and has not been committed yet.

One reason dirty writes are problematic is they can violate **integrity constraints**. For example, there are two transactions A and B, where transaction A runs the operations [x=1, y=1] and transaction B runs the operations [x=2, y=2]. Then, the serial execution of them would always result in a situation where x and y have the same value. However, this is not necessarily true in a concurrent execution where dirty writes are possible.

**Example**

An example could be the following execution [x=1, x=2, y=2, commit B, y=1, commit A] that would result in x=2 and y=1.

Another problem with dirty writes is they make it impossible for the system to automatically rollback to a previous image of the database. As a result, this is an anomaly we need to prevent in most cases.

![](images/image_1764833156.5413451.svg)![Example of a dirty write](images/6590300108750848.svg "Example of a dirty write")

Example of a dirty write

### Dirty read[#](#Dirty-read)

A **dirty read** occurs when a transaction reads a value that has been written by another transaction that has not yet been committed.

This is problematic since the system might make decisions depending on these values, even though the associated transactions might be rolled back subsequently. Even in the case where these transactions eventually commit, though, this can still be a problem.

**Example**

An example is the classic scenario of a bank transfer, where the total amount of money should be observed to be the same at all times. For example, imagine transaction A is able to read the balance of two accounts involved in a transfer during another transaction (B) that performs the transfer from account 1 to account 2. During the transfer, it will look as if some money has been lost from account 1.

However, there are a few cases where allowing dirty reads can be useful if done with care. One such case is to generate a big aggregate report on a full table when we can tolerate some inaccuracies on the numbers of the report.

It can also be useful when we troubleshoot an issue and want to inspect the state of the database in the middle of an ongoing transaction.

![](images/image_1764833156.7287564.svg)![Example of a dirty read](images/6370074729512960.svg "Example of a dirty read")

Example of a dirty read

### Fuzzy or non-repeatable read[#](#Fuzzy-or-non-repeatable-read)

A **fuzzy or non-repeatable read** occurs when a value is retrieved twice during a transaction (without it being updated in the same transaction), and the value is different.

This can lead to problematic situations similar to the example presented above for dirty reads.

Other cases where this can lead to problems are when the first read of the value is used for some conditional logic, and the second is used to update data. In this case, the transaction might act on stale data.

![](images/image_1764833156.915922.svg)![Example of a fuzzy or non-repeatable read](images/4737521488625664.svg "Example of a fuzzy or non-repeatable read")

Example of a fuzzy or non-repeatable read

### Phantom read[#](#Phantom-read)

A **phantom read** occurs when a transaction does a predicate-based read, and another transaction writes or removes a data item matched by that predicate while the first transaction is still in flight. If that happens, then the first transaction might be acting again on stale data or inconsistent data.

**Example**

For example, transaction A runs 2 queries to calculate the maximum and the average age of a specific set of employees. However, between the two queries, transaction B is interleaved and inserts a lot of old employees in this set, thus making transaction A return an average that is larger than the maximum.

Allowing phantom reads can be safe for an application that does not make use of predicate-based reads, i.e., performs only the reads that select records using a primary key.

![](images/image_1764833157.1273344.svg)![Example of a phantom read](images/6362574877753344.svg "Example of a phantom read")

Example of a phantom read

### Lost update[#](#Lost-update)

A **lost update** occurs when two transactions read the same value and then try to update it to two different values. The end result is that one of the two updates survives, but the process executing the other update is not informed that its update did not take effect. Thus it is called a lost update.

**Example**

Imagine a warehouse with various controllers that update the database when new items arrive. The transactions are rather simple. They involve reading the number of items currently in the warehouse, adding the number of new items to this number, and then storing the result back in the database.

This anomaly could lead to the following problem:

* Transactions A and B read the current inventory size simultaneously (say, 100 items), add the number of new items to this (say, 5 and 10 respectively), and then store this back to the database. Let’s assume that transaction B was the last one to write. This means that the final inventory is 110 instead of 115. Thus, five new items are *not* recorded!

See the following illustration for a visualization of this example.

![](images/image_1764833157.3370066.svg)![Example of a lost update](images/6207340624871424.svg "Example of a lost update")

Example of a lost update

Depending on the application, it might be safe to allow lost updates in some cases. For example, consider an application that allows multiple administrators to update specific parts of an internal website used by employees of a company.

### Read skew[#](#Read-skew)

A **read skew** occurs when there are integrity constraints between two data items that seem to be violated because a transaction can only see partial results of another transaction.

**Example**

Let’s imagine an application that contains a table of persons, where each record represents a person and contains a list of all the friends of this person. The main integrity constraint is that friendships are mutual; if person B is included in person A’s list of friends, then A must also be included in B’s list. Every time someone (say, P1) wants to unfriend someone else (say, P2), a transaction is executed that removes P2 from P1’s list and also removes P1 from P2’s list in a single go.

Now, let’s also assume that some other part of the application allows people to view friends of multiple people simultaneously. This is done by a transaction that reads the friends list of these people. If the second transaction reads the friends list of P1 before the first transaction has started but reads the friends list of P2 after the first transaction has been committed, it will notice an integrity violation. P2 will be in P1’s list of friends, but P1 will not be in P2’s list of friends.

> Note that this case is not a dirty read because any values written by the first transaction are read-only after it has been committed.

See the following illustration for a visualization of this example.

![](images/image_1764833157.514137.svg)![Example of a read skew](images/5302041177096192.svg "Example of a read skew")

Example of a read skew

A strict requirement to prevent read skew is quite rare, as we might have guessed already. For example, a common application of this type might allow a user to view the profile of only one person at a time along with their friends, thus not requiring the integrity constraint described above.

### Write skew[#](#Write-skew)

A **write skew** occurs when two transactions read the same data, but then modify disjoint sets of data.

**Example**

Imagine an application that maintains the on-call rotation of doctors in a hospital. A table contains one record for every doctor with a field indicating whether they are on-call. The application allows a doctor to remove themself from the on-call rotation if another doctor is also registered. This is done via a transaction that reads the number of doctors that are on-call from this table. If the number is greater than one, it updates the record corresponding to this doctor to not be on-call.

Now, let’s look at the problems that can arise from the write skew phenomenon. Let’s say two doctors, Alice and Bob, are on-call currently, and they both decide to see if they can remove themselves. Two transactions running concurrently might read the state of the database, see there are two doctors, and remove the associated doctor from being on-call. In the end, the system ends up with no doctors on-call!

See the following illustration for visualization of this example.

![](images/image_1764833157.6957848.svg)![Example of a write skew](images/6704429712670720.svg "Example of a write skew")

Example of a write skew

> It is evident by now that there are many different anomalies for us to consider. On top of that, different applications manipulate data in different ways. So, we have to analyze each case separately to see which anomalies can create problems.

Backlesson

Mark As CompletedComplete

Next

CAP Theorem's Consistency Model

Prevention of Anomalies in Isolation Levels

Ask

[Anomalies](#Anomalies)

[Dirty write](#Dirty-write)

[Dirty read](#Dirty-read)

[Fuzzy or non-repeatable read](#Fuzzy-or-non-repeatable-read)

[Phantom read](#Phantom-read)

[Lost update](#Lost-update)

[Read skew](#Read-skew)

[Write skew](#Write-skew)

---


# Prevention of Anomalies in Isolation Levels

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Prevention of Anomalies in Isolation Levels

# Prevention of Anomalies in Isolation Levels

In this lesson, we will identify which isolation level prevents which anomalies.

We'll cover the following...

* [Isolation level that prevents all of the anomalies](#Isolation-level-that-prevents-all-of-the-anomalies)
* [Other isolation levels](#Other-isolation-levels)

## Isolation level that prevents all of the anomalies[#](#Isolation-level-that-prevents-all-of-the-anomalies)

There is one isolation level that prevents all of these anomalies: the **serializable** one.

Like the consistency models presented in the [Consistency Models](https://www.educative.io/courses/distributed-systems-practitioners/consistency-models) lesson, this level provides a more formal specification of what is possible, e.g., which execution histories are possible. More specifically, it guarantees that the result of the execution of concurrent transactions is the same as that produced by some serial execution of the same transactions. This means that we can only analyze serial executions for defects. If all the possible serial executions are safe, then any concurrent execution by a system at the serializable level will also be safe.

However, serializability has performance costs since it intentionally reduces concurrency to guarantee safety.

## Other isolation levels[#](#Other-isolation-levels)

Isolation levels other than the serializable ones are less strict and provide better performance via increased concurrency at the cost of decreased safety.

These models allow some of the anomalies we described previously. The following illustration contains a table with the most basic isolation levels, along with the anomalies they prevent.

## Isolation levels and prevented anomalies

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  | **Dirty**  **Writes** | **Dirty**  **Reads** | **Fuzzy**  **Reads** | **Lost**  **Updates** | **Read**  **Skew** | **Write**  **Skew** | **Phantom**  **Reads** |
| **Read**  **Uncommitted** | not  possible | possible | possible | possible | possible | possible | possible |
| **Read**  **Committed** | not  possible | not  possible | possible | possible | possible | possible | possible |
| **Snapshot**  **Isolation** | not  possible | not  possible | not  possible | not  possible | not  possible | possible | possible |
| **Repeatable**  **Read** | not  possible | not  possible | not  possible | not  possible | not  possible | not  possible | possible |
| **Serializability** | not  possible | not  possible | not  possible | not  possible | not  possible | not  possible | not  possible |

These isolation levels originated from the early relational database systems that were not distributed. Still, they are applicable in distributed datastores too.

> **Note:** Based on the definition of Snapshot Isolation, one can think of how phantom reads are possible in this isolation level. This is due to the practical implementation of snapshot isolation using multi-version concurrency control (MVCC), discussed in the lesson on [Achieving Snapshot Isolation](https://www.educative.io/courses/distributed-systems-practitioners/achieving-snapshot-isolation).

Backlesson

Mark As CompletedComplete

Next

Isolation Levels and Anomalies

Consistency and Isolation

Ask

[Isolation level that prevents all of the anomalies](#Isolation-level-that-prevents-all-of-the-anomalies)

[Other isolation levels](#Other-isolation-levels)

---


# Consistency and Isolation

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Consistency and Isolation

# Consistency and Isolation

Let's examine the differences and similarities between consistency models and isolation levels.

We'll cover the following...

* [Similarities between consistency models and isolation models](#Similarities-between-consistency-models-and-isolation-models)
* [Differences between consistency models & isolation levels](#Differences-between-consistency-models--isolation-levels)
  + [Why real-time guarantees are important](#Why-real-time-guarantees-are-important)
* [Strict serializability](#Strict-serializability)

The following illustration will help us remember the consistency models and isolation levels.

Consistency models and isolation levels

## Similarities between consistency models and isolation models[#](#Similarities-between-consistency-models-and-isolation-models)

It is interesting to observe that *isolation levels* are not that different from *consistency models*.

*Isolation levels* and *consistency models* are essential constructs that allow us to express:

* Which executions are possible
* Which executions are not possible

In both cases, some of the models are stricter and allow fewer executions, thus providing increased *safety* at the cost of reduced *performance* and *availability*.

For instance, *linearizability* allows a subset of the executions *causal consistency* allows, while *serializability* allows a subset of the executions that *snapshot isolation* allows.

> We can also express this strictness relationship by saying that one model implies another model.

The fact that a system provides *linearizability* automatically implies that the same system also provides *causal consistency*.

> Note that there are some models that are not directly comparable, which means neither of them is stricter than the other.

## Differences between consistency models & isolation levels[#](#Differences-between-consistency-models--isolation-levels)

*Consistency models* and *isolation levels* have some differences with regards to the characteristics of their allowed and disallowed behaviors.

* *Consistency models* are applied to single-object operations (e.g. read/write to a single register), while *isolation levels* are applied to multi-object operations (e.g. read and write from/to multiple rows in a table within a transaction).

> Looking at the strictest models in these two groups, *linearizability* and *serializability*, there is another important difference.

* *Linearizability* provides real-time guarantees, while *serializability* does not.

*Linearizability* guarantees that the effects of an operation took place at some point between when the client invoked the operation, and when the result of the operation was returned to the client.

*Serializability* only guarantees that the effects of multiple transactions will be the same as if they run in serial order. It does not provide any guarantee on whether that serial order would be compatible with real-time order.

### Why real-time guarantees are important[#](#Why-real-time-guarantees-are-important)

The following illustration shows why real-time guarantees are important from an application perspective.

![](images/image_1764833184.383187.svg)![](images/6246805776498688.svg)

Think of an automated teller machine that can support two transactions:

1. `GET_BALANCE()`
2. `WITHDRAW(amount)`

The first transaction performs a single operation to read the balance of an account.

The second operation reads the balance of an account, reduces it by the specified amount, and then returns the client the specified amount in cash.

Let’s also assume this system is serializable.

Now, let’s examine the following scenario:

A customer with an initial balance of `x` reads their balance and then decides to withdraw $20 by executing a `WITHDRAW(20)` transaction.

After the transaction has been completed and the money is returned, the customer performs a `GET_BALANCE()` operation to check their new balance. However, the machine still returns `x` as the current balance instead of `x-20`.

> Note that this execution is serializable (with the serial order of transactions T1, T3, and T2) and the end result is as if the machine executed the `GET_BALANCE()` transactions first, and then the `WITHDRAW(20)` transaction in a completely serial order.

This example shows how serializability is not sufficient in itself in some cases.

## Strict serializability[#](#Strict-serializability)

**Strict serializability** is a model that is a combination of *linearizability* and *serializability*.

This model guarantees that the result of multiple transactions is equivalent to the result of a serial execution of them, and is also compatible with the real-time ordering of these transactions.

As a result, transactions appear to execute serially, and the effects of each of them take place at some point between their invocation and completion.

As we learned before, *strict* serializability is often a more useful guarantee than *plain* serializability.

In centralized systems, however, providing strict serializability is simple and just as efficient as only providing serializability guarantees. As a result, systems such as relational databases sometimes advertise *serializability* guarantees, while they actually provide *strict serializability*.

This is not necessarily true in a distributed database, where providing *strict serializability* can be more costly because it requires additional coordination.

It is important to understand the difference between these two guarantees in order to determine which one is needed, depending on the application domain.

Backlesson

Mark As CompletedComplete

Next

Prevention of Anomalies in Isolation Levels

Hierarchy of Models

Ask

[Similarities between consistency models and isolation models](#Similarities-between-consistency-models-and-isolation-models)

[Differences between consistency models & isolation levels](#Differences-between-consistency-models--isolation-levels)

[Why real-time guarantees are important](#Why-real-time-guarantees-are-important)

[Strict serializability](#Strict-serializability)

---


# Hierarchy of Models

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Hierarchy of Models

# Hierarchy of Models

Let's look at the hierarchy of the consistency models and isolation levels based on the strictness and guarantees they provide.

We'll cover the following...

* [Hierarchy tree](#Hierarchy-tree)

Models can be organized in a hierarchical tree according to their strictness and the guarantees they provide.

## Hierarchy tree[#](#Hierarchy-tree)

The following illustration depicts such a tree that contains some of the models.

![](images/image_1764833194.5910208.svg)

Hierarchy of consistency levels and isolation models, where the strictness level decreases from top to bottom

Backlesson

Mark As CompletedComplete

Next

Consistency and Isolation

Why All the Formalities?

Ask

[Hierarchy tree](#Hierarchy-tree)

---


# Why All the Formalities?

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Why All the Formalities?

# Why All the Formalities?

Let's discuss why we need the complicated, formal, and academic constructs we have learned till now.

We'll cover the following...

* [The need for formal models](#The-need-for-formal-models)

The previous chapters spent a significant amount of time going through many different formal models.

## The need for formal models[#](#The-need-for-formal-models)

All these complicated, formal, and academic constructs help us define different types of properties in a more precise way. As a result, when we design a system, we can easily reason about the properties the system needs to satisfy, and know which of these models are sufficient to provide the required guarantees.

![](images/4709981453680640.png)

In many cases, applications are built on top of pre-existing datastores. They derive most of their properties from these datastores because most of the data management is delegated to them. Consequently, necessary research needs to be done to identify datastores that can provide the guarantees the application needs.

Unfortunately, the terminology and their associated models presented here are not used consistently across the industry. This makes decision-making and comparison of systems a lot harder.

For example, some data stores do not precisely state what kind of consistency guarantees their system can provide—or, at least, these statements are well hidden. In fact, these statements should be highlighted as some of the most important things in their documentation. In some other cases, such documentation exists, but the various levels we discussed earlier are misused and lead to a lot of confusion. As we learned earlier, one source of this confusion was the initial ANSI-SQL standard. For example, the serializable level provided by Oracle 11g, MySQL 5.7, and PostgreSQL 9.0 was not truly serializable and was susceptible to some anomalies.

Understanding the models presented here is a good first step towards being more careful when we design systems, so we reduce the risk for errors. We should be willing to search the documentation of systems we want to use to understand what kind of guarantees they provide. Ideally, we should also be able to read between the lines and identify mistakes or incorrect usages of terms. This will help us make more informed decisions. Hopefully, it will also help raise awareness across the industry and encourage vendors of distributed systems to specify the guarantees their systems can provide.

Backlesson

Mark As CompletedComplete

Next

Hierarchy of Models

Quiz on Distributed System Concepts and Theorems

Ask

[The need for formal models](#The-need-for-formal-models)

---


# Introduction to Distributed Transactions

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction to Distributed Transactions

# Introduction to Distributed Transactions

Get an introduction to distributed transactions.

We'll cover the following...

* [Transaction](#Transaction)
  + [Guarantees provided by database transactions](#Guarantees-provided-by-database-transactions)
    - [Atomicity](#Atomicity)
    - [Consistency](#Consistency)
    - [Isolation](#Isolation)
    - [Durability](#Durability)
  + [What ACID means in an application](#What-ACID-means-in-an-application)
  + [Achieving consistency and durability](#Achieving-consistency-and-durability)
* [Distributed transaction](#Distributed-transaction)
  + [Atomicity and isolation in distributed transactions](#Atomicity-and-isolation-in-distributed-transactions)

One of the most common problems faced when moving from a *centralized* to a *distributed* system is performing operations across multiple nodes in an atomic way. We call this a **distributed transaction**.

> In the next three chapters, we explore all the complexities involved in performing a distributed transaction, and examine several available solutions for each one as well as their pitfalls.

Before diving into the available solutions, let’s first learn about **transactions** and their properties, and what distinguishes distributed transactions from them.

## Transaction[#](#Transaction)

A transaction is a unit of work performed in a database system that represents a change potentially composed of multiple operations.

**Database transactions** are an abstraction invented to simplify engineers’ work and relieve them of dealing with all the possible failures that the inherent unreliability of hardware introduces.

### Guarantees provided by database transactions[#](#Guarantees-provided-by-database-transactions)

As we have learned, the acronym ACID sums up the major guarantees that database transactions provide. As a reminder, ACID stands for the following:

* Atomicity
* Consistency
* Isolation
* Durability

> Each transaction TX comprises multiple operations (op1, op2, op3, …), and multiple transactions (TX1, TX2, etc.,) are executed simultaneously in a database.

#### Atomicity[#](#Atomicity)

Atomicity is the property that guarantees that either all of the operations of a transaction completed successfully or none of them take effect.

In other words, there are no situations where the transaction “partially fails,” by performing only some of the operations.

#### Consistency[#](#Consistency)

Consistency ensures that a transaction transitions the database from a valid state to another valid state, while maintaining all the invariants that the application defines.

As an example, a financial application defines an invariant that states that the balance of every account should always be positive. The database then ensures that this invariant is maintained at all times while executing transactions.

#### Isolation[#](#Isolation)

Isolation guarantees that transactions are executed concurrently, without interfering with each other.

#### Durability[#](#Durability)

Durability guarantees that once a transaction is committed, it remains committed even in the case of a system failure (i.e., power outage).

> All these properties transfer a set of responsibilities from the application to the database, simplify the development of applications, and reduce any potential errors due to software bugs or hardware failures.

### What ACID means in an application[#](#What-ACID-means-in-an-application)

**Atomicity** implies that our application does not have to take care of all possible failures, but has the conditional logic to bring the database back to a consistent state in the case of a partial failure by rolling back operations that should not have occured.

**Consistency** allows us to state the invariants of our application in a declarative way and remove redundant code from our application and allow the database to perform these checks whenever necessary.

**Isolation** allows our applications to leverage concurrency and serve multiple requests by executing transactions in parallel, with the certainty that the database prevents any bugs due to the concurrent execution.

**Durability** guarantees that when the database declares a transaction committed, it is a final declaration that cannot be reverted. This relieves our application of complicated logic again.

> These aspects of *consistency* and *durability* do not require special treatment in distributed systems and are relatively straightforward, so there is no separate analysis for them in this course.

### Achieving consistency and durability[#](#Achieving-consistency-and-durability)

Databases provide many different mechanisms that maintain consistency. This includes constraints, cascades, triggers, etc. The application is responsible for defining any constraints through these mechanisms. Meanwhile, the database is responsible for checking these conditions while executing transactions and aborting any transactions that violate them.

Durability is guaranteed by persisting transactions at non-volatile storage when they commit.

> In distributed systems, this might be a bit more nuanced. This is because the system should ensure that it stores the results of a transaction in more than one node so that the system keeps functioning if a single node fails. In fact, this is reasonable, because availability is one of the main benefits of a distributed system. We can achieve this via replication.

A database transaction is quite a powerful abstraction that greatly simplifies how applications are built. Considering the inherent complexity in distributed systems, we can easily deduce that transactional semantics are even more useful in them.

## Distributed transaction[#](#Distributed-transaction)

A distributed transaction is a transaction that takes place in two or more different nodes.

There are two slightly different variants of distributed transactions.

1. The first variant is one where the same piece of data needs to be updated in multiple replicas. This is the case where the whole database is essentially duplicated in multiple nodes, and a transaction needs to update all of them in an atomic way.
2. The second variant is one where different pieces of data that reside in different nodes need to be updated atomically. For instance, a financial application may use a partitioned database for the accounts of customers, where the balance of user A resides in node n1. In contrast, the balance of user B resides in node n2, and we want to transfer some money from user A to user B. We need to do this in an atomic way so that data is not lost (i.e., removed from user A, but not added in user B, because the transaction fails midway).

> The second variant is the most common use of distributed transactions, while primary-backup synchronous replication mostly tackles the first variant.

### Atomicity and isolation in distributed transactions[#](#Atomicity-and-isolation-in-distributed-transactions)

The aspects of *atomicity* and *isolation* are significantly more complex and require us to consider more things in the context of distributed transactions.

For instance, partial failures make it much harder to guarantee atomicity. Meanwhile, the concurrency and network asynchrony present in distributed systems make it challenging to preserve isolation between transactions running in different nodes.

Furthermore, *atomicity* and *isolation* have far-reaching implications for the performance and the availability of a distributed system, as we see later in this course.

> This course contains dedicated sections for **atomicity** and **isolation**, that analyze their characteristics and some techniques.

Note that some of these techniques are used internally by database systems, and we might want to use them from our application to store and access data. This means that everything may be hidden from us behind a high-level interface. This interface lets us build an application without having to know how the database provides all these capabilities under the hood.

However, it is still useful to understand these techniques well, so we can make better decisions about which database systems to use. There can also be cases where we need to use some of these techniques directly at the application level to achieve properties that the database system doesn’t provide.

Backlesson

Mark As CompletedComplete

Next

Quiz on Distributed System Concepts and Theorems

Quiz on Distributed Transactions

Ask

[Transaction](#Transaction)

[Guarantees provided by database transactions](#Guarantees-provided-by-database-transactions)

[Atomicity](#Atomicity)

[Consistency](#Consistency)

[Isolation](#Isolation)

[Durability](#Durability)

[What ACID means in an application](#What-ACID-means-in-an-application)

[Achieving consistency and durability](#Achieving-consistency-and-durability)

[Distributed transaction](#Distributed-transaction)

[Atomicity and isolation in distributed transactions](#Atomicity-and-isolation-in-distributed-transactions)

---


# Quiz on Distributed Transactions

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed Transactions

# Quiz on Distributed Transactions

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

Which acronym sums up the guarantees that a distributed transaction needs to provide?

A.

ACID

B.

CAP

---

1 / 5

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Introduction to Distributed Transactions

Achieving Serializability

Ask

---


# Achieving Serializability

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Achieving Serializability

# Achieving Serializability

Let's learn how to achieve serializability. Look at the mechanisms for concurrency control and the cases where each performs well.

We'll cover the following...

* [Types of serializability](#Types-of-serializability)
  + [View serializability](#View-serializability)
  + [Conflict serializability](#Conflict-serializability)
* [Determining whether a schedule is a conflict serializable](#Determining-whether-a-schedule-is-a-conflict-serializable)
  + [Trivial way](#Trivial-way)
  + [Precedence graph](#Precedence-graph)
    - [Example](#Example)
* [Generating a schedule that is serializable](#Generating-a-schedule-that-is-serializable)
* [Mechanisms for concurrency control](#Mechanisms-for-concurrency-control)
  + [Pessimistic concurrency control](#Pessimistic-concurrency-control)
  + [Optimistic concurrency control](#Optimistic-concurrency-control)
* [Cases where optimistic methods perform well](#Cases-where-optimistic-methods-perform-well)
* [Cases where pessimistic methods perform well](#Cases-where-pessimistic-methods-perform-well)

We know that there are some potential anomalies from concurrent transactions that are not properly isolated.

Concurrent transaction

> There are different isolation levels that prevent these anomalies. Stronger isolation levels prevent more anomalies at the cost of performance.

We also provided some examples to illustrate the real-life consequences of these anomalies.

As the previous lesson, [Consistency and Isolation](https://www.educative.io/courses/distributed-systems-practitioners/consistency-and-isolation), explained, the system should be **strictly serializable** to be completely protected against any of these anomalies.

> *Strictly serializable* is the strongest isolation level. Then comes **serializability**, which we will see in this lesson.

A system that provides serializability guarantees that the result of any allowed execution of transactions is the same as that produced by some serial execution of the same transactions(hence its name).

> In the context of isolation, the execution of multiple transactions that correspond to an ordering of the associated operations is also called a **schedule**.

You might ask: what does the **same** mean in the previous sentence? Let’s explain.

## Types of serializability[#](#Types-of-serializability)

There are two major types of serializability that establish two different notions of similarity.

### View serializability[#](#View-serializability)

A schedule is a **view** equivalent to a serial schedule with the same transactions when all the operations from transactions in the two schedules read and write the same data values (“view” the same data).

### Conflict serializability[#](#Conflict-serializability)

A schedule is a **conflict** equivalent to a serial schedule with the same transactions when every pair of conflicting operations between transactions is ordered in the same way in both schedules.

> It turns out that calculating whether a schedule is *view serializable* is a very computationally hard problem. More specifically, it is an **NP-complete** problem. This means that the time required to solve the problem using any currently known algorithm increases rapidly as the size of the problem grows. So, we will not analyze view serializability further.

However, determining whether a schedule is conflict serializable is a much easier problem to solve, which is one of the reasons conflict serializability is widely used.

## Determining whether a schedule is a conflict serializable[#](#Determining-whether-a-schedule-is-a-conflict-serializable)

To understand conflict serializability, we first have to define what it means for two operations to be conflicting.

Two operations are conflicting (or conflict) if:

* They belong to different transactions
* They are on the same data item, and at least one of them is a write operation, where a write operation inserts, modifies or deletes an object

As a result, we can have three different forms of conflicts:

1. A read-write conflict
2. A write-read conflict
3. A write-write conflict

### Trivial way[#](#Trivial-way)

A trivial way to check if a schedule is a conflict serializable is to calculate all possible serial schedules, identify conflicting operations in them, and check if their order is the same as in the schedule under examination.

> This is computationally heavy, as it requires us to compute all the possible permutations of transactions.

A more practical way of determining whether a schedule is conflict serializable is through a **precedence graph**.

### Precedence graph[#](#Precedence-graph)

A **precedence graph** is a directed graph, where the:

* **Nodes** represent transactions in a schedule
* **Edges** represent conflicts between operations

The edges in the graph denote the order in which transactions must execute in the corresponding serial schedule.

> As a result, a schedule is a conflict serializable if and only if its precedence graph of committed transactions is **acyclic**.

Let’s look at an example to get a better idea about this rule.

#### Example[#](#Example)

The following illustration contains a schedule of three transactions T1T\_1T1​, T2T\_2T2​, and T3T\_3T3​, where R(Ii)R(I\_i)R(Ii​) and W(Ii)W(I\_i)W(Ii​) represent a read and write operation, respectively, on item IiI\_iIi​.

Precedence graph of a non-conflict serializable schedule

As we can see in the above illustration, the conflicting operations in this schedule form a precedence graph *with* a cycle. This means that this schedule is *not conflict serializable*. The cycle between T1T\_1T1​ and T2T\_2T2​ means that there must be a serial schedule where T1T\_1T1​ executes before T2T\_2T2​ and vice-versa, which is impossible.

The following illustration contains a slightly different schedule of the same transactions that are now *conflict serializable* since there are *no cycles* in the corresponding precedence graph.

Precedence graph of a conflict serializable schedule

Looking at the precedence graph, we can see the edges only impose the constraints that T1T\_1T1​ must be before T2T\_2T2​ and T3T\_3T3​ in the corresponding serial schedule. This means that this schedule is conflict equivalent to both serial schedules T1T\_1T1​, T2T\_2T2​, T3T\_3T3​ and T1T\_1T1​, T3T\_3T3​, T2T\_2T2​.

> The method described above is one way to determine whether a schedule is *serializable*. However, what we really need is a way to generate a schedule that is *serializable* ahead of time.

## Generating a schedule that is serializable[#](#Generating-a-schedule-that-is-serializable)

The notion of a precedence graph is beneficial here.

All we need to do is ensure that no cycle is formed as we execute operations in the schedule. We can achieve this in two basic ways.

1. Prevent transactions from making progress when there is a risk of introducing a conflict that can create a cycle.
2. Let transactions execute all their operations and check if committing that transaction could introduce a cycle. In that case, the transaction can be aborted and restarted from scratch.

> These two approaches lead to the two main mechanisms for concurrency control.

## Mechanisms for concurrency control[#](#Mechanisms-for-concurrency-control)

There are two main mechanisms for concurrency control:

### Pessimistic concurrency control[#](#Pessimistic-concurrency-control)

This approach blocks a transaction if it’s expected to cause violation of serializability, and resumes it when it is safe to do so.

This is usually achieved by having transactions acquire locks on the data they process to prevent other transactions from processing the same data concurrently.

The name *pessimistic* comes from the fact that this approach assumes that the majority of transactions are expected to conflict with each other, so appropriate measures are taken to prevent this from causing issues.

### Optimistic concurrency control[#](#Optimistic-concurrency-control)

This approach delays the checking of whether a transaction complies with the rules until the end of the transaction. The transaction is aborted if a commit would violate any serializability rules, and is then restarted and re-executed from the beginning.

The name “optimistic” comes from the fact that this approach assumes that the majority of transactions are expected not to have conflicts, so measures are taken only in the rare case that they do.

> The main trade-off between *pessimistic* and *optimistic* concurrency control is between the extra overhead from locking mechanisms, and the wasted computation from aborted transactions.

## Cases where optimistic methods perform well[#](#Cases-where-optimistic-methods-perform-well)

In general, optimistic methods are expected to perform well in cases where there are not many conflicts between transactions.

This can be the case for workloads with many read-only transactions and only a few write transactions, or in cases where most of the transactions touch different data.

## Cases where pessimistic methods perform well[#](#Cases-where-pessimistic-methods-perform-well)

Pessimistic methods incur some overhead from the use of locks. Still, they can perform better in workloads that contain a lot of transactions that conflict. This is because they reduce the number of aborts and restarts, thus reducing wasted effort.

Your system mostly runs read-only analytics with a few occasional writes, and transactions rarely touch the same rows. Should you choose optimistic or pessimistic concurrency control, and what trade-off are you accepting? Provide your answer in the widget given below.

Want to know the correct answer?

Choosing Between Optimistic and Pessimistic Concurrency Control

Enter your answer here

﻿

Evaluate

Beta

750 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Quiz on Distributed Transactions

Pessimistic Concurrency Control (PCC)

Ask

[Types of serializability](#Types-of-serializability)

[View serializability](#View-serializability)

[Conflict serializability](#Conflict-serializability)

[Determining whether a schedule is a conflict serializable](#Determining-whether-a-schedule-is-a-conflict-serializable)

[Trivial way](#Trivial-way)

[Precedence graph](#Precedence-graph)

[Example](#Example)

[Generating a schedule that is serializable](#Generating-a-schedule-that-is-serializable)

[Mechanisms for concurrency control](#Mechanisms-for-concurrency-control)

[Pessimistic concurrency control](#Pessimistic-concurrency-control)

[Optimistic concurrency control](#Optimistic-concurrency-control)

[Cases where optimistic methods perform well](#Cases-where-optimistic-methods-perform-well)

[Cases where pessimistic methods perform well](#Cases-where-pessimistic-methods-perform-well)

---


# Pessimistic Concurrency Control (PCC)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Pessimistic Concurrency Control (PCC)

# Pessimistic Concurrency Control (PCC)

In this lesson, we will explore the 2-phase locking, a pessimistic concurrency control protocol.

We'll cover the following...

* [2-Phase locking (2PL)](#2-Phase-locking-2PL)
  + [Types of locks](#Types-of-locks)
* [Interaction between write (exclusive) locks and read (shared) locks](#Interaction-between-write-exclusive-locks-and-read-shared-locks)
* [Phases where transactions acquire or release locks](#Phases-where-transactions-acquire-or-release-locks)
  + [Expanding phase](#Expanding-phase)
  + [Shrinking phase](#Shrinking-phase)
* [Deadlocks](#Deadlocks)
  + [Ways to deal with deadlocks](#Ways-to-deal-with-deadlocks)
    - [Prevention](#Prevention)
    - [Detection](#Detection)

## 2-Phase locking (2PL)[#](#2-Phase-locking-2PL)

**2-phase locking (2PL)** is a pessimistic concurrency control protocol that uses locks to prevent concurrent transactions from interfering. These locks indicate that a record is being used by a transaction, so that other transactions can determine whether it is safe to use it or not.

### Types of locks[#](#Types-of-locks)

There are two basic types of locks used in this protocol:

* **Write (exclusive) locks**: These locks are acquired when a record is going to be written (inserted/updated/deleted).
* **Read (shared) locks**: These locks are acquired when a record is read.

## Interaction between write (exclusive) locks and read (shared) locks[#](#Interaction-between-write-exclusive-locks-and-read-shared-locks)

* A *read lock* does not block a *read* from another transaction. This is why it is also called *shared* because multiple read locks can be acquired at the same time.
* A *read lock* blocks a *write* from another transaction. The other transaction will have to wait until the read operation is completed and the read lock is released. Then, it will have to acquire a write lock and perform the write operation.
* A *write* lock blocks both *reads* and *writes* from other transactions, which is also the reason it’s also called *exclusive*. The other transactions will have to wait for the write operation to complete and the write lock to be released; then, they will attempt to acquire the proper lock and proceed.

> If a lock blocks another lock, they are called **incompatible**. Otherwise, they are called **compatible**.

As a result, the relationships described above can be visualized in a compatibility matrix, as shown in the following illustration.

Compatibility of locks in 2PL

> The astute reader might notice a similarity between this matrix and the definition of conflicts in *conflict serializability*. This is not a coincidence. The two-phase locking protocol makes use of these locks to prevent cycles of these conflicts from forming, as described before.

Each type of conflict is represented by an incompatible entry in the above matrix.

## Phases where transactions acquire or release locks[#](#Phases-where-transactions-acquire-or-release-locks)

In 2-phase locking protocol, transactions acquire and release locks in two distinct phases:

### Expanding phase[#](#Expanding-phase)

In this phase, a transaction is allowed to only *acquire* locks, but not *release* any locks.

### Shrinking phase[#](#Shrinking-phase)

In this phase, a transaction is allowed to only *release* locks, but not *acquire* any locks.

The following illustration shows these phases.

Created with Fabric.js 3.6.6

1 / 2

A transaction acquiring locks for using distributed resources

Created with Fabric.js 3.6.6

1 / 2

A transaction releasing locks to free up acquired distributed resources

> It’s been implied so far that locks are held per record. However, it’s important to note that if the associated database supports operations based on predicates, there must also be a way to lock ranges of records (predicate locking), e.g., all the customers of ages between 23 and 29. This is to prevent anomalies like phantom reads.

As proven by Franking, this protocol only allows serializable executions to happen.

> A schedule generated by two-phase locking will be conflict equivalent to a serial schedule, where transactions are serialized in the order they completed their expanding phase.

There are some slight variations of the protocol that can provide some additional properties, such as:

* Strict two-phase locking (S2PL)
* Strong strict two-phase locking (SS2PL)

## Deadlocks[#](#Deadlocks)

The locking mechanism introduces the risk for deadlocks, where two transactions might wait on each other for the release of a lock, thus never making progress. This is shown in the following illustration.

Deadlock: Transaction 1 is waiting for Transaction 2 to release Resource B while Transaction 2 is waiting for Transaction 1 to release Resource A

### Ways to deal with deadlocks[#](#Ways-to-deal-with-deadlocks)

In general, there are two ways to deal with these deadlocks.

#### Prevention[#](#Prevention)

This method prevents the deadlocks from being formed in the first place.

For example, this can be done if transactions know all the locks they need in advance and acquire them in an ordered way. This is typically done by the application since many databases support interactive transactions and are thus unaware of all the data a transaction will access.

#### Detection[#](#Detection)

This method detects deadlocks that occur, and breaks them.
For example, this can be achieved by keeping track of which transaction a transaction waits on, using this information to detect cycles that represent deadlocks, and then forcing one of these transactions to abort. This is typically done by the database, without the application having to do anything extra.

Backlesson

Mark As CompletedComplete

Next

Achieving Serializability

Optimistic Concurrency Control (OCC)

Ask

[2-Phase locking (2PL)](#2-Phase-locking-2PL)

[Types of locks](#Types-of-locks)

[Interaction between write (exclusive) locks and read (shared) locks](#Interaction-between-write-exclusive-locks-and-read-shared-locks)

[Phases where transactions acquire or release locks](#Phases-where-transactions-acquire-or-release-locks)

[Expanding phase](#Expanding-phase)

[Shrinking phase](#Shrinking-phase)

[Deadlocks](#Deadlocks)

[Ways to deal with deadlocks](#Ways-to-deal-with-deadlocks)

[Prevention](#Prevention)

[Detection](#Detection)

---


# Optimistic Concurrency Control (OCC)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Optimistic Concurrency Control (OCC)

# Optimistic Concurrency Control (OCC)

In this lesson, we will describe a way through which the optimistic concurrency control method controls concurrent operations.

We'll cover the following...

* [Begin phase](#Begin-phase)
* [Read & modify phase](#Read--modify-phase)
* [Validate & commit/rollback phase](#Validate--commitrollback-phase)
  + [Ways to implement validation logic](#Ways-to-implement-validation-logic)
    - [Version checking](#Version-checking)
    - [Timestamp ordering](#Timestamp-ordering)

**Optimistic concurrency control** **(OCC)** is a concurrency control method that was first proposed in 1981 by Kung et al., where transactions can access data items without acquiring locks on them.

In this method, transactions execute in the following three phases:

* Begin
* Read & modify
* Validate & commit/rollback

## Begin phase[#](#Begin-phase)

In this phase, transactions are assigned a unique timestamp that marks the beginning of the transaction referred to as the **start timestamp**.

## Read & modify phase[#](#Read--modify-phase)

During this phase, transactions execute their read and write operations *tentatively*. This means that when an item is modified, a copy of the item is written to a temporary, local storage location. A read operation first checks for a copy of the item in this location and returns this one, if it exists. Otherwise, it performs a regular read operation from the database.

## Validate & commit/rollback phase[#](#Validate--commitrollback-phase)

The transaction enters this phase when all operations have been executed.

During this phase, the transaction checks whether there are other transactions that have modified the data this transaction has accessed, and have started after this transaction’s start time. If there are, then the transaction is aborted and restarted from the beginning, acquiring a new timestamp. Otherwise, the transaction can be committed.

This is shown in the following illustration.

Created with Fabric.js 3.6.6

1 / 3

Client A starts the transaction at timestamp 1, and writes 5 for X to the Storage

Created with Fabric.js 3.6.6

1 / 3

Client B starts the transaction at timestamp 2, and writes 7 for X to the Storage

Created with Fabric.js 3.6.6

1 / 3

Client B has modified the value of X, and also this transaction was started after Client A’s transaction

The commit of a transaction is performed by copying all the values from write operations, from the local storage to the common database storage that other transactions access.

> It’s important to note that the validation checks and the associated commit operation need to be performed in a single atomic action as part of a critical section.

This requires some form of locking mechanism, so there are various optimizations of this approach that attempt to reduce the duration of this phase to improve performance.

### Ways to implement validation logic[#](#Ways-to-implement-validation-logic)

There are two ways to implement validation logic.

#### Version checking[#](#Version-checking)

One way is via version checking, where every data item is marked with a version number. Every time a transaction accesses an item, it can keep track of the version number it had at that point.

During the validation phase, the transaction can check if the version number is the same. If it is, it would mean that no other transaction has accessed the item in the meanwhile.

#### Timestamp ordering[#](#Timestamp-ordering)

Another way is by using timestamps assigned to transactions, a technique also known as timestamp ordering, since the timestamp indicates the order in which a transaction must occur relative to the other transaction.

In this approach, each transaction keeps track of the items that are accessed by read or write operations, known as the **read set** and the **write set**.

During validation, a transaction performs the following inside a critical section:

It records a fresh timestamp, called the **finish timestamp**, and iterates over all the transactions that have been assigned a timestamp between the transaction’s start and finish timestamp.

> These are essentially all transactions that have started after the running transaction and have already been committed.

For each of those transactions, the running transaction checks if their *write set* intersects with its own *read set*. If that’s true for any of these transactions, it means that the transaction essentially reads a value “from the future.”

As a result, the transaction is invalid and must be aborted and restarted from the beginning with a fresh timestamp. Otherwise, the transaction is committed, and is assigned the next timestamp.

Backlesson

Mark As CompletedComplete

Next

Pessimistic Concurrency Control (PCC)

Achieving Snapshot Isolation

Ask

[Begin phase](#Begin-phase)

[Read & modify phase](#Read--modify-phase)

[Validate & commit/rollback phase](#Validate--commitrollback-phase)

[Ways to implement validation logic](#Ways-to-implement-validation-logic)

[Version checking](#Version-checking)

[Timestamp ordering](#Timestamp-ordering)

---


# Achieving Snapshot Isolation

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Achieving Snapshot Isolation

# Achieving Snapshot Isolation

In this lesson, we will learn the multi-version concurrency control mechanism, and discuss how it helps to achieve snapshot isolation.

We'll cover the following...

* [Multi-version concurrency control (MVCC)](#Multi-version-concurrency-control-MVCC)
* [Achieving snapshot isolation using MVCC](#Achieving-snapshot-isolation-using-MVCC)
  + [Steps](#Steps)
    - [Performing a read operation](#Performing-a-read-operation)
    - [Performing a write operation](#Performing-a-write-operation)
* [Not all anomalies can be prevented in MVCC](#Not-all-anomalies-can-be-prevented-in-MVCC)
  + [Write-skew example](#Write-skew-example)

## Multi-version concurrency control (MVCC)[#](#Multi-version-concurrency-control-MVCC)

**Multiversion Concurrency Control (MVCC)** is a technique where multiple physical versions are maintained for a single logical data item. As a result, update operations do not overwrite existing records, but they write a new version of these records. Read operations can then select a specific version of a record, possibly an older one.

> This is in contrast with the previous techniques, where updates are performed in place and there is a single record for each data item that can be accessed by read operations.

Reed proposed the original protocol in a dissertation in 1978, but many different variations of the original idea have been proposed since then by Silberschatz and Stearns et al.

As the name implies, this technique focuses on the multi-version aspect of storage so that it can be used, theoretically, with both *optimistic* and *pessimistic* schemes.

> However, most variations use an optimistic concurrency control method to leverage the multiple versions of an item from transactions that run concurrently.

## Achieving snapshot isolation using MVCC[#](#Achieving-snapshot-isolation-using-MVCC)

In practice, MVCC is commonly used to implement the **snapshot isolation level**.

*Snapshot isolation* (SI) is an isolation level that guarantees that all reads made in a transaction see a consistent snapshot of the database from the point it started, and the transaction commits successfully if no other transaction has updated the same data since that snapshot.
As a result, it is practically easier to achieve *snapshot isolation* using a MVCC technique.

### Steps[#](#Steps)

This works in the following way:

* Each transaction is assigned a unique timestamp at the beginning.
* Every entry for a data item contains a version that corresponds to the
  timestamp of the transaction that created this new version.
* Every transaction records the following pieces of information during its beginning:

  + The transaction with the highest timestamp that has committed so far (say, TsT\_sTs​)
  + The number of active transactions
    that have started but haven’t been committed yet

#### Performing a read operation[#](#Performing-a-read-operation)

When performing a read operation for an item, a transaction returns the entry with the latest version that is earlier than Ts and does not belong to one of the transactions that were active at the beginning of this transaction. This prevents dirty reads, as only committed values from other transactions can be returned.

> There is an exception to this rule: if the transaction has already updated this item, then this value is returned instead.

Fuzzy reads are also prevented since all the reads return values from the same snapshot and ignore values from transactions that committed after this transaction started.

#### Performing a write operation[#](#Performing-a-write-operation)

When performing a write operation for an item, a transaction checks whether there is an entry for the same item that satisfies one of the following criteria: its version is higher than this transaction’s timestamp, or its version is lower than this transaction’s timestamp, but this version belongs to one of the transactions that were active at the beginning of this transaction.

In any of these cases, the transaction is aborted and can be restarted from scratch with a larger timestamp.

In the first case, if the transaction committed correctly, we would have an entry with version TjT\_jTj​ committed before an entry with version TiT\_iTi​, even though Ti<TjT\_i < T\_jTi​<Tj​, which is wrong.

In the second case, the transaction is aborted to prevent a lost update anomaly.

> While this prevents a lot of the anomalies, it is still not serializable, and some anomalies would still be possible.

## Not all anomalies can be prevented in MVCC[#](#Not-all-anomalies-can-be-prevented-in-MVCC)

An example of an anomaly that would not be prevented is a **write skew**.

### Write-skew example[#](#Write-skew-example)

The following illustration shows why we can’t prevent a write skew from happening.

Created with Fabric.js 3.6.6

1 / 6

Transaction 1 begins, and performs a read operation

Created with Fabric.js 3.6.6

1 / 6

Transaction 2 begins, and performs a read operation

Created with Fabric.js 3.6.6

1 / 6

Transaction 1 writes value for item 2 along with the timestamp as Version

Created with Fabric.js 3.6.6

1 / 6

Transaction 2 writes value for item 1 along with the timestamp as Version

Created with Fabric.js 3.6.6

1 / 6

Transaction 2 commits

In the schedule shown in the above illustration, none of the transactions sees the versions written by the other transaction. However, this would not be possible in a serial execution.

Backlesson

Mark As CompletedComplete

Next

Optimistic Concurrency Control (OCC)

Achieving Full Serializable Snapshot Isolation

Ask

[Multi-version concurrency control (MVCC)](#Multi-version-concurrency-control-MVCC)

[Achieving snapshot isolation using MVCC](#Achieving-snapshot-isolation-using-MVCC)

[Steps](#Steps)

[Performing a read operation](#Performing-a-read-operation)

[Performing a write operation](#Performing-a-write-operation)

[Not all anomalies can be prevented in MVCC](#Not-all-anomalies-can-be-prevented-in-MVCC)

[Write-skew example](#Write-skew-example)

---


# Achieving Full Serializable Snapshot Isolation

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Achieving Full Serializable Snapshot Isolation

# Achieving Full Serializable Snapshot Isolation

Let's investigate how a serializable snapshot isolation algorithm helps to achieve full serializability preventing all anomalies.

We'll cover the following...

* [Serializable snapshot isolation (SSI)](#Serializable-snapshot-isolation-SSI)
  + [Statement](#Statement)
  + [Approach](#Approach)
* [Preventing write-skew anomaly using SSI](#Preventing-write-skew-anomaly-using-SSI)

Research in the field of concurrency control mechanism for achieving **snapshot isolation level** has resulted in an improved algorithm, called **serializable snapshot isolation (SSI)**, that can provide full serializability and has been integrated into commercial, widely used databases by Ports et al.

> This algorithm is still optimistic and just adds some extensions on top of what we described in the previous lesson.

## Serializable snapshot isolation (SSI)[#](#Serializable-snapshot-isolation-SSI)

The solution mechanics are based on a key principle of previous research that showed that all the non-serializable executions under *snapshot isolation* share a common characteristic.

### Statement[#](#Statement)

SSI states this: in the precedence graph of any non-serializable execution, there are two **rw-dependency** edges that form consecutive edges in a cycle. These involve two transactions that have been active concurrently, as shown in the following illustration.

Dangerous structure in serialization graph for SSI

T0T\_0T0​, T1T\_1T1​ and TNT\_NTN​ are three concurrent transactions. TNT\_NTN​ could also be a different number (e.g., T3T\_3T3​). TNT\_NTN​ implies that this circle/chain could be larger and involve more transactions between T1T\_1T1​ and TNT\_NTN​.

> What’s important here is the path from TNT\_NTN​ to T1T\_1T1​ that contains two consecutive transactions with a *rw-dependency*.

A *rw-dependency* is a data dependency between transactions T1T\_1T1​ and T0T\_0T0​, where T0T\_0T0​ reads a version of item `x` and T1T\_1T1​ produces a version of item `x` that is later in the version order than the version read by T0T\_0T0​.

### Approach[#](#Approach)

The SSI approach detects these cases and breaks the cycle when they are about to happen. It prevents them from being formed by aborting one of the involved transactions. To do this, the SSI performs the following steps:

* It keeps track of the incoming and outgoing rw-dependency edges of each transaction.
* If there is a transaction that has both incoming and outgoing edges, the algorithm aborts one of the transactions and retries it later.

> Note this can lead to aborts that are **false positives**, since the algorithm does not check whether there is a cycle. This is done intentionally to avoid the computational costs associated with tracking cycles.

So, it is sufficient to maintain two Boolean flags per transaction `T.inConflict` and `T.outConflict`, that denote whether there is an incoming and outgoing rw-dependency edge. These flags can be maintained in the following way:

* When a transaction TTT is performing a read, it is able to detect whether there is a version of the same item that was written after the transaction started, e.g., by another transaction UUU. This would imply a rw-dependency edge, so the algorithm can update `T.outConflict` and `U.inConflict` to `true`.

> However, this will not detect cases where the write happens after the read. The algorithm uses a different mechanism to detect these cases, too.

* Every transaction creates a read lock, called **SIREAD lock**, when it performs a read. As a result, when a transaction performs a write, it can read the existing SIREAD locks and detect concurrent transactions that have previously read the same item. It thus updates the same Boolean flags accordingly.

> Note that these are a softer form of locks, since they do not block other transactions from operating, but exist mainly to signal data dependencies between them. This means the algorithm preserves its optimistic nature.

## Preventing write-skew anomaly using SSI[#](#Preventing-write-skew-anomaly-using-SSI)

The following illustration shows how this approach would prevent the write skew anomaly we have seen in the previous lesson.

Created with Fabric.js 3.6.6

1 / 6

How write skew is prevented in SSI

Created with Fabric.js 3.6.6

1 / 6

How write skew is prevented in SSI

Created with Fabric.js 3.6.6

1 / 6

How write skew is prevented in SSI

Created with Fabric.js 3.6.6

1 / 6

How write skew is prevented in SSI

Created with Fabric.js 3.6.6

1 / 6

Given both the inConflict and the outConflict flags for T2 are true at this moment, this transaction is aborted

When transaction T2T\_2T2​ executes the write operation, it checks for existing SIREAD locks on item I1I\_1I1​. T1T\_1T1​ holds such a lock, so transaction T2T\_2T2​ updates its `inConflict` flag to `true`. If both the `inConflict` and the `outConflict` flags for T2T\_2T2​ are `true` at this moment, this transaction is aborted.

> For brevity, this explanation omitted some details of SSI. For further information, we can have a look at the related papers by Cahill et al. and Ports et al.

Backlesson

Mark As CompletedComplete

Next

Achieving Snapshot Isolation

Quiz on Isolation

Ask

[Serializable snapshot isolation (SSI)](#Serializable-snapshot-isolation-SSI)

[Statement](#Statement)

[Approach](#Approach)

[Preventing write-skew anomaly using SSI](#Preventing-write-skew-anomaly-using-SSI)

---


# Quiz on Isolation

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Isolation

# Quiz on Isolation

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

True or False: 2-phase locking is an optimistic concurrency control.

A.

True

B.

False

---

1 / 5

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Achieving Full Serializable Snapshot Isolation

Hard to Guarantee Atomicity

Ask

---


# Hard to Guarantee Atomicity

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Hard to Guarantee Atomicity

# Hard to Guarantee Atomicity

Let's check out why atomicity is hard to achieve in general and how it becomes even more difficult in distributed systems.

We'll cover the following...

* [Guaranteeing atomicity is a hard problem](#Guaranteeing-atomicity-is-a-hard-problem)
  + [A way to achieve atomicity](#A-way-to-achieve-atomicity)
* [Atomicity in a distributed system](#Atomicity-in-a-distributed-system)

The second challenging aspect of transactions, and especially distributed transactions, is **atomicity**.

One of the benefits of grouping operations inside a transaction is the guarantee that either all of them will be performed, or none of them will be. As a result, the application developer does not need to think about scenarios of **partial failures**, where the transaction fails after some of the operations were already performed.

> Similar to the *isolation* guarantees, the *atomicity* guarantee makes it easier to develop applications. It delegates some of the complexity around handling these situations to the persistence layer, e.g., to the datastore used by the application that provides *atomicity* guarantees.

Let’s see why *atomicity* is hard to achieve in general, and how it is even more difficult in distributed systems.

## Guaranteeing atomicity is a hard problem[#](#Guaranteeing-atomicity-is-a-hard-problem)

Guaranteeing *atomicity* is hard in general, and not only in distributed systems.

The reason is that components can fail unexpectedly regardless of whether they are software or hardware components.

According to Pillai et al., “Even the simple act of writing some bytes to a file requires extra work to ensure it will be performed in an atomic way and the file will not end up in a corrupted state if the disk fails while executing part of the operation”.

### A way to achieve atomicity[#](#A-way-to-achieve-atomicity)

One common way of achieving atomicity, in this case, is through **journalling** or **write-ahead** logging. In this technique, metadata about the operation are first written to a separate file, along with markers that denote whether an operation has been completed or not.

Based on this data, the system can identify which operations were in progress when a failure happened, and drive them to completion either by undoing their effects and aborting them, or by completing the remaining part and committing them. This approach is used extensively in file systems and databases.

## Atomicity in a distributed system[#](#Atomicity-in-a-distributed-system)

The issue of *atomicity* in a distributed system becomes even more complicated because components (nodes in this context) are separated by the network that is slow and unreliable.

Furthermore, we do not only need to make sure that an operation is performed atomically in a node. In most cases, we need to ensure that an operation is performed atomically across multiple nodes. This means that the operation needs to take effect either at *all* the nodes or at *none* of them. This problem is also known as [**atomic commit**](https://en.wikipedia.org/wiki/Atomic_commit).

> The lessons, [2PC](https://www.educative.io/courses/distributed-systems-practitioners/2-phase-commit-2pc), [3PC](https://www.educative.io/courses/distributed-systems-practitioners/3-phase-commit-3pc), and the [quorum-based commit protocol](https://www.educative.io/courses/distributed-systems-practitioners/quorum-based-commit-protocol), will look at how we can achieve *atomicity* in distributed settings. Algorithms are discussed in chronological order so that we can understand what the pitfalls of each algorithm are, and how subsequent algorithms addressed them.

Backlesson

Mark As CompletedComplete

Next

Quiz on Isolation

2-Phase Commit (2PC)

Ask

[Guaranteeing atomicity is a hard problem](#Guaranteeing-atomicity-is-a-hard-problem)

[A way to achieve atomicity](#A-way-to-achieve-atomicity)

[Atomicity in a distributed system](#Atomicity-in-a-distributed-system)

---


# 2-Phase Commit (2PC)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

2-Phase Commit (2PC)

# 2-Phase Commit (2PC)

Let's explore how the 2-phase commit algorithm helps to achieve atomicity.

We'll cover the following...

* [Phases](#Phases)
  + [Voting phase](#Voting-phase)
  + [Commit phase](#Commit-phase)
* [Handling failures](#Handling-failures)
  + [Failure of a participant in the voting phase](#Failure-of-a-participant-in-the-voting-phase)
  + [Failure of a participant in the commit phase](#Failure-of-a-participant-in-the-commit-phase)
  + [Network failures](#Network-failures)
* [Blocking nature of 2-phase commit protocol](#Blocking-nature-of-2-phase-commit-protocol)
* [Usage of the 2-phase commit protocol](#Usage-of-the-2-phase-commit-protocol)
* [Conclusion](#Conclusion)

In a distributed system with an unreliable network, just sending a message to the involved nodes would not be enough for executing a distributed transaction. The node initiating the transaction would not know whether the other nodes committed successfully, or aborted because of some failure, to make a final decision about the result of the transaction.

> When we think about it, the simplest idea is to add another round of messages, and check what the result was on each node. This is essentially the 2-phase commit protocol (2PC).

## Phases[#](#Phases)

The 2-phase commit protocol consists of two phases, hence the name.

The protocol contains two different roles. Their names reflect their actual responsibilities in the protocol.

1. The **coordinator** is responsible for coordinating the different phases of the protocol
2. The **participants** correspond to all the nodes that participate in the transaction

> Note that one of the participants could also play the role of the coordinator.

### Voting phase[#](#Voting-phase)

In this phase, the coordinator sends the transaction to all the participants. The participants execute the transaction up to the point where they are supposed to commit.

> In some cases, the operations of each transaction are executed separately and before the voting phase, which starts after all the operations of a transaction has been executed. Agreement protocols like this usually involve some locking protocol as well, so that other concurrent transactions cannot make participants that have already voted change their mind on whether they can commit or not. For example, the *2-phase commit* protocol can be combined with the *2-phase locking* protocol.

Then, participants respond to the coordinator with a vote that shows if the transaction’s operations are executed successfully (“Yes” vote) or there is some error that means the transaction cannot be committed (“No” vote).

Now that you’ve seen how 2PC can be paired with locking, why would combining 2PC with 2-phase locking help prevent participants from changing their vote, and what risk does this combination still leave unaddressed? Provide your answer in the widget given below.

Want to know the correct answer?

Why Pair 2PC With 2PL?

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

### Commit phase[#](#Commit-phase)

In this phase, the coordinator gathers all the votes from the participants. If all the votes are “Yes”, then the coordinator messages the participants again with an instruction to commit the transaction.

Otherwise, if at least one vote is “No”, the coordinator instructs the participants to abort the transaction. Finally, the participants reply with an acknowledgment and close this phase.

> The fact that a unanimous positive vote is needed for a commit means that the transaction will either commit to all the participants, or will be aborted to all of them (*atomicity* property).

The *coordinator* and the *participants* make use of a **write-ahead-log**, where they persist their decisions during the various steps so that they can recover in case of a failure.

The coordinator also uses a **timeout** when waiting for the responses from the first phase. If the timeout expires, the coordinator interprets this timeout as a No vote and considers the node as failed.

On the other hand, the *participants* do not apply any timeouts while waiting for the coordinator’s messages, since that could lead to participants reaching different conclusions due to timing issues.

The following illustration shows what this flow looks like.

Created with Fabric.js 3.6.6

1 / 12

There are three nodes in the system

Created with Fabric.js 3.6.6

1 / 12

Coordinator sends Prepare TX message to participants

Created with Fabric.js 3.6.6

1 / 12

Participant A runs the transaction and logs the vote

Created with Fabric.js 3.6.6

1 / 12

Participant B runs the transaction and logs the vote

Created with Fabric.js 3.6.6

1 / 12

Participant A returns its vote

## Handling failures[#](#Handling-failures)

Since the happy path is straightforward, let’s examine how the protocol handles various kinds of failures.

### Failure of a participant in the voting phase[#](#Failure-of-a-participant-in-the-voting-phase)

If a participant fails in the voting phase before replying to the coordinator, the coordinator will timeout waiting and assume a *No* vote on behalf of this participant.

This means that the protocol will end up aborting the transaction.

### Failure of a participant in the commit phase[#](#Failure-of-a-participant-in-the-commit-phase)

In this scenario, a participant votes in the voting phase but then fails before it receives the message from the coordinator and completes the transaction (either by committing or abort).

In this case, the protocol will conclude without this node. If this node recovers, later on, it will identify that pending transaction and communicate with the *coordinator* to find out what the result was, and conclude it in the same way.

So, if the result of the transaction is successful, any crashed participant will eventually find out upon recovery and commit it. The protocol does not allow aborting it unilaterally. Thus, *atomicity* is maintained.

> Some readers may have noticed that there is a chance that the participants may fail at the point they try to commit the transaction and break their promise, e.g., because they are out of disk space. Indeed, this is true. Thus, participants have to make the minimum work possible as part of the commit phase to avoid this. For example, the participants can write all the necessary data on the disk during the first phase so that they can signal a transaction is committed by doing minimal work during the second phase (e.g., flipping a bit).

### Network failures[#](#Network-failures)

Network failures have similar results to those described previously, since timeouts make them equivalent to node failures.

> Even though a 2-phase commit can handle all the aforementioned failures gracefully, there’s a single point of failure: the coordinator.

## Blocking nature of 2-phase commit protocol[#](#Blocking-nature-of-2-phase-commit-protocol)

Because of the blocking nature of the protocol, failures of the coordinator at specific stages of the protocol can bring the whole system to a halt. More specifically, if a coordinator fails after sending a prepared message to the participants, the participants will block. The participants will wait for the coordinator to recover and find out the outcome of the transaction, so that they commit or abort it as needed.

This means that failures of the coordinator can decrease the *availability* of the system significantly. Moreover, if the data from the coordinator’s disk cannot be recovered (e.g., due to disk corruption), the result of pending transactions cannot be discovered, and manual intervention might be needed to unblock the protocol.

## Usage of the 2-phase commit protocol[#](#Usage-of-the-2-phase-commit-protocol)

Despite the blocking nature of the protocol, the 2-phase commit is widely used. A specification, called the [**eXtended Architecture (XA**)](https://en.wikipedia.org/wiki/X/Open_XA), has also been released.

In this specification, each of the participant nodes is referred to as resources, and they must implement the interface of a resource manager.

The specification also defines the concept of a **transaction manager** that acts as the coordinator that starts, coordinates, and ends transactions.

## Conclusion[#](#Conclusion)

The 2PC protocol satisfies the *safety* property that ensures all *participants* always arrive at the same decision (*atomicity*). However, it does not satisfy the liveness property that implies it will always make progress.

Backlesson

Mark As CompletedComplete

Next

Hard to Guarantee Atomicity

3-Phase Commit (3PC)

Ask

[Phases](#Phases)

[Voting phase](#Voting-phase)

[Commit phase](#Commit-phase)

[Handling failures](#Handling-failures)

[Failure of a participant in the voting phase](#Failure-of-a-participant-in-the-voting-phase)

[Failure of a participant in the commit phase](#Failure-of-a-participant-in-the-commit-phase)

[Network failures](#Network-failures)

[Blocking nature of 2-phase commit protocol](#Blocking-nature-of-2-phase-commit-protocol)

[Usage of the 2-phase commit protocol](#Usage-of-the-2-phase-commit-protocol)

[Conclusion](#Conclusion)

---


# 3-Phase Commit (3PC)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

3-Phase Commit (3PC)

# 3-Phase Commit (3PC)

In this lesson, we will look into how the 3-phase commit protocol solves the problem of the 2-phase commit protocol.

We'll cover the following...

* [The problem with 2-phase commit protocol](#The-problem-with-2-phase-commit-protocol)
* [Tackling the 2PC problem with 3-phase commit protocol](#Tackling-the-2PC-problem-with-3-phase-commit-protocol)
* [Benefit of 3PC](#Benefit-of-3PC)
* [Network partition failure in 3PC](#Network-partition-failure-in-3PC)
* [Conclusion](#Conclusion)

## The problem with 2-phase commit protocol[#](#The-problem-with-2-phase-commit-protocol)

As we described [previously](https://www.educative.io/collection/page/10370001/4891237377638400/5066587856437248#blocking-nature-of-2-phase-commit-protocol), the main bottleneck of the 2-phase commit protocol was failures of the coordinator leading the system to a blocked state.

Ideally, we would like the *participants* to be able to take the lead in some way and continue the execution of the protocol in this case, but this is not so easy.

The underlying reason is the fact that in the commit phase, the *participants* are not aware of the state of the other participants—only the *coordinator* is So, taking the lead without waiting for the coordinator can result in breaking the *atomicity* property.

For instance, imagine the following scenario: in the commit phase of the protocol, the coordinator manages to send a commit (or abort) message to one of the participants but then fails, and this participant also fails. If one of the other participants takes the lead, it will only be able to query the live participants. So, it will be unable to make the right decision without waiting for the failed participant (or the coordinator) to recover.

## Tackling the 2PC problem with 3-phase commit protocol[#](#Tackling-the-2PC-problem-with-3-phase-commit-protocol)

The 2-phase commit problem could be tackled by splitting the first round (voting phase) into 2 sub-rounds, where the coordinator first communicates the votes result to the nodes, waits for an acknowledgment, and then proceeds with the commit or abort message.

In this case, the participants would know the result from the votes and complete the protocol independently in case of a coordinator failure. This is essentially the 3-phase commit protocol (3PC).

> Wikipedia contains a detailed description of the various stages of the [protocol](https://en.wikipedia.org/wiki/Three-phase_commit_protocol) and a nice visual demonstration. Feel free to refer to this resource for additional study on the protocol.

## Benefit of 3PC[#](#Benefit-of-3PC)

The main benefit of this protocol is that the coordinator stops being a single point of failure.

In case of a coordinator failure, the participants are able to take over and complete the protocol.

A participant taking over can commit the transaction if it receives a **prepare-to-commit**, knowing that all the participants have voted “Yes”. If it does not receive a prepare-to-commit, it can abort the transaction, knowing that no participant has committed, without all the participants receiving a prepare-to-commit message first.

As a result, the 3PC protocol increases *availability* and prevents the coordinator from being a single point of failure.

> However, this comes at the cost of *correctness*, since the protocol is vulnerable to failures such as network partitions.

## Network partition failure in 3PC[#](#Network-partition-failure-in-3PC)

An example of such a failure case is shown in the following illustration.

Created with Fabric.js 3.6.6

1 / 8

A distributed system with one coordinator and three participants

Created with Fabric.js 3.6.6

1 / 8

Coordinator sends commit messages to all participants

Created with Fabric.js 3.6.6

1 / 8

All participants confirm

Created with Fabric.js 3.6.6

1 / 8

Coordinator sends Prepare to Commit message to all participants

Created with Fabric.js 3.6.6

1 / 8

Participant A receives the prepare message, but a network partition occurs, causing other participants to miss that message

In this example, a network partition occurs at a point where the coordinator manages to send a prepare-to-commit message only to some participants. Meanwhile, the coordinator fails right after this point, so the participants time out and have to complete the protocol on their own.

In this case, one side of the partition has participants that receive a prepare-to-commit and continue with committing the transaction. However, the *participants* at the other side of the partition do not receive a prepare-to-commit message and, thus, unilaterally abort the transaction.

> This can seem like a failure case that is very unlikely to happen. However, the consequences are disastrous if it happens, since the system is at an inconsistent state after the network partition is fixed. The *atomicity* property of the transaction has been violated.

## Conclusion[#](#Conclusion)

The 3PC protocol satisfies the *liveness* property that ensures it will always make progress, at the cost of violating the *safety* property of *atomicity*.

Backlesson

Mark As CompletedComplete

Next

2-Phase Commit (2PC)

Quorum-Based Commit Protocol

Ask

[The problem with 2-phase commit protocol](#The-problem-with-2-phase-commit-protocol)

[Tackling the 2PC problem with 3-phase commit protocol](#Tackling-the-2PC-problem-with-3-phase-commit-protocol)

[Benefit of 3PC](#Benefit-of-3PC)

[Network partition failure in 3PC](#Network-partition-failure-in-3PC)

[Conclusion](#Conclusion)

---


# Quorum-Based Commit Protocol

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quorum-Based Commit Protocol

# Quorum-Based Commit Protocol

Let's probe how the quorum-based protocol solves the problem of the 3-phase commit protocol.

We'll cover the following...

* [The problem with 3-phase commit protocol](#The-problem-with-3-phase-commit-protocol)
* [Coping with the problem](#Coping-with-the-problem)
  + [Sub-protocols in quorum-based commit protocol](#Sub-protocols-in-quorum-based-commit-protocol)
    - [Commit protocol](#Commit-protocol)
    - [Termination protocol](#Termination-protocol)
    - [Merge protocol](#Merge-protocol)
  + [Example](#Example)
* [Conclusion](#Conclusion)

## The problem with 3-phase commit protocol[#](#The-problem-with-3-phase-commit-protocol)

As we observed in the [previous](https://www.educative.io/collection/page/10370001/4891237377638400/5514587942682624#network-partition-failure-in-3pc) lesson, the main issue with the 3PC protocol occurs at the end of the second phase, where a potential network partition can bring the system to an inconsistent state.

This can happen when participants attempt to unblock the protocol by taking the lead without having a picture of the overall system, resulting in a [split-brain](https://en.wikipedia.org/wiki/Split-brain_(computing)) situation.

## Coping with the problem[#](#Coping-with-the-problem)

Ideally, we would like to cope with this network partition without compromising the safety of the protocol. This can be done using a concept we have already learned in this course: a quorum.

This approach is followed by the quorum-based commit protocol.

> This protocol is significantly more complex when compared to the other two protocols we described previously, so we should study the original paper carefully to examine all the possible edge cases. However, we will attempt to give a high-level overview of the protocol in this section.

As we mentioned before, this protocol leverages the concept of a *quorum* to ensure that different sides of a partition do not arrive at conflicting results.

The protocol establishes the concept of a **commit quorum (VC)(V\_C)(VC​)** and an **abort quorum (VA)(V\_A)(VA​)**.

A node can proceed with committing only if a *commit quorum* has been formed, while a node can proceed with aborting only if an *abort quorum* has been formed.

The values of the abort and commit quorums have to be selected so that the following property holds:

VA+VC>VV\_A + V\_C > VVA​+VC​>V

VVV is the total number of participants of the transaction.

> Based on the fact that a node can be in only one of the two quorums, it’s impossible for both quorums to be formed at two different sides of the partition and lead to conflicting results.

### Sub-protocols in quorum-based commit protocol[#](#Sub-protocols-in-quorum-based-commit-protocol)

The quorum-based commit protocol comprises three different sub-protocols used in different cases:

* The **commit** protocol, which is used when a new transaction starts
* The **termination** protocol, which is used when there is a network partition
* The **merge** protocol, which is used when the system recovers from a
  network partition

#### Commit protocol[#](#Commit-protocol)

This protocol is very similar to the 3PC protocol. The only difference is that the coordinator waits for VCV\_CVC​ number of acknowledgments at the end of the third phase to proceed with committing the transaction.

If there is a network partition at this stage, the coordinator can be rendered unable to complete the transaction. In this case, the participants on each side of a partition will investigate whether they can complete the transaction, using the following protocol.

#### Termination protocol[#](#Termination-protocol)

Initially, a (surrogate) coordinator will be selected from amongst the *participants* with a leader election.

> Note that it’s irrelevant which leader election algorithm is used. Even if multiple leaders are elected, the correctness of the protocol is not violated.

The elected coordinator queries the nodes of the partition for their status.

If there is at least one participant that has committed (or aborted), the coordinator commits (or aborts) the transaction, maintaining the *atomicity* property.

If there is at least one participant at the prepare-to-commit state, and at least VCV\_CVC​ participants waiting for the result of the votes, the *coordinator* sends prepare-to-commit to the participants and continues to the next step.

Alternatively, if there’s no participant at the prepare-to-commit state and at least VAV\_AVA​ participants waiting for the results vote, the coordinator sends a prepare-to-abort message.

> Note that this message does not exist in the *commit* protocol, but only in the *termination* protocol.

The last phase of the termination protocol waits for acknowledgments and attempts to complete the transaction in a similar fashion to the commit protocol.

#### Merge protocol[#](#Merge-protocol)

The merge protocol is simple. It includes a leader election amongst the leaders of the two partitions that are merged, and then the execution of the termination protocol we described.

### Example[#](#Example)

Let’s examine what would happen in the network partition example from the [previous](https://www.educative.io/collection/page/10370001/4891237377638400/5514587942682624#network-partition-failure-in-3pc) lesson. We have shown the same illustration below.

Created with Fabric.js 3.6.6

1 / 8

A distributed system with one coordinator and three participants

Created with Fabric.js 3.6.6

1 / 8

Coordinator sends commit messages to all participants

Created with Fabric.js 3.6.6

1 / 8

All participants confirm

Created with Fabric.js 3.6.6

1 / 8

Coordinator sends Prepare to Commit message to all participants

Created with Fabric.js 3.6.6

1 / 8

Participant A receives the prepare message, but a network partition occurs, causing other participants to miss that message

In this case, we have three participants (V=3)(V = 3)(V=3), and we assume that the protocol would use quorums of size VA=2V\_A = 2VA​=2 and VC=2V\_C = 2VC​=2 . As a result, during the network partition, the participant on the left side of the partition is unable to form a commit quorum. On the other hand, the participants on the right side of the partition are able to form an abort quorum, and proceed with aborting the transaction, and assume no more partitions happen.

Later on, when the network partition recovers, the merge protocol executes. The merge protocol ensures that the participant from the left side of the partition also aborts the transaction, since the new coordinator identifies at least one node that aborted the transaction.

The following illustration contains a visualization of this execution. An interesting property of the protocol is that we can tune the values of the quorums VAV\_AVA​, VCV\_CVC​, and effectively adjust the protocol’s tendency to complete a transaction via commit or abort in the presence of a partition.

Created with Fabric.js 3.6.6

1 / 12

A network partition and a coordinator failure has occurred

Created with Fabric.js 3.6.6

1 / 12

On one side of the partition, the participant can’t form a commit quorum and stalls

Created with Fabric.js 3.6.6

1 / 12

On the other side of the partition, a new leader is elected

Created with Fabric.js 3.6.6

1 / 12

New leader inquires the status

Created with Fabric.js 3.6.6

1 / 12

The participant replies that it is waiting

## Conclusion[#](#Conclusion)

The quorum-based commit protocol satisfies the *safety* property that ensures that all participants will always arrive at the same decision (*atomicity*). It does not satisfy the *liveness* property that ensures that it will always make progress, since there are always degenerate, extreme failure cases (e.g., multiple, continuous, and small partitions).
However, the quorum-based commit protocol is much more resilient that 2PC and other protocols, and can make progress in the most common types of failures.

Backlesson

Mark As CompletedComplete

Next

3-Phase Commit (3PC)

Quiz on Atomicity

Ask

[The problem with 3-phase commit protocol](#The-problem-with-3-phase-commit-protocol)

[Coping with the problem](#Coping-with-the-problem)

[Sub-protocols in quorum-based commit protocol](#Sub-protocols-in-quorum-based-commit-protocol)

[Commit protocol](#Commit-protocol)

[Termination protocol](#Termination-protocol)

[Merge protocol](#Merge-protocol)

[Example](#Example)

[Conclusion](#Conclusion)

---


# Quiz on Atomicity

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Atomicity

# Quiz on Atomicity

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

What is the main limitation of the 2-phase commit protocol?

A.

There is a single point of failure, which is the coordinator

B.

Network partition failure

---

1 / 3

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Quorum-Based Commit Protocol

How It All Fits Together

Ask

---


# How It All Fits Together

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

How It All Fits Together

# How It All Fits Together

Let's inspect how we can combine all of the distributed transaction guarantees.

We'll cover the following...

* [Guarantees distributed systems should provide](#Guarantees-distributed-systems-should-provide)
  + [Consistency and durability guarantees](#Consistency-and-durability-guarantees)
  + [Atomicity and isolation guarantees](#Atomicity-and-isolation-guarantees)
* [Combining algorithms to guarantee all properties](#Combining-algorithms-to-guarantee-all-properties)
* [Complexity in algorithms](#Complexity-in-algorithms)
  + [Algorithms that work for both systems](#Algorithms-that-work-for-both-systems)

As we have described often, transactions need to provide some guarantees if applications are to benefit from them.

**Distributed transactions** need to provide similar guarantees.

## Guarantees distributed systems should provide[#](#Guarantees-distributed-systems-should-provide)

Some basic guarantees commonly used are contained in the ***ACID*** acronym that we analyzed earlier.

### Consistency and durability guarantees[#](#Consistency-and-durability-guarantees)

> *Consistency* and *durability* do not require very different treatment in a distributed setting when compared to a centralized, single-node system. For *durability*, it’s enough for the data to be stored in non-volatile storage before it is acknowledged by the client.

To achieve *durability* in a distributed system, we should store data in more than one replicas before acknowledging, so that the system can survive the failures of a single node.

To achieve *consistency*, the system can introduce some additional read and write operations in the transaction’s context to guarantee the preservation of application consistency. These operations may be automatically generated, such as referential integrity constraints from foreign keys or cascades, or they may be defined by the application, e.g., via triggers.

### Atomicity and isolation guarantees[#](#Atomicity-and-isolation-guarantees)

The guarantees of *atomicity* and *isolation* are more challenging to preserve, and we previously analyzed some of the algorithms we can use for this purpose.

The course examined some algorithms that can help preserve *isolation* across transactions, and some algorithms that can help preserve *atomicity* in a distributed system.

## Combining algorithms to guarantee all properties[#](#Combining-algorithms-to-guarantee-all-properties)

The algorithms must combine to guarantee all properties: *atomicity*, *consistency*, *isolation*, and *durability*.

Some combinations of these algorithms might be easier to implement in practice because of their common characteristics. For example, *two-phase locking* has very similar characteristics to *two-phase commit*, so it’s easier to understand how they can be combined.

Spanner is an example of a system that uses a combination of these two techniques to achieve *atomicity* and *isolation*, as explained later in the course.

## Complexity in algorithms[#](#Complexity-in-algorithms)

Looking at the previous algorithms presented, it is easy to realize that some of them introduce either brittleness (e.g., two-phase commit) or a lot of additional complexity to a system (e.g., quorum-based commit).

### Algorithms that work for both systems[#](#Algorithms-that-work-for-both-systems)

The algorithms presented for *isolation* can be used in both centralized and distributed systems. However, their use in a distributed system has several additional implications.

For example, *two-phase locking* requires the use of distributed locks, which is something that is not trivial to implement in a distributed system, as we will explain later in the course.

Optimistic techniques, such as snapshot isolation, require a lot of data transfer between different nodes in a distributed system, which has adverse effects on performance.

> As a consequence, using transactions in a distributed system comes at a higher cost compared to a centralized system. So, systems that do not have a strong need for distributed systems can be designed to operate safely without them.

That is also one of the reasons why many distributed databases either do not provide full support for ACID transactions or force the user to opt in to use them explicitly.

Backlesson

Mark As CompletedComplete

Next

Quiz on Atomicity

Long-Lived Transactions and Sagas

Ask

[Guarantees distributed systems should provide](#Guarantees-distributed-systems-should-provide)

[Consistency and durability guarantees](#Consistency-and-durability-guarantees)

[Atomicity and isolation guarantees](#Atomicity-and-isolation-guarantees)

[Combining algorithms to guarantee all properties](#Combining-algorithms-to-guarantee-all-properties)

[Complexity in algorithms](#Complexity-in-algorithms)

[Algorithms that work for both systems](#Algorithms-that-work-for-both-systems)

---


# Long-Lived Transactions and Sagas

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Long-Lived Transactions and Sagas

# Long-Lived Transactions and Sagas

In this lesson, we will explore long-lived transactions and saga transactions. We will also look into the benefits that sagas provide over distributed transactions.

We'll cover the following...

* [Long-lived transactions](#Long-lived-transactions)
  + [Examples of LLTs](#Examples-of-LLTs)
* [Saga](#Saga)
  + [Benefits of the saga](#Benefits-of-the-saga)
    - [Example scenario](#Example-scenario)
      * [Cases where isolation is required](#Cases-where-isolation-is-required)
* [Providing isolation at the application layer](#Providing-isolation-at-the-application-layer)
  + [Semantic lock](#Semantic-lock)
  + [Commutative updates](#Commutative-updates)
  + [Re-ordering the structure of the saga](#Re-ordering-the-structure-of-the-saga)

As explained [previously](https://www.educative.io/courses/distributed-systems-practitioners/achieving-full-serializable-snapshot-isolation), achieving complete **isolation** between transactions is relatively expensive.

The system either has to maintain locks for each transaction and potentially block other concurrent transactions from making progress, or abort some transactions to maintain **safety**, which leads to some wasted effort.

Furthermore, the longer the duration of a transaction is the bigger the impact of these mechanisms is expected to be on the overall throughput.

There is also a positive feedback cycle: using these mechanisms can cause transactions to take longer, which can increase the impact of these mechanisms.

## Long-lived transactions[#](#Long-lived-transactions)

There is a specific class of transactions, called ***long-lived transactions (LLT)***.

These are transactions that by their nature have a longer duration in the order of hours or even days, instead of milliseconds. This can happen because this transaction processes a large amount of data, requires human input to proceed, or needs to communicate with third party systems that are slow.

### Examples of LLTs[#](#Examples-of-LLTs)

* Batch jobs that calculate reports over big datasets
* Claims at an insurance company, containing various stages that require
  human input
* An online order of a product that spans several days from order to
  delivery

As a result, running these transactions using the common concurrent mechanisms degrades **performance** significantly, since they need to hold resources for long periods of time, while not operating on them.

Sometimes, long-lived transactions do not really require full *isolation* between each other, but they still need to be *atomic*, so that *consistency* is maintained under partial failures. Thus, researchers came up with a new concept: the **saga**.

## Saga[#](#Saga)

The *saga* is a sequence of transactions T1T\_1T1​, T2T\_2T2​, …, TNT\_NTN​ that can be interleaved with other transactions.

However, it’s guaranteed that either all of the transactions will succeed, or none of them will, maintaining the *atomicity* guarantee.

Each transaction TiT\_iTi​ is associated with a so-called compensating transaction CiC\_iCi​, that is executed in case a rollback is needed.

### Benefits of the saga[#](#Benefits-of-the-saga)

The concept of *saga* transactions can be really useful in distributed systems. As demonstrated in the previous sections, distributed transactions are generally hard and can only be achieved by making compromises on *performance* and *availability*.

There are cases where we can use a saga transaction instead of a distributed transaction. This will satisfy all of our business requirements while keeping our systems loosely coupled and achieving good *availability* and *performance*.

#### Example scenario[#](#Example-scenario)

Let’s imagine we are building an e-commerce application, where every order of a customer requires several discrete steps: credit card authorization, checking warehouse inventory, item shipping, invoice creation and delivery, etc.

* One approach could be to perform a distributed transaction across all these systems for every order. However, in this case, the failure of a single component (i.e., the payment system) could potentially bring the whole system to a halt.
* An alternative, leveraging the saga pattern, would be to model the order operation as a saga operation, consisting of all these sub-transactions, where each of them is associated with a compensating transaction.

For example, debiting a customer’s bank account could have a compensating transaction that would give a refund. Then, we can build the order operation as a sequential execution of these transactions, as shown in the following transactions. In case any of these transactions fail, we can rollback the transactions that have been executed and run their corresponding compensating transactions.

Example of a saga transaction

> There might still be cases where some form of *isolation* is needed.

In the example above, orders from different customers about the same product might share some data, which can lead to interference between each other.

##### Cases where isolation is required[#](#Cases-where-isolation-is-required)

Think about the scenario of two concurrent orders A and B, where A has reserved the last item from the warehouse. As a result of this, order B fails at the first step and is rejected because of zero inventory. Later on, order A also fails at the second step because the customer’s card does not have enough money. Then, the associated compensating transaction runs, returning the reserved item to the warehouse.

This would mean that an order was rejected while it could have been processed normally. Of course, this violation of isolation does not have severe consequences. However, in some cases the consequences might be more serious, e.g. customers being charged without receiving a product.

> To prevent these scenarios, some form of isolation can be introduced at the application layer.

## Providing isolation at the application layer[#](#Providing-isolation-at-the-application-layer)

Previous research on this topic proposed some concrete techniques that are **countermeasures to isolation anomalies**.

Some of these techniques are as follows:

### Semantic lock[#](#Semantic-lock)

The use of a semantic lock essentially signals that some data items are currently in process and should be treated differently or not accessed at all. The final transaction of a *saga* takes care of releasing this lock and resetting the data to its normal state.

### Commutative updates[#](#Commutative-updates)

The use of commutative updates that have the same effect regardless of their order of execution. This can help mitigate cases that are otherwise susceptible to lost update phenomena.

### Re-ordering the structure of the saga[#](#Re-ordering-the-structure-of-the-saga)

Re-order the saga structure so that a transaction called a **pivot transaction** delineates a boundary between transactions that can fail and those that can’t.

In this way, transactions that can’t fail, but could lead to serious problems if rolled back due to failures of other transactions, can be moved after the *pivot transaction*.

An example of this is a transaction that increases the balance of an account. This transaction could have serious consequences if another concurrent *saga* reads this increase in the balance, but then the previous transaction is rolled back. Moving this transaction after the *pivot transaction* means that it will never be rolled back, since only all the transactions after the *pivot transaction* can succeed.

> We can apply these techniques selectively in cases where they are needed. However, they introduce significant complexity and move some of the burdens back to the application developers; the developers have to think again about all the possible failures and design accordingly. We need to consider trade-offs when choosing between using saga transactions or leveraging the transaction capabilities of the underlying datastore.

Backlesson

Mark As CompletedComplete

Next

How It All Fits Together

Defining the Consensus Problem

Ask

[Long-lived transactions](#Long-lived-transactions)

[Examples of LLTs](#Examples-of-LLTs)

[Saga](#Saga)

[Benefits of the saga](#Benefits-of-the-saga)

[Example scenario](#Example-scenario)

[Cases where isolation is required](#Cases-where-isolation-is-required)

[Providing isolation at the application layer](#Providing-isolation-at-the-application-layer)

[Semantic lock](#Semantic-lock)

[Commutative updates](#Commutative-updates)

[Re-ordering the structure of the saga](#Re-ordering-the-structure-of-the-saga)

---


# Defining the Consensus Problem

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Defining the Consensus Problem

# Defining the Consensus Problem

Let's look into the consensus and its use-cases.

We'll cover the following...

* [Formal definition](#Formal-definition)
* [Some use-cases of consensus](#Some-use-cases-of-consensus)
  + [Leader election](#Leader-election)
    - [Example](#Example)
  + [Distributed locking](#Distributed-locking)
  + [Atomic broadcast](#Atomic-broadcast)

Most problems in distributed systems space share a common trait that characterizes most, if not all, of them.

It’s the fact that the various nodes of a distributed system try to reach an agreement on a specific thing.

* In the case of a distributed transaction, it’s whether a transaction has been committed or not.
* In the case of message delivery, it’s whether a message has been delivered or not.

This underlying property is common in many more problems in the distributed systems space.

As a result, researchers formally defined this problem and researched possible solutions, since these can then be used as building blocks for more complicated problems. This is known as the **consensus problem**.

## Formal definition[#](#Formal-definition)

Assume we have a distributed system that consists of k nodes (n1n\_1n1​, n2n\_2n2​, …, nkn\_knk​), where each one can propose a different value viv\_ivi​.

*Consensus* is the problem of making all these nodes agree on a single value vvv.

The following properties must also be satisfied:

* **Termination**: Every non-faulty node must eventually decide.
* **Agreement**: The final decision of every non-faulty node must be identical.
* **Validity**: The agreed value must have been proposed by one of the nodes.

Consensus: there are more votes for X, so everyone agrees on X

## Some use-cases of consensus[#](#Some-use-cases-of-consensus)

As explained before, consensus lies beneath many other common problems in the distributed systems space. We will now visit some of them and discuss how they relate to the consensus problem.

### Leader election[#](#Leader-election)

It is a widespread problem where the nodes that are part of a distributed system need to elect one node from amongst them to act as their leader, and coordinate the operation of the whole system.

#### Example[#](#Example)

An example of this problem is the **primary-backup replication** scheme.

This scheme is based on the fact that one node, designated as primary, will be responsible for performing operations that update data. The other nodes, designated as secondaries, will follow up with the same operations.

However, the system first needs to select the primary node through a process called **leader election**. Since all the nodes are practically agreeing on a single value, the identity of the leader, this problem can easily be modeled as a *consensus problem*.

### Distributed locking[#](#Distributed-locking)

One more common problem is **distributed locking**. Most distributed systems receive multiple concurrent requests and need to perform concurrency control to prevent data inconsistencies because of interference between these requests.

One of these concurrency control methods is **locking**. However using locking in the context of a distributed system comes with a lot of edge-cases that add a lot of risks.

Of course, *distributed locking* can also be modeled as a *consensus problem*, where the nodes of the system agree on a single value, which is the node that holds the lock.

### Atomic broadcast[#](#Atomic-broadcast)

Another commonly cited problem is **atomic broadcast**, which is concerned with allowing a set of nodes to concurrently broadcast messages while ensuring that all destinations consistently deliver them in the same sequence despite the possible presence of faulty nodes.

This problem is also equivalent to consensus, as also demonstrated in previous research by Chandra et al. and Defago et al..

> The reason we described these problems and demonstrated how they could be modelled as a consensus problem is so that we can appreciate the value of this abstraction, and understand that solving the consensus problem can provide solutions to many more problems.

Backlesson

Mark As CompletedComplete

Next

Long-Lived Transactions and Sagas

FLP Impossibility

Ask

[Formal definition](#Formal-definition)

[Some use-cases of consensus](#Some-use-cases-of-consensus)

[Leader election](#Leader-election)

[Example](#Example)

[Distributed locking](#Distributed-locking)

[Atomic broadcast](#Atomic-broadcast)

---


# The Paxos Algorithm

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Paxos Algorithm

# The Paxos Algorithm

In this lesson, we will examine how the Paxos algorithm solves the consensus problem.

We'll cover the following...

* [Story of the Paxos algorithm](#Story-of-the-Paxos-algorithm)
  + [Roles](#Roles)
    - [Proposer](#Proposer)
    - [Acceptor](#Acceptor)
    - [Learners](#Learners)
  + [Phases](#Phases)
    - [Phase 1 (a)](#Phase-1-a)
    - [Phase 1 (b)](#Phase-1-b)
    - [Phase 2 (a)](#Phase-2-a)
    - [Phase 2 (b)](#Phase-2-b)
  + [Example](#Example)
* [Basic ingredient of the Paxos protocol](#Basic-ingredient-of-the-Paxos-protocol)

Some algorithms could arguably be applied as solutions to the **consensus problem**.

For instance, the [2-phase commit](https://www.educative.io/courses/distributed-systems-practitioners/2-phase-commit-2pc) protocol could be used, where the **coordinator** would drive the voting process.

However, such a protocol would have very limited fault tolerance, since the failure of a single node (the *coordinator*) could bring the whole system to a halt.

The obvious next step is to allow multiple nodes to inherit the role of the *coordinator* in these failure cases. This would then mean that there might be multiple primaries that might produce conflicting results.

> This phenomenon is demonstrated in the lesson [multi-primary replication](https://www.educative.io/courses/distributed-systems-practitioners/multi-primary-replication-algorithm) and the [3-phase commit](https://www.educative.io/courses/distributed-systems-practitioners/3-phase-commit-3pc) lesson.

One of the first algorithms that could solve the *consensus problem* safely under these failures is the **Paxos algorithm**.

## Story of the Paxos algorithm[#](#Story-of-the-Paxos-algorithm)

This algorithm guarantees that the system will come to an agreement on a single value and tolerate the failure of any number of nodes (potentially all of them) as long as more than half the nodes work properly at any time, which is a significant improvement.

Funnily enough, this algorithm was invented by Leslie Lamport during his attempt to prove that this is actually impossible!

He decided to explain the algorithm in terms of a parliamentary procedure used in an ancient, fictional Greek island called **Paxos**.

Despite being elegant and highly entertaining, this first paper was not well received by the academic community, who found it extremely complicated and could not discern its applicability in the field of distributed systems.

A few years later and after several successful attempts to use the algorithm in real-life systems, Lamport decided to publish a second paper, explaining the algorithm in simpler terms and demonstrating how it can be used to build an actual, highly available distributed system.

A historical residue of all this is the fact that the Paxos algorithm is regarded as a rather complicated algorithm until today. Hopefully, this section will help dispel this myth.

### Roles[#](#Roles)

The Paxos algorithm defines three different roles:

* Proposers
* Acceptors
* Learners

Every node in the system can potentially play multiple roles.

#### Proposer[#](#Proposer)

A *proposer* is responsible for proposing values (potentially received from clients’ requests) to the *acceptors* and trying to persuade them to accept their value to arrive at a common decision.

#### Acceptor[#](#Acceptor)

An *acceptor* is responsible for receiving these proposals and replying with their decision on whether this value can be chosen or not.

#### Learners[#](#Learners)

The *learners* are responsible for learning the outcome of the consensus, storing it (in a replicated way) and potentially acting on it, by either notifying clients about the result or performing actions.

The following illustration contains a visual overview of these roles and how they interact with the clients.

An overview of the paxos protocol

### Phases[#](#Phases)

The Paxos algorithm is split into two phases, each of which contains two parts:

#### Phase 1 (a)[#](#Phase-1-a)

A *proposer* selects a number NNN and sends a prepare request with this number prepare(NNN) to at least a majority of the *acceptors*.

NNN is the **round Identifier**, which has two interesting properties:

1. The round identifier has to be bigger than any previous round identifier used by any other proposer in our Paxos cluster. This is achieved by incrementing a counter `i++`.
2. Make round identifiers unique because we never want two proposers to come up with the same round identifier and reuse it. Reusing identifiers would break the protocol. To achieve this we append `node_number` to the counter.

> We will use a function `cat(i++, node_number)` that appends `node_number` to the counter `i++`.

#### Phase 1 (b)[#](#Phase-1-b)

When receiving a prepare request, an *acceptor* has the following options:

* If it has not already responded to another prepare request of a higher number NNN, it responds to the request with a promise not to accept any more proposals that are numbered less than NNN. It also returns the highest-numbered proposal it has accepted, if any (Note: the definition of a proposal follows).
* Otherwise, if it has already accepted a prepare request with a higher number, it rejects this prepare request. This ideally gives a hint to the proposer about the number of the other prepare request it has already responded to.

#### Phase 2 (a)[#](#Phase-2-a)

If the *proposer* receives a response to its prepare(NNN) requests from a majority of *acceptors*, then it sends an accept(NNN, vvv) request to these *acceptors* for a proposal numbered NNN with a value vvv. The value is selected according to the following logic:

* If any of the *acceptors* had already accepted another proposal and included that in its response, then the *proposer* uses the value of the highest-numbered proposal among these responses. Essentially, this means that the *proposer* attempts to bring the latest proposal to conclusion.
* Otherwise, if none of the *acceptors* had accepted any other proposal, then the *proposer* is free to select any desired value. This value is usually selected based on the clients’ requests.

#### Phase 2 (b)[#](#Phase-2-b)

If the *acceptor* receives an accept(NNN, vvv) request for a proposal numbered NNN, it accepts the proposal, unless it has already responded to a prepare(kkk) request of a higher number (k>Nk > Nk>N).

Created with Fabric.js 3.6.6

1 / 12

Assuming we have three computers in a distributed system

Created with Fabric.js 3.6.6

1 / 12

Computer 1 plays two roles (Propose & Acceptor) while the other two computers are acting as Acceptors

Created with Fabric.js 3.6.6

1 / 12

Phase 1 (a): Proposer proposes a value N, let say i++ gave us 7 in this case, cat appends 7 to the computer number(node\_number) which is 1

Created with Fabric.js 3.6.6

1 / 12

Phase 1 (a): Proposer sends a Prepare request with number N to at least a majority of the Acceptors

Created with Fabric.js 3.6.6

1 / 12

Phase 1 (b): Checking the condition

Furthermore, as the *acceptors* accept proposals, they also announce their acceptance to the *learners*. When a *learner* receives an acceptance from a majority of *acceptors*, it knows that a value has been chosen. This is the most basic version of the Paxos protocol.

Nodes can play multiple roles for practical reasons and this is usually the case in real-life systems.

### Example[#](#Example)

As an example, we can observe that the *proposers* can play the role of *learners* as well, since they receive some of these accept responses anyway, minimize traffic, and improve the **performance** of the system.

During Phase 1 (a) of the protocol, the *proposers* have to select a proposal number NNN. These numbers must be unique for the protocol to maintain its **correctness** properties. This is so that *acceptors* are always able to compare two prepare messages.

This can be achieved in several ways, but the easiest one is to compose these numbers out of two parts, the one being an integer and the second one being a unique identifier of the proposer (i.e., the IP address of the node). In this way, proposers can draw numbers from the same set.

As we have insinuated at the beginning of this section, multiple *proposers* can initiate concurrent prepare requests. The proposer that receives a response to its prepare request from a majority of *acceptors* is essentially elected as the current (but temporary) leader.

As a result, it can proceed with making a proposal request. The value of this proposal will be the chosen one unless a majority of *acceptors* have failed (and did not reply to the proposal) or another leader stepped up, becoming the temporary leader in the meanwhile (in which case, the *acceptors* will reject this proposal).

Now that you’ve seen how proposal numbers are formed, how should a proposer choose N when it restarts after a crash to avoid reusing an old number, and why is appending a node identifier necessary? Provide your answer in the widget given below.

Want to know the correct answer?

Picking Safe Proposal Numbers After Restart

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

## Basic ingredient of the Paxos protocol[#](#Basic-ingredient-of-the-Paxos-protocol)

The basic ingredient of the Paxos protocol is a concept we have already seen, namely the **quorum**. More specifically, the Paxos protocol makes use of majority *quorums*.

A majority *quorum* consists of more than half of the nodes of the system, such as at least k+1k+1k+1 nodes in a system of 2k2k2k nodes.

This protocol guarantees that there can’t be two different proposers that complete both phases of the protocol concurrently because proposers require a majority quorum to proceed with a proposal. As a result, only a single value can be chosen, satisfying the agreement property of consensus.

Backlesson

Mark As CompletedComplete

Next

FLP Impossibility

Intricacies of Paxos

Ask

[Story of the Paxos algorithm](#Story-of-the-Paxos-algorithm)

[Roles](#Roles)

[Proposer](#Proposer)

[Acceptor](#Acceptor)

[Learners](#Learners)

[Phases](#Phases)

[Phase 1 (a)](#Phase-1-a)

[Phase 1 (b)](#Phase-1-b)

[Phase 2 (a)](#Phase-2-a)

[Phase 2 (b)](#Phase-2-b)

[Example](#Example)

[Basic ingredient of the Paxos protocol](#Basic-ingredient-of-the-Paxos-protocol)

---


# Intricacies of Paxos

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Intricacies of Paxos

# Intricacies of Paxos

Let's look into the intricacies of Paxos that happen while solving leader election problem and handling partial failures.

We'll cover the following...

* [Paxos solving leader election problem](#Paxos-solving-leader-election-problem)
  + [Dueling proposers](#Dueling-proposers)
  + [A way to handle dueling proposers](#A-way-to-handle-dueling-proposers)
* [Paxos handling partial failures](#Paxos-handling-partial-failures)

The **Paxos protocol** was considered to be difficult to understand by many people.

One of the reasons for this is the inherent complexity of the **consensus problem**, which in turn originates from the increased concurrency and large state space of distributed systems.

> This lesson will cover some edge cases and how Paxos handles them. Of course, we will not be able to cover all the possible cases since that would be a much bigger undertaking. The examples presented in this lesson will help us understand the basic parts of the protocol and give us a starting point for exploring any other cases we might think of.

For all of the examples presented in this lesson, we will assume that the nodes play all the roles of the protocol, thus being **proposers**, **acceptors**, and **learners** at the same time, to simplify our explanations.

> Keep in mind that this is a realistic assumption since many implementations of the Paxos protocol follow this approach.

## Paxos solving leader election problem[#](#Paxos-solving-leader-election-problem)

*Paxos* can be used to solve the **leader election problem**.

> *Paxos* itself needs to elect a leader in order to reach consensus, which seems like a [catch-22](https://en.wikipedia.org/wiki/Catch-22_(logic)).

The *Paxos protocol* resolves this paradox, by allowing multiple leaders to be elected, thus not needing to reach consensus for the leader itself.

It still has to guarantee that there will be a single decision, even though multiple nodes might be proposing different values.

Let’s examine how *Paxos* achieves that and what are some of the consequences.

When a *proposer* receives a response to a prepare message from a majority of nodes, it considers itself the (temporary) leader and proceeds with a proposal. If no other *proposer* has attempted to become the leader in the meanwhile, its proposal will be accepted. However, if another *proposer* managed to become a leader, the accept requests of the initial node will be rejected. This prevents multiple values to be chosen by the proposals of both nodes.

### Dueling proposers[#](#Dueling-proposers)

The above solution results in a situation, where *proposers* are continuously dueling each other, thus not making any progress, as we can see in the following illustration.

Created with Fabric.js 3.6.6

1 / 12

A distributed system of five nodes

Created with Fabric.js 3.6.6

1 / 12

Node A wants to become a leader, so it sends Prepare message in order to receive votes from majority of the nodes in the quorum

Created with Fabric.js 3.6.6

1 / 12

Node A receives response from majority of the nodes in the quorum, so it considers itself a (temporary) leader

Created with Fabric.js 3.6.6

1 / 12

Before Node A proceeds with the proposal, Node B attempted to become a leader

Created with Fabric.js 3.6.6

1 / 12

Node B receives response from majority of the nodes in the quorum, so it considers itself a (temporary) leader

> vNv\_NvN​ is a value as per the definition of accept (N,v)(N,v)(N,v) request at Phase 2(((b))) of the Paxos protocol in the [The Paxos Algorithm lesson](https://www.educative.io/collection/page/10370001/4891237377638400/5732699023605760#Phase-2-(b)).

There are many ways to avoid getting into this infinite loop.

### A way to handle dueling proposers[#](#A-way-to-handle-dueling-proposers)

The most basic way is to force the *proposers* to use random delays or exponential back-off every time they get their accept messages rejected and have to send a new prepare request. In this way, they give more time to the node that is currently leading to complete the protocol, by making a successful proposal, instead of competing.

## Paxos handling partial failures[#](#Paxos-handling-partial-failures)

Another interesting aspect of the Paxos protocol is how it handles partial failures gracefully, maintaining safety at all times.

In this context, by partial failures, we refer to cases where a node sends a message to multiple nodes (i.e., accept messages as part of [Phase 2.a](https://www.educative.io/collection/page/10370001/4891237377638400/5732699023605760#phase-2-a), and only some of them are delivered either due to node failures or network issues.

Let’s examine an extreme case, where multiple *proposers* attempt to propose different values, but only one of their accept messages gets delivered to the *acceptors* of the majority quorum. The following illustration provides a visualization of the execution of the protocol to aid comprehension.

A Paxos execution with partial failures

* Every row represents a different round of the protocol
* The dashed box shows which nodes were included in the majority quorum of Phase 1.
* The text inside every node displays any proposal that has already been accepted in the form (nnn, vvv), where nnn is the proposal number, and vvv is the value of the proposal.
* The bold text represents the values that have been accepted in that round.

As we can see, every proposer manages to deliver an accept message to only one acceptor at every round.

For the first three rounds, none of the nodes in the majority quorum have accepted any value, so proposers are free to propose their own value.

In rounds four and five, proposers have to propose the value of the highest-numbered proposal that has been accepted by the acceptors included in Phase one’s majority quorum. This is A for round four and B for round five.

As it’s demonstrated for round six, at this point, the behavior depends partially on the quorum that will be used. For example, if the next proposer selects the yellow quorum, value C will be proposed, while value B will be proposed if the green quorum is used instead.

However, there is one important thing to note: as soon as the system recovers from failures and a proposer manages to get a proposal accepted by a majority quorum, then this value is chosen, and it cannot be changed.

The reason is that any subsequent proposer will need to get a majority quorum for Phase 1 of the protocol. This majority will have to contain at least 1 node from the majority that has accepted the aforementioned proposal, thus transferring the accepted proposal to the prospective leader.

Furthermore, it’s guaranteed this will be the highest-numbered proposal, which means any subsequent proposer can only propagate the chosen value to the acceptors that might not have it yet.

Backlesson

Mark As CompletedComplete

Next

The Paxos Algorithm

Paxos in Real Life

Ask

[Paxos solving leader election problem](#Paxos-solving-leader-election-problem)

[Dueling proposers](#Dueling-proposers)

[A way to handle dueling proposers](#A-way-to-handle-dueling-proposers)

[Paxos handling partial failures](#Paxos-handling-partial-failures)

---


# Paxos in Real Life

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Paxos in Real Life

# Paxos in Real Life

Let's look into some details on Paxos that are not covered in the original paper.

We'll cover the following...

* [Towards running multiple instances of Paxos](#Towards-running-multiple-instances-of-Paxos)
* [Paxos returning current state of the system](#Paxos-returning-current-state-of-the-system)
  + [Read operation](#Read-operation)
  + [Leader leases](#Leader-leases)
* [Problem while using multiple instances of Paxos](#Problem-while-using-multiple-instances-of-Paxos)
* [Solution with Multi-Paxos](#Solution-with-Multi-Paxos)
* [Dynamically updating the nodes](#Dynamically-updating-the-nodes)

> As we have seen so far, the **Paxos protocol** is well-specified. However, there are some small details and optimizations that the original paper could not cover. Some of these topics were covered in subsequent papers. This lesson will cover some of these topics as briefly as possible.

## Towards running multiple instances of Paxos[#](#Towards-running-multiple-instances-of-Paxos)

The basic *Paxos protocol* describes how a distributed system of multiple nodes can decide on a single value.

However, just choosing a single value would have limited practical applications on its own.

To build more useful systems, we need to be able to continuously select values.

This can be achieved by running multiple instances of Paxos, where an instance is an execution of the protocol that leads to a decision on a single value. These instances can run independently and in parallel, but they also have to be numbered.

Depending on the functionality needed, there can be several rules applied, such as not returning the result of an instance to the client, unless all the previous instances have been completed as well.

> We will elaborate more on this topic in the [next](https://www.educative.io/collection/page/10370001/4891237377638400/6468611512729600#using-paxos-at-the-consensus-layer) lesson.

## Paxos returning current state of the system[#](#Paxos-returning-current-state-of-the-system)

Another common need is the ability to query the current state of the system.

Of course, the clients of the system learn the chosen values, so they could keep track of the state on their side. But, there will always be cases, where some clients need to retrieve some of the values chosen in the past, i.e. because they are clients that have just been brought into operation.

### Read operation[#](#Read-operation)

*Paxos* should also support **read operations** that return the decisions of previously completed instances alongside write operations that start new instances of the protocol.

These *read operations* have to be routed to the current leader of the system, which is essentially the node that completed successfully the last proposal.

It’s important to note that this node cannot reply to the client using its local copy.

The reason for this is that another node might have done a proposal in the meanwhile (becoming the new leader), thus meaning that the reply will not reflect the latest state of the system.

> This would mean that the read/write consensus operations would not be linearizable. Note that in the context of consensus, operations such as proposals are considered single-object operations. As a result, there is no need for isolation guarantees.

As a result, that node will have to perform a read from a majority of nodes, essentially seeing any potential new proposal from another node.

> We should be able to understand how a majority quorum can guarantee that by now. If not, it would probably be a good idea to revisit the lesson about [quorums](https://www.educative.io/collection/page/10370001/4891237377638400/5694609382965248#quorums) and their intersection properties.

This means that reads can become quite slow since they will have to execute in two phases.

### Leader leases[#](#Leader-leases)

According to Lampson, "An alternative option that works as optimization is to make use of the technique called **leases**.

Using this approach, a node can take a lease, by running a *Paxos* instance, establishing a point in time, until which it’s guaranteed to be considered the leader and no other node can challenge it. This means that this node can then serve read operations locally.

However, one has to take **clock skew** into account in the implementation of this approach and keep in mind it will be safe only if there’s an upper bound in the *clock skew*.

## Problem while using multiple instances of Paxos[#](#Problem-while-using-multiple-instances-of-Paxos)

By the same logic, one could argue that electing a leader in every instance of the Paxos protocol is not as efficient as possible and degrades **performance** significantly under normal conditions without many failures.

Indeed, that is true!

## Solution with Multi-Paxos[#](#Solution-with-Multi-Paxos)

There is a slightly adjusted implementation of *Paxos*, called **Multi-Paxos** by David et al. that mitigates this issue.

In this approach, the node that has performed the last successful proposal is considered the current distinguished proposer. This means that a node can perform a full instance of *Paxos* and then it can proceed straight to the second phase for the subsequent instances, using the same proposal number that has been accepted previously.

The rest of the nodes know which node is currently the leader based on which node made the last successful proposal. They can perform periodic health checks. If they believe this node has crashed, they can initiate a prepare request to perform a successful proposal and become the distinguished proposer.

Essentially, this means that the protocol is much more efficient under stable conditions since it has only one phase. When failures occur, the protocol falls back to plain *Paxos*.

## Dynamically updating the nodes[#](#Dynamically-updating-the-nodes)

Another common need is a way to update the nodes that are members of the system dynamically. The answer to this requirement might sound familiar thanks to the elegance of the protocol; membership information can just be propagated as a new Paxos proposal!

The nodes that are members of the system can have their own way of identifying failures of other nodes (i.e., periodic health checks) and the corresponding policies on when a node should be considered dead. When a node is considered dead, one of the nodes that have identified it can trigger a new Paxos instance. Then it proposes a new membership list, which is the previous one minus the dead node. As soon as this proposal completes, all the subsequent instances of Paxos should make use of the updated membership list.

Backlesson

Mark As CompletedComplete

Next

Intricacies of Paxos

Replicated State Machine via Consensus

Ask

[Towards running multiple instances of Paxos](#Towards-running-multiple-instances-of-Paxos)

[Paxos returning current state of the system](#Paxos-returning-current-state-of-the-system)

[Read operation](#Read-operation)

[Leader leases](#Leader-leases)

[Problem while using multiple instances of Paxos](#Problem-while-using-multiple-instances-of-Paxos)

[Solution with Multi-Paxos](#Solution-with-Multi-Paxos)

[Dynamically updating the nodes](#Dynamically-updating-the-nodes)

---


# Replicated State Machine via Consensus

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Replicated State Machine via Consensus

# Replicated State Machine via Consensus

In this lesson, we will explain how a consensus algorithm could be used to build a replicated state machine.

We'll cover the following...

* [Building a replicated state machine using a consensus algorithm](#Building-a-replicated-state-machine-using-a-consensus-algorithm)
  + [Using Paxos at the consensus layer](#Using-Paxos-at-the-consensus-layer)

At the [beginning](https://www.educative.io/courses/distributed-systems-practitioners/defining-the-consensus-problem) of this chapter, we briefly described how a consensus algorithm could be used to solve a wide variety of problems.

This is not a coincidence since all these problems share a common, fundamental characteristic. This is the fact that they can all be modeled as a **state machine** to some extent. This is also the reason why it’s easier to solve them in a **centralized** setting, but it gets much harder when we want to solve them in a **distributed** setting in order to increase **availability**.

## Building a replicated state machine using a consensus algorithm[#](#Building-a-replicated-state-machine-using-a-consensus-algorithm)

Using a consensus algorithm, we can build a replicated state machine. This is a set of nodes, where each of them is receiving commands and executing them, transitioning between states.

If all the nodes use the same state machine, all we need is to ensure that all the nodes receive the same inputs in the same order, and then we can guarantee that all the nodes will make the same transitions. This would mean that the distributed system would look similar to a single server from the outside.

As a result, one could achieve all the benefits of a distributed system while maintaining a simple programming model.

The following illustration contains a high-level overview of such a system.

A replicated state machine using consensus

The top layer receives requests from the clients. It creates proposals for the consensus layer, which conducts the necessary coordination between the other nodes of the system and propagates the chosen values to the lower layer, which receives these values as inputs and executes the necessary state transitions.

### Using Paxos at the consensus layer[#](#Using-Paxos-at-the-consensus-layer)

Let’s elaborate a bit more on what that would entail, assuming Paxos is used as the consensus layer of the system.

Essentially, the clients would send regular requests to the system, depending on the system’s domain. These requests could be either commands to the system or requests to inspect its internal system.

These requests would be dispatched to the system’s current leader, which will be determined based on previous instances of the consensus.

If a node that is not a leader receives a request, it can return the leader’s address so the client can reroute it.

> When the system is bootstrapped, and no consensus instances have been run yet, the leader can be determined from a configuration file, or the nodes can compete with each other for the leader role.

Every time the leader node receives a new command, it attempts to execute a new instance of consensus, increasing the instance number every time.

Created with Fabric.js 3.6.6

1 / 15

Three Clients and five Nodes running Paxos where Node D is acting as leader

Created with Fabric.js 3.6.6

1 / 15

Client 1 send request R1 to a non-leader Node C

Created with Fabric.js 3.6.6

1 / 15

Node C reply Client 1 with Leader's Id

Created with Fabric.js 3.6.6

1 / 15

Client 1 resends the request R1 to the leader

Created with Fabric.js 3.6.6

1 / 15

The leader runs Paxos instance 1

To achieve satisfactory performance, multiple consensus instances can be run in parallel. However, the necessary serialization must be performed in some places to ensure correctness.

For instance, the lower layer should process the decision of a consensus instance only when it has processed all the previous instances to ensure that all state machines perform the same transitions.

Similarly, the leader should wait after an instance is completed and reply to the associated client only after all the previous instances have been completed.

When the current leader is unstable, and other nodes start making proposals, there might be increased contention, for instance, creating significant delays for any subsequent instances that might have completed.

> A dummy value can be proposed by the nodes in these cases, which essentially represents a no-op, rejecting the client’s operation.

This abstraction of a replicated state machine is quite powerful and could potentially be used to implement solutions for many common problems in the distributed systems area.

Backlesson

Mark As CompletedComplete

Next

Paxos in Real Life

Distributed Transactions via Consensus

Ask

[Building a replicated state machine using a consensus algorithm](#Building-a-replicated-state-machine-using-a-consensus-algorithm)

[Using Paxos at the consensus layer](#Using-Paxos-at-the-consensus-layer)

---


# Distributed Transactions via Consensus

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Distributed Transactions via Consensus

# Distributed Transactions via Consensus

Let's explore how we can solve distributed transactions problems via consensus algorithms despite the differences between the two.

We'll cover the following...

* [The core characteristic of distributed transactions](#The-core-characteristic-of-distributed-transactions)
* [Difference between transaction problem and consensus problem](#Difference-between-transaction-problem-and-consensus-problem)
* [Biggest contribution of a consensus algorithm](#Biggest-contribution-of-a-consensus-algorithm)
  + [Achieving the contribution](#Achieving-the-contribution)
    - [Additional message round](#Additional-message-round)
    - [Removing additional message round](#Removing-additional-message-round)

The introduction of this chapter mentioned that the **consensus problem** is very similar to the **distributed transactions** problem.

However, after studying the **Paxos algorithm**, one might think there seems to be a fundamental conflict between *distributed transactions* and the way *Paxos* solves the *consensus problem*.

## The core characteristic of distributed transactions[#](#The-core-characteristic-of-distributed-transactions)

The core characteristic of distributed transactions is ***atomicity***. Either the relevant update has to be performed in all the nodes, or it should not be performed in any of them.

## Difference between transaction problem and consensus problem[#](#Difference-between-transaction-problem-and-consensus-problem)

However, the *Paxos algorithm* relies on just a majority **quorum** to decide on a value. According to Hadzilacos, “Indeed, the problem of *distributed transactions*, known as **atomic commit**, and the *consensus problem* might be closely related. Still, they are not equivalent”.

* The *consensus problem* mandates that every non-faulty node must reach the same decision, while the *atomic commit problem* requires that all the nodes (faulty or not) must reach the same decision.
* The *atomic commit problem* imposes stricter relationships between votes or proposals and the final decision than the *consensus problem*.
* In *consensus*, the only requirement is that the value that is agreed must have been proposed by at least one of the nodes. In *atomic commit*, a decision can be positive only if all the votes were positive. The decision is also required to be positive if all votes are positive and there are no failures.

> As a result of this difference, one might think that the *Paxos algorithm* does not have anything to offer in the problem space of *distributed transactions*. This is not true, and in this lesson, we will try to illustrate what *Paxos* (and any other *consensus algorithm*) has to offer.

## Biggest contribution of a consensus algorithm[#](#Biggest-contribution-of-a-consensus-algorithm)

One useful contribution of a *consensus algorithm* is that it communicates the **resource managers**’ results back to the **transaction manager**, which requires successful communication for all of them and not just a majority.

However, its true value is storing and transmitting the transaction’s result back to the *resource managers* in a fault-tolerant way so that the failure of a single node (the *transaction manager*) cannot block the system.

### Achieving the contribution[#](#Achieving-the-contribution)

Indeed, there is a very simple way to achieve this goal in the existing **2-phase commit (2PC) protocol**, by leveraging a *consensus algorithm*.

Assuming we make use of *Paxos* as a *consensus algorithm*, we could have the *transaction manager* start a new *Paxos* instance, proposing a value for the result of the transaction, instead of just storing the result locally before sending it back to the *resource managers*.

The proposal value would be either **commit** or **abort**, depending on the previous results of each one of the *resource managers*. This adjustment on its own would make the *2-phase commit protocol* resilient against failures of the *transaction manager* since another node could take the role of the *transaction manager* and complete the protocol. That node would have to read the result of the transaction from any existing *Paxos* instance. If there’s no decision, that node would be free to make an *abort* proposal.

Created with Fabric.js 3.6.6

1 / 14

A distributed system with two resource managers and one transaction manager

Created with Fabric.js 3.6.6

1 / 14

TM creates a Paxos instance

Created with Fabric.js 3.6.6

1 / 14

TM decides and holds the result for T1

Created with Fabric.js 3.6.6

1 / 14

TM sends the result of T1 (commit/abort) to RMs

Created with Fabric.js 3.6.6

1 / 14

Transaction T1 completes

#### Additional message round[#](#Additional-message-round)

The above method is simple and elegant, but it would require adding one more messaging round to the *2-phase commit protocol*.

It’s actually possible to remove the additional message round, trading off some simplicity for increased **performance**.

#### Removing additional message round[#](#Removing-additional-message-round)

We could remove additional message round by essentially “weaving” several instances of *Paxos* in the plain *2-phase commit protocol*, practically obviating the need for a *transaction manager* completely.

More specifically, the *resource managers* would have to send their response to the first phase to a set of ***acceptors***, instead of sending it to the *transaction manager*. This creates a separate *Paxos* instance for every *resource manager* involved in the transaction.

Similarly, the *acceptors* could propagate the chosen values to the *resource managers* directly, instead of doing so indirectly via the *transaction manager*.

The *resource managers* would be responsible for checking that all the *Paxos* instances from the other *resource managers* had a positive result (corresponding to the first phase of *2PC*) to *commit* the transaction.

> A paper titled Consensus on transaction commit examines this relationship between *distributed transactions* and *consensus* and explains this approach in much greater detail, referred to as **Paxos commit**. This paper also demonstrates why *2-phase commit* is essentially a special case of *Paxos commit* with zero tolerance of node failures (f=0f = 0f=0).

Backlesson

Mark As CompletedComplete

Next

Replicated State Machine via Consensus

An introduction to Raft

Ask

[The core characteristic of distributed transactions](#The-core-characteristic-of-distributed-transactions)

[Difference between transaction problem and consensus problem](#Difference-between-transaction-problem-and-consensus-problem)

[Biggest contribution of a consensus algorithm](#Biggest-contribution-of-a-consensus-algorithm)

[Achieving the contribution](#Achieving-the-contribution)

[Additional message round](#Additional-message-round)

[Removing additional message round](#Removing-additional-message-round)

---


# An introduction to Raft

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

An introduction to Raft

# An introduction to Raft

Let's investigate why the Raft algorithm was created when there was already a Paxos algorithm for solving the consensus problem.

We'll cover the following...

* [Motivation](#Motivation)
* [Getting started with Raft](#Getting-started-with-Raft)
  + [Node states](#Node-states)
  + [Preventing two leaders from operating concurrently](#Preventing-two-leaders-from-operating-concurrently)
  + [Terms](#Terms)

## Motivation[#](#Motivation)

**Paxos** has been the canonical solution to the **consensus problem**. However, the initial specification of the algorithm did not cover some aspects that were crucial in implementing the algorithm in practice, some of these aspects were covered in subsequent papers.

The *Paxos algorithm* is also widely considered hard to understand.

As a response to these issues, researchers decided to create a new algorithm with the goals of improved understandability and ease of implementation. This algorithm, proposed by Ongaro et al., is called **Raft**.

> We will briefly examine the *Raft algorithm* in this lesson since it has provided a good foundation for many practical implementations. It nicely demonstrates how the various aspects described before can be consolidated in a single protocol.

## Getting started with Raft[#](#Getting-started-with-Raft)

*Raft* establishes the concept of a **replicated state machine** and the associated replicated log of commands as first-class citizens and supports by default multiple consecutive rounds of *consensus* by default.

It requires a set of nodes that form the **consensus group**, which is referred to as the **Raft cluster**. Each of these nodes can be in one of the three states:

* Leader
* Follower
* Candidate

### Node states[#](#Node-states)

One node is elected the *leader* and is responsible for receiving log entries from clients (proposals) and replicating them to the other ***follower*** nodes to reach *consensus*.

The *leader* is responsible for sending heartbeats to the other nodes in order to maintain its leadership.

Any node that hasn’t heard from the *leader* for a while will assume the *leader* has crashed; it will enter the **candidate** state and attempt to become the *leader* by triggering a new election.

On the other hand, if a previous *leader* identifies another node has gained leadership, it falls back to a *follower* state.

The following illustration illustrates the behavior of the nodes depending on their state.

The states of nodes in Raft

### Preventing two leaders from operating concurrently[#](#Preventing-two-leaders-from-operating-concurrently)

To prevent two leaders from operating concurrently, *Raft* has the temporal concept of **terms**.

### Terms[#](#Terms)

Time is divided into *terms*, which are numbered with consecutive integers.

Each *term* begins with an election where one or more *candidates* attempt to become *leaders*.

To become a *leader*, a *candidate* needs to receive votes from a majority of nodes. Each node votes for at most one node per *term* on a **first-come-first-served** basis. Consequently, at most, one node can win the election for a specific *term* since two different majorities would conflict in at least one node.

If a *candidate* wins the election, it serves as the *leader* for the rest of the *term*.

> Any *leader* from previous terms will not be able to replicate any new log entries across the group since the voters of the new *leader* will be rejecting its requests, and it will eventually discover it has been deposed.

If none of the *candidates* manages to get a majority of votes in a *term*, this *term* ends with no *leader*, and a new *term* (with a new election) begins straight after.

Backlesson

Mark As CompletedComplete

Next

Distributed Transactions via Consensus

Communication among Raft Nodes

Ask

[Motivation](#Motivation)

[Getting started with Raft](#Getting-started-with-Raft)

[Node states](#Node-states)

[Preventing two leaders from operating concurrently](#Preventing-two-leaders-from-operating-concurrently)

[Terms](#Terms)

---


# Communication among Raft Nodes

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Communication among Raft Nodes

# Communication among Raft Nodes

Let's explore how Raft nodes communicate, what problem occurs, and how Raft solves this problem.

We'll cover the following...

* [Communication mechanism](#Communication-mechanism)
* [Divergence among nodes](#Divergence-among-nodes)
* [Resolving divergence](#Resolving-divergence)
* [What happens when a leader crashes before committing an entry?](#What-happens-when-a-leader-crashes-before-committing-an-entry)

## Communication mechanism[#](#Communication-mechanism)

Nodes communicate via **remote procedure calls (RPCs)** and *Raft* has two basic *RPC* types:

* **RequestVote**: Sent by *candidates* during an election
* **AppendEntries**: Sent by *leaders* to replicate log entries and provide a heartbeat form

The commands are stored in a log replicated to all the nodes of the cluster.

The log entries are numbered sequentially, and they contain the *term* in which they were created and the associated command for the state machine, as shown in the following illustration.

The structure of the replicated log

An entry is considered **committed** if it can be applied to the *state machine* of the nodes. *Raft* guarantees that *committed* entries are ***durable*** and will eventually be executed by all of the available *state machines*, while also guaranteeing that no other entry will be committed for the same index. It also guarantees that all the preceding entries of a *committed* entry are also *committed*. This status essentially signals that *consensus* has been reached on this entry.

As mentioned previously, *leaders* are responsible for receiving commands from clients and replicating them across the clusters. This happens in the following order:

1. When a *leader* receives a new command, it appends the entry to its own log and then sends an *AppendEntries* request in parallel to the other nodes, retrying when it does not receive a timely response.
2. When the *leader* receives a response from a majority of *followers*, the entry can be considered *committed*.
3. The *leader* applies the command to its *state machine* and informs the *followers* they can do the same by piggybacking the necessary information about *committed* entries in subsequent *AppendEntries* messages.

Of course, this is mostly the happy path.

## Divergence among nodes[#](#Divergence-among-nodes)

During leader and follower failures, divergence might be observed between the various nodes. The following illustration contains some examples of this phenomenon.

Temporary divergence of node logs

For example, a *follower* might crash and thus miss some (*committed*) entries (rows a and b in the above illustration). It might receive some more (non committed) entries (rows c and d). Or, both things might happen (rows e and f). Specifically, the scenario in row f could happen if a node was elected leader in both terms 2 and 3, replicated some entries, but crashed before any of these entries were
committed.

## Resolving divergence[#](#Resolving-divergence)

*Raft* contains some additional elements to resolve these temporary divergences.

The main overarching principle is that any elected *leader* should contain any entries that have been *committed* up to the *term* it becomes *leader*. The *leader* is then responsible for helping any *followers* with conflicting logs adjust them accordingly to converge again.

> It’s important to note that a *leader* only appends entries to its log and never updates it. Only *followers* are allowed to update their log.

These two aspects are satisfied in the following way.

* During an election, every *RequestVote RPC* contains some information about the *candidate*’s log. A voter is allowed to vote for a *candidate* only if its log is not more up-to-date than the *candidate*’s log. *Raft* determines which of the two logs is more up-to-date by comparing the index and term of the last entries in the logs. A *candidate* must receive votes from a majority of the cluster in order to be elected, which means that every committed entry must be present in at least one of those servers. If the *candidate*’s log is at least as up-to-date as any other log in that majority, then it’s guaranteed to hold all the *committed* entries.
* When sending an *AppendEntries RPC*, a *leader* includes the index and *term* of the entry that immediately precedes the new entries in its log. The *followers* check against their own logs and reject the request if their log differs. If that happens, the *leader* discovers the first index where their logs disagree and starts sending all the entries after that point from its log. The *follower* discards its own entries and adds the *leader*’s entries to its log. As a result, their logs eventually converge again.

**Scenario:** A follower crashed and later returns with extra uncommitted entries from an old leader, and it now rejects the current leader’s AppendEntries due to a term/index mismatch. How does the leader systematically find the correct point to resume replication and ensure the follower’s log converges with the leader’s? Provide your answer in the widget given below.

Want to know the correct answer?

How Leaders Heal Conflicting Follower Logs?

Enter your answer here

﻿

Evaluate

Beta

1000 characters left

Save

Reset

## What happens when a leader crashes before committing an entry?[#](#What-happens-when-a-leader-crashes-before-committing-an-entry)

We mentioned previously that a *leader* knows that an entry from its term can be considered *committed* when it has been successfully replicated to a majority of nodes. It can then be safely applied to the *state machine*.

Let’s see what happens when a *leader* crashes before committing an entry.

If subsequent *leaders* have received this entry, they will attempt to finish replicating the entry.

However, a subsequent *leader* cannot safely conclude that an entry from a previous *term* is *committed* once stored on a majority of nodes.

The reason is there is an edge case where future *leaders* can still replace this entry even if it’s stored on a majority of nodes.

> Feel free to refer to the paper for a full description of how this can happen.

As a result, *leaders* can safely conclude an entry from a previous *term* is *committed* by replicating it and then replicating a new entry from its *term* on top of it. If the new entry from its own *term* is replicated to a majority, the *leader* can safely consider it as *committed*. Thus, it can also consider all the previous entries as *committed* at this point.

So, a *leader* is guaranteed to have all the *committed* entries at the start of its *term*, but it doesn’t know which ones. To find out, it needs to *commit* an entry from its own *term*. To expedite this in periods of idleness, the *leader* can just *commit* a `no-op` command at the beginning of its *term*.

Backlesson

Mark As CompletedComplete

Next

An introduction to Raft

Raft's Implementation

Ask

[Communication mechanism](#Communication-mechanism)

[Divergence among nodes](#Divergence-among-nodes)

[Resolving divergence](#Resolving-divergence)

[What happens when a leader crashes before committing an entry?](#What-happens-when-a-leader-crashes-before-committing-an-entry)

---


# Raft's Implementation

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Raft's Implementation

# Raft's Implementation

Let's have an overview of Raft's implementation.

We'll cover the following...

* [A brief overview](#A-brief-overview)
  + [Mechanism to avoid running out of storage problem](#Mechanism-to-avoid-running-out-of-storage-problem)

## A brief overview[#](#A-brief-overview)

> What has been described so far consists of the main specification of the Raft protocol. The paper contains more information on some other implementation details that will be covered briefly here.

Cluster membership changes can be performed using the same mechanisms by storing the cluster members in the same way regular data is stored.

An important note is that transition from an old configuration ColdC\_{old}Cold​ to a new configuration CnewC\_{new}Cnew​ must be done via a transition to an intermediate configuration CjointC\_{joint}Cjoint​ that contains both the old and the new configuration. This is to prevent two different leaders from being elected for the same term. The following illustration illustrates how that could happen if the cluster transitioned from ColdC\_{old}Cold​ directly to CnewC\_{new}Cnew​.

Risk of switching directly from C\_old to C\_new

During the intermediate transition, log entries are replicated to the servers of both configurations. Any node from both configurations can serve as a *leader* and *consensus* requires a majority from both the old and the new configuration. After the CjointC\_{joint}Cjoint​ configuration has been *committed*, the *cluster* then switches to the new configuration CnewC\_{new}Cnew​.

Since the log can grow infinitely, there also needs to be a mechanism to avoid running out of storage.

### Mechanism to avoid running out of storage problem[#](#Mechanism-to-avoid-running-out-of-storage-problem)

Nodes can perform **log compaction** by writing a snapshot of the system’s current state on stable storage and removing old entries.

When handling read requests from clients, a *leader* needs first to send heartbeats to ensure it’s still the current *leader*. That guarantees the **linearizability** of reads.

Alternatively, *leaders* can rely on the **heartbeat mechanism** to provide some form of lease, but this would assume bounded clock skew to be safe.

A *leader* might also fail after applying a *committed* entry to its *state machine*, but before replying to the client.

In these cases, clients are supposed to retry the request to the new *leader*. If these requests are tagged with unique serial numbers, the *Raft* nodes can identify commands that have already been executed and reply to the clients without re-executing the same request twice.

A leader handling a client's read request must first take an action to guarantee *linearizability*. What is this action? Additionally, if a leader fails after committing a client's write request but before replying, how does Raft prevent the new leader from executing the same request twice when the client retries?

Want to know the correct answer?

Powered by AI

15 Prompts Remaining

Prompt AI WidgetOur tool is designed to help you to understand concepts and ask any follow up questions. Ask a question to get started.

Backlesson

Mark As CompletedComplete

Next

Communication among Raft Nodes

Standing on the Shoulders of Giants

Ask

[A brief overview](#A-brief-overview)

[Mechanism to avoid running out of storage problem](#Mechanism-to-avoid-running-out-of-storage-problem)

---


# Standing on the Shoulders of Giants

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Standing on the Shoulders of Giants

# Standing on the Shoulders of Giants

Let's conclude the consensus.

We'll cover the following...

At this point, we have spent enough time examining all the small details of the various **consensus** algorithms. This can prove to be very useful when one thinks about how to design a system, what kinds of guarantees it would require, or even when troubleshooting edge cases.

Hopefully, we have realized by now that these problems are very complicated. As a result, creating an algorithm that solves these problems or even translating an existing algorithm to a concrete implementation is a really big undertaking.

If there is an existing solution out there, we should first consider re-using this before rolling out our own since it’s highly likely that the existing solution would be much more mature and battle-tested.

This is true not only for consensus but other problems inherent to distributed systems as well.

> A later chapter contains some case studies of basic categories of such distributed systems that we can leverage to solve some common problems.

Backlesson

Mark As CompletedComplete

Next

Raft's Implementation

Quiz on Consensus

Ask

---


# Quiz on Consensus

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Consensus

# Quiz on Consensus

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

Which of the following properties must be satisfied by a consensus algorithm? (Select all that apply) Multi-select

A.

Termination

B.

Agreement

C.

Validity

---

1 / 5

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Standing on the Shoulders of Giants

What is Different in a Distributed System?

Ask

---


# What is Different in a Distributed System?

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

What is Different in a Distributed System?

# What is Different in a Distributed System?

Let's explore the thing that makes distributed systems different.

We'll cover the following...

* [Usecase of time in software systems](#Usecase-of-time-in-software-systems)
* [Examples](#Examples)
* [Difference between a centralized and a distributed system about time](#Difference-between-a-centralized-and-a-distributed-system-about-time)

## Usecase of time in software systems[#](#Usecase-of-time-in-software-systems)

One of the main use cases of **time** in a software system is to determine the **order** of different events.

In practice, this can mean very different things.

![](images/image_1764833633.6178236.svg)![](images/4545133428211712.svg)

## Examples[#](#Examples)

A system might want to impose an *order* to requests received concurrently by different clients to determine in which *order* the effects of each request should take place.

A different example is one where a system administrator might investigate an incident. They may do it by looking at the system logs and inferring relationships between different events, and use the timestamp of the logs associated with these events.

> Both examples have a common underlying goal: to determine the *order* between events.

## Difference between a centralized and a distributed system about time[#](#Difference-between-a-centralized-and-a-distributed-system-about-time)

There is only a single node in a **centralized system** and, thus, only a single clock. This means we can maintain the illusion of a single, universal time dimension, which can then determine the *order* of the various events in the single node of the system.

On the other hand, in a **distributed system**, each node has its own clock. Each one of those clocks may run at a different rate or granularity, which means they will drift apart from each other. Consequently, in a distributed system, “there is no global clock, which could have been used to *order* events happening on different nodes of the system”.

Backlesson

Mark As CompletedComplete

Next

Quiz on Consensus

A Practical Perspective

Ask

[Usecase of time in software systems](#Usecase-of-time-in-software-systems)

[Examples](#Examples)

[Difference between a centralized and a distributed system about time](#Difference-between-a-centralized-and-a-distributed-system-about-time)

---


# A Practical Perspective

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

A Practical Perspective

# A Practical Perspective

Let's look into the practical perspective of clocks and time in distributed systems.

We'll cover the following...

* [Physical clock](#Physical-clock)
  + [Sundial](#Sundial)
  + [Hourglass](#Hourglass)
  + [Pendulum clock](#Pendulum-clock)
  + [Quartz clock](#Quartz-clock)
  + [Atomic clock](#Atomic-clock)
* [Skew between clocks](#Skew-between-clocks)
* [Side effects of assuming a global clock in distributed systems](#Side-effects-of-assuming-a-global-clock-in-distributed-systems)
* [Conclusion](#Conclusion)

The clocks used in real systems are what we usually call **physical clocks**.

## Physical clock[#](#Physical-clock)

A physical clock is a physical process coupled with a method of measuring that process to record the passage of time.

Most *physical clocks* are based on cyclic processes. Below are some examples of such devices:

### Sundial[#](#Sundial)

A *sundial* is one of the most basic and easy-to-understand devices. It tells the time of the day by using a gnomon and tracking the shadow created by the sun.

![](images/image_1764833648.992966.svg)![](images/6031089637392384.svg)

### Hourglass[#](#Hourglass)

An *hourglass* is also a basic and easy-to-understand device. It measures time by the regulated flow of sand through a bulb.

![](images/image_1764833649.1828299.svg)![](images/6741751099424768.svg)

### Pendulum clock[#](#Pendulum-clock)

A *pendulum clock* is a common clock device that uses an oscillating weight as its timekeeping element.

![](images/image_1764833649.3765612.svg)![](images/5563282369937408.svg)

### Quartz clock[#](#Quartz-clock)

A *quartz clock* is an electronic version of the *pendulum clock* and is used in software systems. This device makes use of a crystal, called quartz crystal, that vibrates or ticks with a specific frequency when electricity is applied to it.

![](images/image_1764833649.5637088.svg)![](images/5004856761909248.svg)

### Atomic clock[#](#Atomic-clock)

An *atomic clock* is one of the most accurate timekeeping devices. It uses the frequency of electronic transitions in certain atoms to measure time.

![](images/image_1764833649.7334764.svg)![](images/5448634593312768.svg)

## Skew between clocks[#](#Skew-between-clocks)

All of the above devices rely on physical processes to measure time. Of course, errors may reside in the measurement tools and the physical processes themselves.

As a result, no matter how often we synchronize these clocks with each other or other clocks with accurate measurement methods, there will always be a ***skew*** between the various clocks involved in a distributed system.

## Side effects of assuming a global clock in distributed systems[#](#Side-effects-of-assuming-a-global-clock-in-distributed-systems)

When we build a **distributed system**, we must take the difference between clocks into account. The overall system should not operate under the assumption that all these clocks are the same and act as a single global clock.

The following illustration contains an example of what could happen otherwise.

![](images/image_1764833649.916503.svg)![Side-effects of assuming a global clock](images/4813026342600704.svg "Side-effects of assuming a global clock")

Side-effects of assuming a global clock

EAE\_AEA​ is the **event** happening at node AAA, and TAT\_ATA​ is the timestamp assigned to that event. The same is true for the other such symbols.

Let’s assume we have a distributed system comprising of three different nodes A, B, and C. Every time an event happens at a node, the node assigns a *timestamp* to the event, using its own clock, and then propagates this event to the other nodes. As the nodes receive events from the other nodes, they compare the timestamps associated with these events to determine the *order* in which the events happened.

If all the clocks were completely accurate and reflected exactly the same time, the scheme would theoretically be capable of identifying the order.

However, if there is a *skew* between the clocks of the various nodes, the correctness of the system is violated.

More specifically, in our example, we assume that the clock of node A runs ahead of the clock of node B. In the same way, the clock of node C runs behind the clock of node B. As a result, even if the event in node A happened before the event in node C, node B will compare the associated timestamps and believe that the event from node C happened first.

## Conclusion[#](#Conclusion)

From a practical point of view, the best we can do is to accept there will always be a difference between the clocks of different nodes in the system. Then, we can expose this uncertainty in some way so that the various nodes in the system can handle it appropriately.

> Spanner is a system that follows this approach, using the TrueTime API that directly exposes this uncertainty by using time intervals (embedding an error) instead of plain timestamps.

Backlesson

Mark As CompletedComplete

Next

What is Different in a Distributed System?

A Theoretical Perspective

Ask

[Physical clock](#Physical-clock)

[Sundial](#Sundial)

[Hourglass](#Hourglass)

[Pendulum clock](#Pendulum-clock)

[Quartz clock](#Quartz-clock)

[Atomic clock](#Atomic-clock)

[Skew between clocks](#Skew-between-clocks)

[Side effects of assuming a global clock in distributed systems](#Side-effects-of-assuming-a-global-clock-in-distributed-systems)

[Conclusion](#Conclusion)

---


# A Theoretical Perspective

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

A Theoretical Perspective

# A Theoretical Perspective

This lesson will explain the theoretical perspective of time.

We'll cover the following...

* [Laws of physics](#Laws-of-physics)
  + [Train experiment](#Train-experiment)
* [Relativity in computing systems](#Relativity-in-computing-systems)

What we have demonstrated so far is a rather practical and simplified version of the notion of **time**.

People once believed in an absolute, universal time—a single, unchanging clock ticking throughout the cosmos. However, modern physics has shown that time is relative. Observers in different states of motion or gravitational environments can measure time differently. Thus, the concept of universal time doesn’t hold in reality.

## Laws of physics[#](#Laws-of-physics)

According to the laws of physics, more specifically the [special theory of relativity](https://en.wikipedia.org/wiki/Relativity_of_simultaneity), it is impossible to absolutely state that two distinct events occur at the same time if those events are separated in space.

For example, a car crash in London and another in New York that appear to happen at the same time to an observer on Earth will appear to have occurred at slightly different times to an observer on an airplane flying between London and New York.

This can look like a paradox, but we can easily understand the reasoning behind this theory via a thought experiment known as the **train experiment**.

### Train experiment[#](#Train-experiment)

This experiment consists of a train with an observer in the middle of the carriage, and another observer standing on the platform as the train passes by. Then, there is a flash of light in the middle of the carriage, at the point when the two observers see each other. For the observer inside the carriage, both sides of the carriage have the same distance from the middle, so the light will reach both sides at the same time. For the observer standing on the platform, the rear side is moving towards the initial point of the flash, while the front side is moving away from it, so the light will reach the two sides at different points in time. This is because the speed of light is the same for all directions.

> As a result, whether two spatially separated events happen at the same time (simultaneously) is not absolute but depends on the observer’s reference frame.

Below is an illustration of the train experiment.

The train experiment

## Relativity in computing systems[#](#Relativity-in-computing-systems)

In the context of this course, this experiment mainly serves to underline the fact that time is relative, and there can be no absolute, universal time dimension in a **distributed system**.

It also gives rise to another observation that forms the basis of distributed algorithms, that provide solutions to ordering problems without relying on a global clock.

> We will cover these algorithms in more detail in the [next](https://www.educative.io/courses/distributed-systems-practitioners/lamport-clocks) chapter.

As illustrated in the previous example, information in the real world flows through light. If the sun stops shining, a human will realize that a bit later around 8 minutes later, to be exact. This is the time it takes sunlight to reach Earth from the sun. If we think about it, *distributed systems* are very similar. Events happen at different nodes of the system, and it takes some time for other nodes of the system to recognize that these events happened.

> A difference worth pointing out is that the speed of light is constant, but the speed with which information flows in a *distributed system* is variable. This is because it depends on the underlying infrastructure and conditions of the network.

In the worst-case scenario, information might not be able to flow between two parts of a system at all because of a network partition.

Backlesson

Mark As CompletedComplete

Next

A Practical Perspective

Logical Clocks

Ask

[Laws of physics](#Laws-of-physics)

[Train experiment](#Train-experiment)

[Relativity in computing systems](#Relativity-in-computing-systems)

---


# Logical Clocks

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Logical Clocks

# Logical Clocks

Let's explore what logical clocks are and how they help to order events.

We'll cover the following...

* [What are logical clocks?](#What-are-logical-clocks)
* [Event ordering with logical clocks](#Event-ordering-with-logical-clocks)

The focus of this chapter so far has been on **physical clocks** and explaining their main limitations when used in **distributed systems**. Now, let’s explore the use of ***logical clocks***.

## What are logical clocks?[#](#What-are-logical-clocks)

**Logical clocks** are the alternative category of clocks that do not rely on physical processes to keep track of time. Instead, they make use of messages exchanged between the nodes of the system. This is also the main mechanism of information flow in a *distributed system*, as discussed previously.

## Event ordering with logical clocks[#](#Event-ordering-with-logical-clocks)

We can imagine a trivial form of such a clock in a system that consists of only a single node. Instead of using a physical clock, this node could use a logical clock, which would consist of a single method, say `getTime()`. When invoked, this method would return a counter, which would subsequently be incremented. For example, if the system started at 9:00 and events A, B and C happened at 9:01, 9:05, and 9:55, respectively, they could be assigned the timestamps 1, 2, and 3. As a result, the system would still be able to order the events, but it would not be able to determine the temporal distance between any two events.

> We have described some more elaborate types of *logical clocks* in the [next](https://www.educative.io/courses/distributed-systems-practitioners/lamport-clocks) chapter.

If two events A and B occur minutes apart in real time but receive consecutive logical timestamps (e.g., 1 and 2), why can’t a logical clock tell you how far apart they were, and what does it still let you conclude? Provide your answer in the widget given below.

Want to know the correct answer?

Limitations and Uses of Logical Clocks

Enter your answer here

﻿

Evaluate

Beta

750 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

A Theoretical Perspective

Quiz on Distributed Clocks

Ask

[What are logical clocks?](#What-are-logical-clocks)

[Event ordering with logical clocks](#Event-ordering-with-logical-clocks)

---


# Quiz on Distributed Clocks

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed Clocks

# Quiz on Distributed Clocks

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

True or False: In a distributed system, there is no single, global clock.

A.

True

B.

False

---

1 / 5

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Logical Clocks

Total and Partial Ordering

Ask

---


# Total and Partial Ordering

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Total and Partial Ordering

# Total and Partial Ordering

This lesson will explain the order types with examples. Also, we will explore the ordering used by distributed systems to order events.

We'll cover the following...

* [Total ordering](#Total-ordering)
  + [Example](#Example)
* [Partial ordering](#Partial-ordering)
  + [Example](#Example)
* [Total ordering events in single-node systems](#Total-ordering-events-in-single-node-systems)
* [Partial ordering events in distributed systems](#Partial-ordering-events-in-distributed-systems)

Determining the **order** of events is a common problem that needs to be solved in software systems.

However, there are two different possible types of ordering: **total ordering** and **partial ordering**.

## Total ordering[#](#Total-ordering)

A *total order* is a binary relation that compares any two elements of a set with each other. As a direct consequence of this property, we can use this relation to derive only a single order for all the elements in a set. This is why it’s called a *total order*.

### Example[#](#Example)

If we totally order the set of unique integers {7,9,3,2,6}\lbrace 7, 9, 3, 2, 6 \rbrace{7,9,3,2,6} using the relation less than <<<, the associated total order is [2,3,6,7,9][2, 3, 6, 7, 9][2,3,6,7,9].

## Partial ordering[#](#Partial-ordering)

A *partial order* is a binary relation that can be used to compare only some of the elements of a set with each other. Consequently, we can use this relation to derive multiple, valid orders for all the elements in the set.

### Example[#](#Example)

The set of the following sets of integers {{0},{1},{2},{0,1},{1,2}}\lbrace\lbrace0\rbrace,\lbrace1\rbrace,\lbrace2\rbrace,\lbrace0,1\rbrace,\lbrace1,2 \rbrace\rbrace{{0},{1},{2},{0,1},{1,2}} can only be partially ordered, using the subset relation ⊆\subseteq⊆. If we pick the elements {0}\lbrace0\rbrace{0} and {0,1}\lbrace0,1\rbrace{0,1}, we can order them since {0}⊆{0,1}\lbrace0\rbrace\subseteq\lbrace0,1\rbrace{0}⊆{0,1}. However, the elements {0,1}\lbrace0,1\rbrace{0,1} and {1,2}\lbrace1,2\rbrace{1,2} cannot be ordered using this relation, since neither {0,1}⊆{1,2}\lbrace0,1\rbrace\subseteq\lbrace1,2\rbrace{0,1}⊆{1,2} nor {1,2}⊆{0,1}\lbrace1,2\rbrace\subseteq\lbrace0,1\rbrace{1,2}⊆{0,1} holds.

As a result, both [{0},{1},{2},{0,1},{1,2}][\lbrace0\rbrace,\lbrace1\rbrace,\lbrace2\rbrace,\lbrace0,1\rbrace,\lbrace1,2\rbrace][{0},{1},{2},{0,1},{1,2}] and [{2},{1},{0},{1,2},{0,1}][\lbrace2\rbrace,\lbrace1\rbrace,\lbrace0\rbrace,\lbrace1,2\rbrace,\lbrace0,1\rbrace][{2},{1},{0},{1,2},{0,1}] would be valid partial orderings.

> There could be more sequences other than these two.

## Total ordering events in single-node systems[#](#Total-ordering-events-in-single-node-systems)

In systems comprised of a single node, it’s easy and intuitive to determine a *total ordering* of events. The main reason is that there is a single actor where all the events happen, so this actor can impose a *total order* on these events as they occur.

*Total orderings* also make it much simpler to build protocols and algorithms.

## Partial ordering events in distributed systems[#](#Partial-ordering-events-in-distributed-systems)

In a *distributed system* it’s not that straightforward to impose a *total order* on events. This is because there are multiple nodes in the system, and events might be happening concurrently on different nodes. As a result, a *distributed system* can use any valid *partial ordering* of the events occurring if there is no strict need for a *total ordering*.

The following illustration shows why *total ordering* is much harder to determine in a *distributed system*.

Total ordering vs partial ordering

In a system comprising of a single node that can only execute events serially, it’s easy to define a *total order* on all the events happening. This is because, between two events (e1e\_1e1​, e2e\_2e2​), one of them starts after the other one finishes.
On the other hand, in a *distributed system* with multiple nodes where events are happening concurrently, it’s much harder to determine a *total order*. This is because there might be pairs of events that cannot be ordered.

We can make an interesting and important observation from the above discussion. The fact that these operations have some duration and are interleaved with each other is not the only problem that makes *total ordering* hard to achieve. Even if these operations are instantaneous (or linearizable), total ordering is still non-trivial to achieve as there is no global clock.

As a result, even if each node can assign unique timestamps to the events happening, these timestamps will come from clocks running at different rates, thus making it harder to compare them. This is demonstrated in the following illustration.

Clock errors making total ordering harder

The above illustration shows that any **clock errors** can be ignored in a single-node system since there is only one clock in use. This makes it possible to assign timestamps to events as if they are instantaneous and establish a *total order*.

However, in a *distributed system*, there are multiple clocks in play that run at different rates and can have different errors. This means that the errors need to be taken into account when comparing timestamps between different nodes. This makes it harder to establish a *total order* since there will be pairs of events where we cannot know which one happened first.

> Note that for ease of understanding, the illustration shows the clocks of all the nodes having the same error, which is not realistic.

Backlesson

Mark As CompletedComplete

Next

Quiz on Distributed Clocks

The Concept of Causality

Ask

[Total ordering](#Total-ordering)

[Example](#Example)

[Partial ordering](#Partial-ordering)

[Example](#Example)

[Total ordering events in single-node systems](#Total-ordering-events-in-single-node-systems)

[Partial ordering events in distributed systems](#Partial-ordering-events-in-distributed-systems)

---


# The Concept of Causality

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Concept of Causality

# The Concept of Causality

Learn the concept of causality in general and also in distributed systems.

We'll cover the following...

* [Total ordering in natural phenomena](#Total-ordering-in-natural-phenomena)
* [Causal ordering using logical clocks](#Causal-ordering-using-logical-clocks)
* [Causality](#Causality)
  + [Determining causality](#Determining-causality)
* [Causality in distributed systems](#Causality-in-distributed-systems)
* [Event causality using logical clocks](#Event-causality-using-logical-clocks)
* [Events in distributed systems](#Events-in-distributed-systems)
* [Potential causality](#Potential-causality)

## Total ordering in natural phenomena[#](#Total-ordering-in-natural-phenomena)

As humans, we grow accustomed to **total ordering**, because most of the natural phenomena around us appear to be subject to it.

When we go shopping, we are placed in a queue to be served in a *total order*.

Similarly, cars waiting for the signal to change at an intersection are also ordered in the same way.

> However, there are scenarios especially prevalent in software systems where a *total ordering* is not really necessary.

## Causal ordering using logical clocks[#](#Causal-ordering-using-logical-clocks)

For instance, look at some of the social media platforms people use nowadays, where they can create posts and add comments to the posts of other people. Do we really care about the order in which two unrelated posts are shown to us? Probably not. As a result, the system could potentially leverage a **partial ordering**, where posts that can’t really be ordered are displayed in an arbitrarily chosen order.

However, there is still a need to preserve the order of some events that are tightly linked. For example, if a comment CBC\_BCB​ is a reply to a comment CAC\_ACA​, then we would most probably like to see CBC\_BCB​ after CAC\_ACA​. Otherwise, a conversation could end up being confusing and hard to follow.

## Causality[#](#Causality)

What we just described is the notion of **causality**, where one event contributes to the production of another event.

Looking back at one of the introductory lessons, [consistency models](https://www.educative.io/courses/distributed-systems-practitioners/consistency-models), we can find the description of a consistency model, called the **causal consistency** model. This model ensures that events that are causally related are observed by the various nodes in a single order, where causes precede the effects.

Violating *causality* can lead to behaviors that are really hard to understand by the users of a system.

> Fortunately, as we will explore in the next lessons of this chapter, it’s possible to track *causality* without the need for physical time.

The notion of *causality* is also present in real life. We subconsciously use *causality* when planning or determining the feasibility of a plan.

### Determining causality[#](#Determining-causality)

*Causality* is determined based on a set of loosely synchronized clocks (i.e., wristwatches, wall clocks, etc.) under the illusion of a global clock. This appears to work in most cases because the time duration of events is much more coarse-grained in real life, and information “flows” much more slowly than in software systems.

For instance, compare the time a human needs to go from London to Manchester and the time needed for 10 kilobytes to travel the same distance via the Internet. So, small differences between clocks do not create significant problems in most real-life scenarios.

However, in distributed computing systems, events happen at a much higher rate and higher speed, and their duration is several orders of magnitude smaller. Consequently, if the physical clocks of the various nodes in the system are not precisely synchronized, the *causality* relation between events may not be accurately captured.

## Causality in distributed systems[#](#Causality-in-distributed-systems)

*Causality* can be leveraged in the design of distributed systems with the following two main benefits:

* Increasing concurrency
* Replacing real-time with the notion of logical time, which can be tracked with less infrastructure and costs

As we have seen so far, distributed systems are inherently asynchronous. By introducing coordination and synchronization between them, we essentially reduce the level of concurrency and consequently their performance. The notion of *causality* enables us to let these systems remain asynchronous while also supporting the *causal consistency* model. This prevents a big set of counterintuitive behaviors that stem from weak consistency.

Furthermore, keeping physical clocks synchronized is a task that requires hardware infrastructure with the associated costs, where the costs increase in proportion to how accurate the synchronization needs to be.

Logical clocks rely on the existing messaging exchanged between nodes of a system, which makes them less expensive to implement. Of course, logical clocks have their own pitfalls, so they are definitely not a silver bullet.

## Event causality using logical clocks[#](#Event-causality-using-logical-clocks)

> The following lessons will present some kinds of logical clocks. It is important to highlight in advance that they all share some common characteristics.

The abstraction of logical clocks consist of two main parts:

* A data structure local to every node used to represent logical time
* A protocol to update the data structures accordingly as events happen and time passes by

Each node maintains data structures that provide the following capabilities:

* A local logical clock that helps a node measure its own progress
* A global logical clock that is a good representation of a node’s view of
  the logical global time

Similarly, the protocol consists of two main rules:

* **R1**: A rule that governs how the local logical clock is updated by a node when it executes an event.
* **R2**: A rule that governs how a node updates its global logical clock to update its view of the global time and progress. This determines what information about the logical time needs to be piggybacked in the messages exchanged and how the receiving node uses this information.

> Different types of logical clocks have the same core parts and the protocol described above, but they might differ in the actual data structures used to represent logical time, or the logic in the rules of the protocol.

If physical clocks drift and can’t reliably capture causality, how do logical clocks reduce cost while still enabling causal consistency, and what two protocol rules do nodes follow to propagate logical time? Provide your answer in the widget given below.

Want to know the correct answer?

How Logical Clocks Enable Cheap Causality?

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

## Events in distributed systems[#](#Events-in-distributed-systems)

The events that happen in a distributed system can be classified into three fundamental categories:

* **Local events** that happen at a node and changing its state
* **Send events** that represent a node sending a message to another node to inform about a change
* **Receive events** that represent a node receiving a message from another node about a change

These events exchanged between nodes to propagate information can also propagate time changes between nodes.

The notion of causality is built on top of the [happened-before relation](https://en.wikipedia.org/wiki/Happened-before) (→\to→). This is a strict, partial order on the aforementioned events so that:

* If events aaa and bbb are two events happening at the same node, the relation a→ba\to ba→b holds if the occurrence of event aaa preceded the occurrence of event bbb.

> Note that this is easy to determine for a single node, as shown before.

* If event aaa is the event of a node corresponding to sending a message and event bbb is the event of a different node corresponding to the receipt of the same message, then a→ba\to ba→b.
* For three events aaa, bbb, and ccc, if a→ba\to ba→b and b→cb\to cb→c, then a→ca\to ca→c.

We say that event E1E\_1E1​ causally precedes event E2E\_2E2​ (or these two events are causally related) if E1→E2E\_1\to E\_2E1​→E2​. We say that event E1E\_1E1​ is not causally related to E2E\_2E2​ (E1∥E2E\_1 \parallel E\_2E1​∥E2​), if neither of the relations E1→E2E\_1\to E\_2E1​→E2​ or E2→E1E\_2\to E\_1E2​→E1​ holds.

The following illustration demonstrates how this would work in a distributed system of three nodes.

Happened-before relationship in a distributed system

Here are some of the causal relationships: E1→E4E\_1\to E\_4E1​→E4​, E1→E5E\_1\to E\_5E1​→E5​, E1→E6E\_1\to E\_6E1​→E6​, E1→E7E\_1\to E\_7E1​→E7​, E1→E8E\_1\to E\_8E1​→E8​ and E1→E9E\_1\to E\_9E1​→E9​.

Note that E1∥E3E\_1\parallel E\_3E1​∥E3​ and E2∥E6E\_2\parallel E\_6E2​∥E6​ even though these events are temporally distant, because there was no information exchanged between the nodes that could help the logical clocks track any relation between them. This means that these events should be considered concurrent by the system and could have happened in any order. This is because E6E\_6E6​ could have happened at any point in time from the moment right after E1E\_1E1​ to just before E9E\_9E9​, preserving all the causal relationships intact. The same holds for E2E\_2E2​, which could have happened at any point in time until E4E\_4E4​.

## Potential causality[#](#Potential-causality)

In general, the concept of *causality* in distributed systems (and as defined in the Lamport paper) could be referred to as potential causality. This is because it does not necessarily indicate a cause-and-effect relationship, but only a potential for it.

As a result, when we say that Ei→EjE\_i\to E\_jEi​→Ej​, we don’t mean that EiE\_iEi​ has caused or affected EjE\_jEj​. Instead, we mean that EiE\_iEi​ could have caused or affected EjE\_jEj​. This is because this concept is generic and does not have an application-specific context to infer actual cause-and-effect relationships.

However, applications can leverage the algorithms presented in this chapter, and enrich them with additional metadata that makes it possible to track *actual causality* instead of *potential causality*.

> Note that even the ability to track *potential causality* is still very useful to prevent system behaviors that will confuse users. It just means that the system might be storing and transmitting more information than necessary to achieve this purpose.

Backlesson

Mark As CompletedComplete

Next

Total and Partial Ordering

Lamport Clocks

Ask

[Total ordering in natural phenomena](#Total-ordering-in-natural-phenomena)

[Causal ordering using logical clocks](#Causal-ordering-using-logical-clocks)

[Causality](#Causality)

[Determining causality](#Determining-causality)

[Causality in distributed systems](#Causality-in-distributed-systems)

[Event causality using logical clocks](#Event-causality-using-logical-clocks)

[Events in distributed systems](#Events-in-distributed-systems)

[Potential causality](#Potential-causality)

---


# Lamport Clocks

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Lamport Clocks

# Lamport Clocks

Let's examine what Lamport clocks are and how they work.

We'll cover the following...

* [Rules of the protocol](#Rules-of-the-protocol)
* [Clock consistency condition](#Clock-consistency-condition)
* [Working of Lamport clocks](#Working-of-Lamport-clocks)
* [Usage of Lamport clocks](#Usage-of-Lamport-clocks)

Leslie Lamport invented one of the first and simplest types of logical clocks, called the Lamport clock.

In this type of logical clock, every node in the system maintains a logical clock in the form of a numeric counter that starts from zero when a node starts operating.

## Rules of the protocol[#](#Rules-of-the-protocol)

* (**R1**) Before executing an event (send, receive, or local), a node increments the counter of its logical clock by one: Ci=Ci+1C\_i = C\_i + 1Ci​=Ci​+1.
* (**R2**) Every sent message piggybacks the clock value of its sender at sending time. When a node nin\_ini​ receives a message with timestamp CmsgC\_{msg}Cmsg​, it executes the following actions:
  + Updates its clock by taking the maximum of its clock and the received clock: Ci=max(Ci,Cmsg)C\_i = max(C\_i, C\_{msg})Ci​=max(Ci​,Cmsg​)
  + Executes R1
  + Delivers the message

## Clock consistency condition[#](#Clock-consistency-condition)

The Lamport clocks satisfy the so-called **clock consistency condition**.

If one event e1e\_1e1​ causally precedes another event e2e\_2e2​, then C(e1)<C(e2)C(e\_1) < C(e\_2)C(e1​)<C(e2​). However, the reverse which is the **strong consistency condition**, is not satisfied by Lamport clocks. This means that if C(e1)<C(e2)C(e\_1) < C(e\_2)C(e1​)<C(e2​), then this does not necessarily mean that the event e1e\_1e1​ causally precedes e2e\_2e2​. As a result, this means that Lamport clocks cannot be used to infer **partial orderings** that are causally consistent.

> However, they can still be used for other purposes, such as creating (non causally consistent) **total orderings**.

## Working of Lamport clocks[#](#Working-of-Lamport-clocks)

To understand better how Lamport clocks work, let’s look at the example in the following illustration. We have a distributed system consisting of three nodes A, B, and C, which execute events locally and exchange messages to propagate the necessary information across the whole system. We can try running the rules described above and see that the clocks of each node are updated, as shown in the illustration.

Created with Fabric.js 3.6.6

1 / 18

A system of three nodes. Initially each node has the logical clock value C set to zero.

Created with Fabric.js 3.6.6

1 / 18

Node A sends a message to node B

Created with Fabric.js 3.6.6

1 / 18

Node B receives the message.

Created with Fabric.js 3.6.6

1 / 18

B1’s timestamp is max (clock(B), timestamp(A1)) + 1, which is 2

Created with Fabric.js 3.6.6

1 / 18

B1’s clock becomes 2

Essentially, each node ticks its clock as local events happen and bumps the clock if it identifies that another node has a higher clock value than that node’s value.

Now, let’s discuss the conditions presented previously in more detail.

Any two events that are causally related will reflect this relationship in the clock’s value. For instance, A1A\_1A1​ causally precedes B1B\_1B1​ and we can see that C(A1)=1<2=C(B1)C(A\_1) = 1 < 2 = C(B\_1)C(A1​)=1<2=C(B1​) (clock consistency condition).

We can also see that the *strong consistency condition* does not hold. For instance, C(C2)<C(B2)C(C\_2) < C(B\_2)C(C2​)<C(B2​), but these two events are not causally dependent. Event B2B\_2B2​ could have happened either before or after C2C\_2C2​ with the same clock value.

## Usage of Lamport clocks[#](#Usage-of-Lamport-clocks)

Lamport clocks can be used to create a **total ordering** of events in a distributed system using some arbitrary mechanism to break ties in case clocks of different nodes have the same value (e.g. the ID of the node).

The caveat is that this **total ordering** is somewhat arbitrary and cannot infer causal relationships. This limits the number of practical applications that Lamport clocks can have. The paper demonstrates how they could potentially be used to solve synchronisation problems, such as mutual exclusion.

Backlesson

Mark As CompletedComplete

Next

The Concept of Causality

Vector Clocks

Ask

[Rules of the protocol](#Rules-of-the-protocol)

[Clock consistency condition](#Clock-consistency-condition)

[Working of Lamport clocks](#Working-of-Lamport-clocks)

[Usage of Lamport clocks](#Usage-of-Lamport-clocks)

---


# Vector Clocks

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Vector Clocks

# Vector Clocks

Let's inspect what vector clocks are and how they work and satisfy strong clock condition. Let's also look at the main limitation of Lamport clocks.

We'll cover the following...

* [Limitation of Lamport clocks](#Limitation-of-Lamport-clocks)
* [Defining vector clock](#Defining-vector-clock)
* [Rules of the protocol](#Rules-of-the-protocol)
* [Strong clock condition](#Strong-clock-condition)
* [Working of vector clocks](#Working-of-vector-clocks)
* [Usage of vector clocks](#Usage-of-vector-clocks)
* [Points to be noted](#Points-to-be-noted)

## Limitation of Lamport clocks[#](#Limitation-of-Lamport-clocks)

The main limitation of *Lamport clocks* is that they do not satisfy the **strong clock condition**. This means they cannot be used to infer causal relationships between events.

The underlying reason for this is that both the local and the global logical clocks for each node are flattened into a single number, which does not provide all the necessary information to track causal relationships.

So we need to maintain a set of all events that causally precede each event. This is known as a causal history. For instance, the following illustration shows the causal history of E7E\_7E7​ is {E1,E2,E3,E4,E5}\lbrace E\_1, E\_2, E\_3, E\_4, E\_5\rbrace{E1​,E2​,E3​,E4​,E5​}. We also need to store the causal history of each event as efficiently as possible by using a compact data structure. According to Colin J. and Friedemann, a **vector clock** is an example of such a data structure.

Happened-before relationship in a distributed system

## Defining vector clock[#](#Defining-vector-clock)

A ***vector clock*** is another type of logical clock, where the clock data structure for each node is a vector of NNN counters [c0,c1,..,cN][c^0, c^1, .., c^N][c0,c1,..,cN], where NNN is the number of nodes in the system. For the clock of the ithi^{th}ith node [ci0,ci1,...,ciN][{c\_{i}}^0, {c\_{i}}^1, ..., {c\_{i}}^N][ci​0,ci​1,...,ci​N]:

* The ithi^{th}ith element of the clock cii{c\_{i}}^ici​i represents the local logical clock of the node
* The remaining elements of the clock [ci0,...,cii−1,cii+1,...,ciN][{c\_{i}}^0, ..., {c\_{i}}^{i-1}, {c\_{i}}^{i+1},..., {c\_{i}}^N][ci​0,...,ci​i−1,ci​i+1,...,ci​N] together form the global logical clock of the node

## Rules of the protocol[#](#Rules-of-the-protocol)

The rules of the protocol are the following:

* (**R1**) Before executing an event (send, receive, or local), a node increments the counter of its logical clock by one: Cii=Cii+1{C\_{i}}^i = {C\_{i}}^i + 1Ci​i=Ci​i+1.
* (**R2**) Every sent message piggybacks the clock value of its sender at sending time. When the ithi^{th}ith node receives a message with a vector [cj0,...,cjN][{c\_{j}}^0, ..., {c\_{j}}^N][cj​0,...,cj​N] from the jthj^{th}jth node, it executes the following actions:
  + Executes *R1*
  + Updates each element in its vector by taking the maximum of the value in its own *vector clock* and the value in the vector in the received message: Cik=max(cik,cjk){C\_{i}}^k = max({c\_{i}}^k, {c\_{j}}^k)Ci​k=max(ci​k,cj​k) for every kkk in [0,N][0, N][0,N]
  + Delivers the message

## Strong clock condition[#](#Strong-clock-condition)

*Vector clock* satisfies the *strong clock condition*. This means that if the relationship C​i<C​j​​ holds for two events EiE\_iEi​, EjE\_jEj​ with timestamps CiC\_iCi​, then Ei→EjE\_i\to E\_jEi​→Ej​.’

The only missing thing is how comparing *vector clocks* with each other, which is done in the following way:

* For two clocks Ci=[ci0,...,ciN]C\_i = [{c\_{i}}^0, ..., {c\_{i}}^N]Ci​=[ci​0,...,ci​N] and Cj=[cj0,...,cjN]C\_j = [{c\_{j}}^0, ..., {c\_{j}}^N]Cj​=[cj​0,...,cj​N] Ci<CjC\_i < C\_jCi​<Cj​ iff all the elements of the clock CiC\_iCi​ are less than or equal to all the corresponding elements of clock CjC\_jCj​ (cik≤cjk({c\_{i}}^k \leq {c\_{j}}^k(ci​k≤cj​k for all k)k)k) and there is at least one element of CiC\_iCi​ that is strictly smaller than the corresponding element of CjC\_jCj​ (cil<cjl({c\_{i}}^l < {c\_{j}}^l(ci​l<cj​l for at least one lll in [0,N])[0, N])[0,N]).

## Working of vector clocks[#](#Working-of-vector-clocks)

The following illustration contains the same distributed execution displayed in the [Lamport clocks](https://www.educative.io/collection/page/10370001/4891237377638400/5074906797047808#working-of-lamport-clocks) lesson’s illustration. This time, we are using vector clocks.

Created with Fabric.js 3.6.6

1 / 14

A system with three nodes. The vector clock on each node has one entry for every node in the system and is initialized to 0.

Created with Fabric.js 3.6.6

1 / 14

Node A sends a message to Node B. Send event occurred at Node A, so it increment its entry in its clock

Created with Fabric.js 3.6.6

1 / 14

A local event occured at Node C, it increments its entry in the clock

Created with Fabric.js 3.6.6

1 / 14

The message from Node A arrives at Node B

Created with Fabric.js 3.6.6

1 / 14

Node B stores the sender’s (A) timestamp value from the message in its own vector clock. Also, this is the first event at Node B, so it updates its own entry in the vector clock to 1.

Each node in the system maintains a *vector clock*, where the first element corresponds to the time in node AAA, the second to the time in node BBB, and the third and last element to the time in node CCC.

> We can spend some time again verifying that the clock values have been assigned just by following the rules described above.

This time, we can see that the clock of A1A\_1A1​ is smaller than the clock of B1B\_1B1​, while also A1→B1A\_1 \to B\_1A1​→B1​.

What’s more important, though, is that we can detect events that are not causally related. For instance, B2∥C2B\_2 \parallel C\_2B2​∥C2​ and we can see that the timestamp of B2B\_2B2​ is neither smaller nor larger than the timestamp of C2C\_2C2​. This means that we can consider these events concurrent, and they could have happened in any order.

## Usage of vector clocks[#](#Usage-of-vector-clocks)

Vector clocks can be used in cases that benefit from the capability to detect whether two events are causally related or concurrent. They also allow the different nodes of the system to make progress independently and efficiently without synchronization and coordination bottlenecks.

## Points to be noted[#](#Points-to-be-noted)

We mentioned previously that in a distributed system of nnn nodes, each vector clock is composed of nnn elements. It’s important to clarify that every process that consists of a source of concurrency needs to be considered as a node of the system in the context of the *vector clocks*. This means an entry for this process should be dedicated in each clock.

For example, if our application consists of three servers and two clients, each *vector clock* should contain five entries. Otherwise, we risk not being able to identify concurrent and conflicting operations, and treating them as causally related instead.

> See [why vector clocks are hard](https://riak.com/posts/technical/why-vector-clocks-are-hard).

It has been formally proven by Charron-Bost et al. that “the size of a vector clock must be at least nnn for a system consisting of nnn nodes to fully capture causality”. This means that vector clocks require a significant amount of storage in cases where the number of all the participating nodes is large. This can be the case for some types of systems nowadays, such as web applications where every browser is considered a client of the system.

Backlesson

Mark As CompletedComplete

Next

Lamport Clocks

Version Vectors

Ask

[Limitation of Lamport clocks](#Limitation-of-Lamport-clocks)

[Defining vector clock](#Defining-vector-clock)

[Rules of the protocol](#Rules-of-the-protocol)

[Strong clock condition](#Strong-clock-condition)

[Working of vector clocks](#Working-of-vector-clocks)

[Usage of vector clocks](#Usage-of-vector-clocks)

[Points to be noted](#Points-to-be-noted)

---


# Version Vectors

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Version Vectors

# Version Vectors

Let's find the similarities and differences between version vectors and vector clocks. We will also look into the details of the version vectors and issues with the vector clocks.

We'll cover the following...

* [Comparing version vectors with vector clocks](#Comparing-version-vectors-with-vector-clocks)
* [Rules for the protocol](#Rules-for-the-protocol)
* [Working of version vectors](#Working-of-version-vectors)
  + [Version vectors with per-client entries](#Version-vectors-with-per-client-entries)
  + [Limitation of vector clocks with per-client entries](#Limitation-of-vector-clocks-with-per-client-entries)
* [Coping with the limitation](#Coping-with-the-limitation)
  + [Version vectors with per-server entries](#Version-vectors-with-per-server-entries)
  + [Issues while using vector clocks with per-server entries](#Issues-while-using-vector-clocks-with-per-server-entries)

## Comparing version vectors with vector clocks[#](#Comparing-version-vectors-with-vector-clocks)

**Version vectors** are a mechanism that is very similar to **vector clocks**. The data structure used by *version vectors* and the associated update rules are very similar to those used by *vector clocks*. However, *version vectors* are used for slightly different purposes.

As explained previously, *vector clocks* are used to maintain a logical form of time, which can then be used to identify when events are happening, especially in comparison to other events.

On the other hand, *version vectors* are better suited for applications that store data, where every data item is tagged with a *version vector*. In this way, data can potentially be updated in multiple parts of the system concurrently (e.g., when there is a network partition). So, the *version vectors* from the resulting data items can help us identify those items that can be reconciled automatically and those that require conflict resolution.

*Version vectors* maintain a state identical to that in a *vector clock*, and contain one integer entry per node in the system.

## Rules for the protocol[#](#Rules-for-the-protocol)

The update rules for *version vectors* are slightly different: nodes can experience both local updates (e.g., a write applied at a server) or can synchronize with another node (e.g., when recovering from a network partition).

* Initially, all vectors have all their elements set to zero.
* Each time a node experiences a local update event, it increments its
  own counter in the vector by one.
* Each time two nodes aaa and bbb synchronize, they both set the elements in
  their vector to the maximum of the elements across both vectors Va[x]=Vb[x]=max(Va[x],Vb[x])V\_a[x] = V\_b[x] = max(V\_a[x], V\_b[x])Va​[x]=Vb​[x]=max(Va​[x],Vb​[x]). After synchronization, both nodes will have the same vectors.

Furthermore, depending on whether the initial vectors were causally related or not, one of the associated items will supersede the other, or some *conflict resolution* logic will be executed to maintain one entry associated with the new vector.

## Working of version vectors[#](#Working-of-version-vectors)

*Version vectors* are mostly beneficial in systems that act as datastores, so the nodes in the system will belong to two basic categories: the **server** or **replica** nodes that store the data and receive read/write operations and the client nodes that read data from the replica nodes and send update instructions.

In many cases, clients might not even be part of our systems, such as in scenarios where our system receives operations directly from customers’ web browsers. As a result, it is better to avoid a significant amount of logic and storage overheads in the client nodes.

The *version vector* mechanism allows this in the following way:

* One entry is maintained for every node (both replica/server and client nodes)

However, the client nodes can be stateless, which means they do not store the *version vectors*. Instead, they receive a *version vector* as part of every read operation, and they provide this *version vector* when executing an update operation back to the corresponding replica node.

> According to Perguica et al., this is only possible in an environment where client nodes are not supposed to experience any local events but only interact with server nodes via read/write operations. It also requires us to read our writes semantics (i.e., obtained via read/write quorums) so that each read returns the most recent update to a client.

This vector is referred to as “context”, and the replica node uses it to update its *version vector* accordingly.

### Version vectors with per-client entries[#](#Version-vectors-with-per-client-entries)

The following illustration contains an example execution in a distributed system using *version vectors* with one entry for each node.

Created with Fabric.js 3.6.6

1 / 12

A distributed systems of two Replica Nodes and three Client Nodes

Created with Fabric.js 3.6.6

1 / 12

Replica nodes are initialised with empty version vector { } and a value U

Created with Fabric.js 3.6.6

1 / 12

All the Client nodes read the current value U with the corresponding version vector { } from the Client B

Created with Fabric.js 3.6.6

1 / 12

Client Node C sends a write request PUT to the Replica node C, the first argument is the version vector { } it previously read from the Replica node B, the second argument is the identifier of the Client Node which is C in this case, the third one V is the value to be written

Created with Fabric.js 3.6.6

1 / 12

The Replica Node B increments the entry in the vector, C is the identifier of the Client node, 1 represents that the Replica node B received a write request from the Client C for the first time, and V is the value

For simplicity, the example assumes there is only one item, so all clients operate on the same item. It can easily be extended to cover cases with multiple items, where each item has a separate *version vector* and the clients have to provide an identifier for the item to be accessed.

Each read operation returns the current value with the corresponding *version vector*.

Each write operation has three arguments:

* The version vector that is given as context
* The identifier of the client node
* The value to be written

The replica node is responsible for incrementing the appropriate entry in the vector (depending on the identifier of the client) and then persisting the new value.

Note that this new value can either be persisted alongside other values that were written concurrently, or overwrite values that causally precede it.

In the first case, multiple values will be returned in subsequent reads and the following write operations will reconcile them and persist a single value.

In the above example, if node DDD performed a read from node BBB (which will return both values VVV and WWW and their *version vectors*) and then attempted to write the value ZZZ, then the update will be of the form PUT({(C,1),(D,1)},D,Z)PUT(\lbrace(C,1), (D,1)\rbrace, D, Z)PUT({(C,1),(D,1)},D,Z). The replica node will calculate the new *version vector* {(C,1),(D,2)}\lbrace(C,1), (D,2)\rbrace{(C,1),(D,2)} and will identify it supersedes both existing version vectors {(C,1)}and{(D,1)}\lbrace(C,1)\rbrace and \lbrace(D,1)\rbrace{(C,1)}and{(D,1)}. So it will replace values VVV and WWW, both with ZZZ.

> The approach of including entries in the *vector clock* for all client nodes is safe. It can successfully identify when two different versions have been written concurrently, or if one of them causally precedes the other one and can be discarded.

### Limitation of vector clocks with per-client entries[#](#Limitation-of-vector-clocks-with-per-client-entries)

The main limitation of the *vector clocks* is that their size does not scale nicely.

In **distributed systems** that are used as distributed datastores, the number of clients tends to be a lot bigger than the number of server nodes by two or three orders of magnitude. For instance, in many cases, each item is replicated in three different servers, while thousands of clients access this item.

Note that even in cases where the clients of the systems are a few application servers, a separate entry in the vector clock needs to be maintained for each server that executes operations concurrently from multiple threads.

As a result, this approach requires a significant amount of storage.

## Coping with the limitation[#](#Coping-with-the-limitation)

Ideally, we want the size of the *vector clocks* to scale with the number of server nodes instead of the number of clients.

### Version vectors with per-server entries[#](#Version-vectors-with-per-server-entries)

Could we remove the client entries from the *vector clocks* and let the servers increment their own entries when performing the updates on behalf of the clients?

Unfortunately, no. If we did this, the system would not be able to detect that some operations were performed concurrently, and would discard values that should have been preserved.

### Issues while using vector clocks with per-server entries[#](#Issues-while-using-vector-clocks-with-per-server-entries)

The following illustration shows the issues with this approach.

Created with Fabric.js 3.6.6

1 / 12

A distributed systems of two Replica Nodes and three Client Nodes

Created with Fabric.js 3.6.6

1 / 12

Replica nodes are initialised with empty version vector { } and a value U

Created with Fabric.js 3.6.6

1 / 12

All the Client nodes read the current value U and the corresponding version vector { } from the Client B

Created with Fabric.js 3.6.6

1 / 12

Client Node C sends a write request PUT to the Replica node C, the first argument is the version vector { } it previously read from the Replica node B, the second argument V is the value to be written

Created with Fabric.js 3.6.6

1 / 12

The Replica Node B increments the entry in the vector with its own identifier, 1 represents that the Replica node B received a write request for the first time, and V is the value

As we can see, the first write operations performed by client nodes CCC and DDD are concurrent. However, server node BBB would not be able to identify that. Node BBB would consider the version vector of the second update {(B,2)}\lbrace(B,2)\rbrace{(B,2)} to supersede {(B,1)}\lbrace(B,1)\rbrace{(B,1)}, discarding the value VVV and replace it with the value WWW.

> There is a technique that makes it possible to successfully identify concurrent versions and also allows the *version vectors* to scale with the number of servers. This is called **dotted version vectors**, which we will learn about in the [next](https://www.educative.io/courses/distributed-systems-practitioners/dotted-version-vectors) lesson.

Backlesson

Mark As CompletedComplete

Next

Vector Clocks

Dotted Version Vectors

Ask

[Comparing version vectors with vector clocks](#Comparing-version-vectors-with-vector-clocks)

[Rules for the protocol](#Rules-for-the-protocol)

[Working of version vectors](#Working-of-version-vectors)

[Version vectors with per-client entries](#Version-vectors-with-per-client-entries)

[Limitation of vector clocks with per-client entries](#Limitation-of-vector-clocks-with-per-client-entries)

[Coping with the limitation](#Coping-with-the-limitation)

[Version vectors with per-server entries](#Version-vectors-with-per-server-entries)

[Issues while using vector clocks with per-server entries](#Issues-while-using-vector-clocks-with-per-server-entries)

---


# Dotted Version Vectors

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Dotted Version Vectors

# Dotted Version Vectors

Let's learn what dotted version vectors are and how they provide scaling of version vectors.

We'll cover the following...

* [Characteristic that makes it possible to scale version vectors](#Characteristic-that-makes-it-possible-to-scale-version-vectors)

**Dotted version vectors** is a technique that makes it possible to successfully identify concurrent versions, and allows the version vectors to scale with the number of servers.

The following characteristic of this technique allows it to achieve this.

## Characteristic that makes it possible to scale version vectors[#](#Characteristic-that-makes-it-possible-to-scale-version-vectors)

Each entry in the vector is not a single number anymore, but a pair of numbers. This can encode a sequence of numbers that are not fully sequential but contain one gap.

The pair (n1,n2)(n\_1,n\_2)(n1​,n2​) represents all the numbers from 111 to n1n\_1n1​ plus the number n2n\_2n2​.

For example, the pair (4,7)(4,7)(4,7) represents the sequence [1,2,3,4,7][1,2,3,4,7][1,2,3,4,7]. Note that the second number is optional and some entries can still be a single number. This can be leveraged to keep track of concurrency between multiple versions.

The order between the two versions is now defined in terms of the contains relationship on the corresponding sequences. So, for vectors v1v\_1v1​, v2v\_2v2​ the relationship v1≤v2v\_1\leq v\_2v1​≤v2​ holds if the sequence represented by v1v\_1v1​ is a subset of the sequence represented by v2v\_2v2​. More specifically:

* (m)≤(m′)(m) \leq (m^{\prime})(m)≤(m′) if m≤m′m \leq m^{\prime}m≤m′
* (m)≤(m′,n′)(m)\leq(m^{\prime},n^{\prime})(m)≤(m′,n′) if m≤m′∨m=m′+1=n′m\leq m^{\prime} \vee m=m^{\prime}+1=n^{\prime}m≤m′∨m=m′+1=n′
* (m,n)≤(m′)(m,n)\leq(m^{\prime})(m,n)≤(m′) if n≤m′n\leq m^{\prime}n≤m′
* (m,n)≤(m′,n′)(m,n)\leq(m^{\prime},n^{\prime})(m,n)≤(m′,n′) if n≤m′∨(m≤m′∧n=n′)n\leq m^{\prime} \vee (m\leq m^{\prime}\wedge n=n^{\prime})n≤m′∨(m≤m′∧n=n′)

The update rule executed by each replica node when it receives a write operation is also slightly different.

For all the indexes except the one belonging to the replica node, the node uses the value (m)(m)(m) where mmm is the maximum number amongst those available in the provided *version vectors* in the context.

For the index corresponding to the replica node, the node uses the pair (m,n+1)(m, n+1)(m,n+1), where mmm is the maximum number amongst those available in the provided *version vectors* in the context, and nnn is the maximum number amongst the *version vectors* present in the replica node (essentially the value of its logical clock).

> For a more elaborate analysis of the rules and formal proof that this technique is safe, refer to the original paper.

The following illustration shows what a solution with *dotted version vectors* would look like in our previous examples.

Dotted version vectors

As we can see, the write operations by client nodes CCC and DDD end up receiving version vectors {(B,0,1)}\lbrace(B,0,1)\rbrace{(B,0,1)} and {(B,0,2)}\lbrace(B,0,2)\rbrace{(B,0,2)} and they are successfully identified as concurrent, since {(B,0,1)}≰{(B,0,2)}\lbrace (B,0,1) \rbrace \nleq \lbrace (B,0,2) \rbrace{(B,0,1)}≰{(B,0,2)} and {(B,0,2)}≰{(B,0,1)}\lbrace (B,0,2) \rbrace \nleq \lbrace (B,0,1) \rbrace{(B,0,2)}≰{(B,0,1)}.

Backlesson

Mark As CompletedComplete

Next

Version Vectors

Distributed Snapshot Problem

Ask

[Characteristic that makes it possible to scale version vectors](#Characteristic-that-makes-it-possible-to-scale-version-vectors)

---


# Distributed Snapshot Problem

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Distributed Snapshot Problem

# Distributed Snapshot Problem

Let's look into the problem of capturing distributed snapshots.

We'll cover the following...

* [Problem](#Problem)
* [Capturing distributed snapshots](#Capturing-distributed-snapshots)
  + [State of a distributed system](#State-of-a-distributed-system)
    - [Challenge in recording the state](#Challenge-in-recording-the-state)
      * [Analogy](#Analogy)
      * [Relating the analogy to distributed systems](#Relating-the-analogy-to-distributed-systems)
  + [Consistent snapshot](#Consistent-snapshot)
    - [Example](#Example)

There is another basic problem in distributed systems that is strongly related to the notion of **time** and **order**. It is stated below.

## Problem[#](#Problem)

Here is the problem: how to record a **snapshot** of the state of a distributed system comprising of multiple nodes that perform a continuous computation?

> There are many more problems in distributed systems that can be expressed in terms of the problem of detecting a global state and specific properties associated with it. We will only focus on the *distributed snapshots* problem in this lesson.

*Distributed snapshots* can be used as a recovery mechanism from a point in the past when failures happen.

## Capturing distributed snapshots[#](#Capturing-distributed-snapshots)

A seminal algorithm used for capturing *distributed snapshots* is the Chandy-Lamport algorithm.

### State of a distributed system[#](#State-of-a-distributed-system)

The state of a distributed system consists of the state of the various nodes and any messages that are in transit between the nodes.

#### Challenge in recording the state[#](#Challenge-in-recording-the-state)

The main challenge in recording the state of a distributed system is that the nodes that are part of the system do not have a common clock. So, they cannot record their local states at precisely the same instant.

As a result, the nodes have to coordinate with each other by exchanging messages so that each node records its state and the state of associated communication channels. Thus, the collective set of all node and channel states forms a global state.

Furthermore, any communication required by the *snapshot* protocol should not alter the underlying computation.

The paper presents a very interesting and illuminating analogy for this problem.

##### Analogy[#](#Analogy)

Imagine a group of photographers observing a panoramic, dynamic scene such as a sky filled with migrating birds. This scene is so big that a single photograph cannot capture it. As a result, the photographers must take several *snapshots* and piece them together to form a picture of the overall scene. The *snapshots* cannot be taken at the same time, and the photographers should not disturb the process that is being photographed, i.e., they cannot get all the birds to remain motionless while the photographs are taken.

However, the composite picture should be meaningful.

##### Relating the analogy to distributed systems[#](#Relating-the-analogy-to-distributed-systems)

As discussed in the analogy, the composite picture should be meaningful. This need for a meaningful *snapshot* also exists when talking about distributed systems.

For example, there’s no point in recovering a *snapshot* if that *snapshot* can lead the system to an erroneous or corrupted state.

A meaningful *snapshot* is termed as a **consistent snapshot** in the paper, which presents a formal definition of what this is.

An alternative definition is that of a **consistent cut** by Friedemann, which partitions the space-time diagram along the time axis in a way that respects causality, e.g., for each pair of events eee and fff, if fff is in the cut and e→fe\to fe→f, then eee is also in the cut.

> Note that the Chandy-Lamport algorithm produces snapshots that are also *consistent cuts*.

The formal definition of *consistent snapshot* will be presented here in a more simplified way for ease of understanding.

### Consistent snapshot[#](#Consistent-snapshot)

Let’s assume a distributed system can be modeled as a directed graph, where vertices represent nodes of the system and edges represent communication channels.

An event eee in a node ppp is an atomic action that may change the state of ppp itself and the state of at most one channel ccc incident on ppp: the state of ccc may be changed by the sending of a message MMM along ccc (if ccc is an outbound edge from ppp) or the receipt of a message MMM along ccc (if ccc is an inbound edge to ppp).

So, an event eee could be represented by the tuple <p,s,s′,M,c><p, s, s^{\prime}, M, c><p,s,s′,M,c>, where sss and s′s^{\prime}s′ are the previous and new state of the node.

An event eie\_iei​ moves the global state of the system from SiS\_iSi​ to Si+1S\_{i+1}Si+1​.

A snapshot SsnapshotS\_{snapshot}Ssnapshot​ is thus consistent if:

* SsnapshotS\_{snapshot}Ssnapshot​ is reachable from the state SstartS\_{start}Sstart​ in which the algorithm was initiated.
* the state SendS\_{end}Send​ in which the algorithm terminates is also reachable from SsnapshotS\_{snapshot}Ssnapshot​.

#### Example[#](#Example)

Let’s look at an example to get some intuition about *consistent snapshot*. Let’s assume we have a very simple distributed system consisting of two nodes ppp, qqq and two channels ccc, c′c^{\prime}c′, as shown in the following illustration.

A simple distributed system consisting of two nodes and two communication channels

The system contains one token that is passed between the nodes. Each node has two possible states s0s\_0s0​ and s1s\_1s1​, where s0s\_0s0​ is the state in which the node does not possess the token and s1s\_1s1​ is the state in which it does. The following illustration contains the possible global states of the systems and the associated transitions.

The possible global states and the corresponding transitions of the token system

As a result,

* A *snapshot* where the state is s0s\_0s0​ for both of the nodes and the state of both channels is empty would not be consistent, since the token is lost
* A snapshot where the states are s1s\_1s1​ and s0s\_0s0​ and channel ccc contains the token is also not consistent since there are now two tokens in the system

Backlesson

Mark As CompletedComplete

Next

Dotted Version Vectors

Solving the Distributed Snapshot Problem

Ask

[Problem](#Problem)

[Capturing distributed snapshots](#Capturing-distributed-snapshots)

[State of a distributed system](#State-of-a-distributed-system)

[Challenge in recording the state](#Challenge-in-recording-the-state)

[Analogy](#Analogy)

[Relating the analogy to distributed systems](#Relating-the-analogy-to-distributed-systems)

[Consistent snapshot](#Consistent-snapshot)

[Example](#Example)

---


# Solving the Distributed Snapshot Problem

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Solving the Distributed Snapshot Problem

# Solving the Distributed Snapshot Problem

Let's explore a seminal algorithm used for capturing distributed snapshots.

We'll cover the following...

* [Chandy-Lamport algorithm](#Chandy-Lamport-algorithm)
  + [Idea](#Idea)
  + [Working](#Working)

## Chandy-Lamport algorithm[#](#Chandy-Lamport-algorithm)

The Chandy Lamport algorithm solves the consistent snapshot problem in a distributed system.

### Idea[#](#Idea)

The algorithm is based on the following main idea: a marker message is sent between nodes using the available communication channels that represent an instruction to a node to record a snapshot of the current state.

### Working[#](#Working)

The algorithm works as follows:

* The node that initiates the protocol records its state and then sends a marker message to all the outbound channels.

> Importantly, the marker is sent after the node records its state and before any further messages are sent to the channels.

* When a node receives a marker message, its behaviour depends on whether the node has already recorded its state (while emitting the mark previously) or not.
  + If the node has not recorded its state, it records its state, and then it records the state of the channel ccc the marker was received from as an empty sequence. It then sends the marker to all the outbound channels.
  + If the node has recorded its state, it records the state of the channel the marker was received from as the sequence of messages received from ccc after the node’s state was recorded and before the node received the marker from ccc.

The following illustration contains a sample execution of this algorithm on the simple system presented previously.

Created with Fabric.js 3.6.6

1 / 7

A system of two nodes, initially Node p has the token

Created with Fabric.js 3.6.6

1 / 7

Node p sends the token on the channel, so its state changes to 0. Node p initiates the protocol, so it records its state and then sends the marker message on the channel.

Created with Fabric.js 3.6.6

1 / 7

Node q receives the token, so its state changes to 1

Created with Fabric.js 3.6.6

1 / 7

Node q sends the token on the channel, its state changes to 0

Created with Fabric.js 3.6.6

1 / 7

Node q receives the marker message. Since Node q has not recorded its state before, it records its state, and then it records the state of the channel ( p->q ) the marker was received from as an empty sequence.

The node ppp sends the token and, right after, initiates the execution of the protocol.

As a result, it records its state s0s\_0s0​ and sends the marker in channel ccc. The node qqq receives the token, transitions to state s1s\_1s1​. It then sends the token to channel c′c^{\prime}c′ and transitions to state s0s\_0s0​.

Afterward, it receives the marker message, records its state s0s\_0s0​ and the state of channel ccc as an empty sequence, and sends the marker message to channel c′c^{\prime}c′.

> Note that this is just one of the possible executions. In an alternative execution, node qqq could have processed both the token and the marker, recording its state as s1s1s1 and potentially sending the marker across channel c′c^{\prime}c′ without sending the token yet. This would have led to a different but still *consistent snapshot*.

Meanwhile, node ppp receives the token, transitions to state s1s\_1s1​, and buffers the token in the sequence of messages received while the snapshot protocol was executing. The node ppp then receives the marker and records the state of the channel c′c^{\prime}c′ as the sequence [token].

At this point, the protocol concludes, since the state of all nodes and channels has been recorded and the global snapshot state is the following:

snapshot(ppp): s0s\_0s0​   
snapshot(qqq): s0s\_0s0​   
snapshot(ccc): []   
snapshot(c′c^{\prime}c′): [token]

If a node receives a marker on channel X after it has already recorded its state, how does it determine which in-transit messages to attribute to channel X, and why does this rule prevent double-counting across channels? Provide your answer in the widget given below.

Want to know the correct answer?

Capturing In-Transit Messages After Recording

Enter your answer here

﻿

Evaluate

Beta

750 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Distributed Snapshot Problem

Physical and Logical Time: Closing Thoughts

Ask

[Chandy-Lamport algorithm](#Chandy-Lamport-algorithm)

[Idea](#Idea)

[Working](#Working)

---


# Physical and Logical Time: Closing Thoughts

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Physical and Logical Time: Closing Thoughts

# Physical and Logical Time: Closing Thoughts

Let's conclude the time and order chapters with a clear understanding of the difference between physical and logical time and what each one offers.

We'll cover the following...

* [Difference between physical and logical time](#Difference-between-physical-and-logical-time)
  + [Physical time](#Physical-time)
  + [Logical time](#Logical-time)
* [Points to be noted](#Points-to-be-noted)
* [Advantages and disadvantages of physical time](#Advantages-and-disadvantages-of-physical-time)
* [Advantages and disadvantages of logical time](#Advantages-and-disadvantages-of-logical-time)

Hopefully, the two previous chapters helped us understand the difference between the concepts of physical and logical time. At the same time, some parts went into detail to explain the inner workings of some techniques and their benefits and pitfalls. This might have left us with more questions, so this lesson will contain an overview of what we have seen and some additional observations.

Let’s start by reviewing the basic difference between physical and logical time.

## Difference between physical and logical time[#](#Difference-between-physical-and-logical-time)

### Physical time[#](#Physical-time)

*Physical time* is measured based on some physical phenomena. Depending on the phenomenon that is observed, the granularity of *physical time* can differ from days to seconds or nanoseconds.

In all cases, the time flows continually between discrete values.

> Time can be considered discrete in the context of hardware or software systems. Whether this is true in other contexts (i.e., physics) is a much bigger question and is out of topic for this discussion.

* In a non-distributed system, a computing node can use these measurements to associate occurring events and compare them with each other to determine which happened first.
* In a distributed system, the various nodes have separate clocks that might not be in sync, so they will have to do additional work to ensure the values from their clocks can be compared safely. This additional work involves exchanging messages between nodes that contain the values of their clocks so that nodes can adjust their clocks accordingly to synchronize them.

### Logical time[#](#Logical-time)

*Logical time* is not measured based on physical phenomena, but instead uses local events to measure *logical time*.

For instance, the node can maintain a counter that is incremented every time something happens. In this way, every event can still be associated with a discrete “moment in time” but the value of this time will be most relative and not absolute.

Furthermore, *logical time* will not flow continuously, but will only flow when events happen at a node. The node will still be able to compare local events and determine which one happened first.

As mentioned before, these instances of time do not have any absolute semantics. As a result, in a distributed system, the various nodes will have to exchange their perception of logical time so that they can compare the values of their logical clocks and be able to order events across different nodes (and clocks).

## Points to be noted[#](#Points-to-be-noted)

> After reading the difference between physical and logical time, did you notice anything interesting?

In the beginning, the concepts of physical and logical time do seem really different. However, a closer examination reveals they are quite similar and actually share some basic properties.

In both cases, time flows in discrete increments every time something happens.

* In the case of *physical time*, what happens is the underlying physical phenomenon.
* In the case of *logical time* it’s the actual logical event that happens in a node.

In both cases, communication is required between nodes to synchronize their clocks.

* In the case of *physical time*, this communication is performed in the background continuously.
* In the case of *logical time*, this communication is performed on-demand when messages are sent between nodes.

> Identifying that these two notions make use of these common, basic principles but in a slightly different way is useful to understand the advantages and disadvantages of each concept and where each one can be useful.

## Advantages and disadvantages of physical time[#](#Advantages-and-disadvantages-of-physical-time)

By its nature, *physical time* attempts to perform all the necessary coordination and communication in the background so that the various nodes can establish **order** without additional coordination when needed.

In most cases, physical clocks are used in order to provide the illusion of a **total order**, which is not realistic in a distributed system.

Furthermore, physical clocks need to remain properly synchronized, which might not be temporarily possible under network partitions. If the **clock drift** between nodes is larger than the acceptable error, it might mean the **correctness** of the application is compromised.

## Advantages and disadvantages of logical time[#](#Advantages-and-disadvantages-of-logical-time)

*Logical time* operates under the assumption that **network partitions** are given, and a **partial order** satisfying **causality** is the best kind of ordering one can achieve in a distributed system. During partitions, different nodes can keep operating while essentially leaving their *clock drift*.

However, when partitions are healed, or nodes communicate with each other, they can eventually detect things that happened concurrently and perform the necessary reconciliation.

Logical clocks can also be adapted so that only necessary causal relationships are captured (instead of everything), thus achieving both good ***performance*** and ***safety***.

However, as explained previously *logical time* does not flow on its own as *physical time* does; it only flows when events happen. Consequently, logical time cannot be used for tasks that require a notion of wall clock time that flows even when no events happen. For instance, to identify whether another node is slow during communication or has potentially crashed, a node needs to use ***timeouts*** and ***physical time***.

Consider a distributed e-commerce platform with servers located in different regions. Users interact with the platform to browse products, add items to their carts, and make purchases. The system aims to maintain accurate timestamps for user activities.

Describe how the platform can face challenges related to physical and logical time in this distributed environment. Provide specific examples of scenarios where physical time synchronization and logical time concepts, such as vector clocks or Lamport clocks, play crucial roles. Explain how these timekeeping mechanisms can address the challenges and ensure consistency in recording user interactions across the distributed servers.

Want to know the correct answer?

Address time challenges in a distributed environment, both physically and logically.

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Solving the Distributed Snapshot Problem

Quiz on Event Ordering

Ask

[Difference between physical and logical time](#Difference-between-physical-and-logical-time)

[Physical time](#Physical-time)

[Logical time](#Logical-time)

[Points to be noted](#Points-to-be-noted)

[Advantages and disadvantages of physical time](#Advantages-and-disadvantages-of-physical-time)

[Advantages and disadvantages of logical time](#Advantages-and-disadvantages-of-logical-time)

---


# Quiz on Event Ordering

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Event Ordering

# Quiz on Event Ordering

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

True or False: A skew between the clocks of different nodes is one reason why the **total ordering** of events in a distributed system is hard to achieve.

A.

True

B.

False

---

1 / 4

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Physical and Logical Time: Closing Thoughts

Introduction

Ask

---


# Introduction

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction

# Introduction

Get an introduction to the networking concepts for distributed systems.

We'll cover the following...

* [Rewinding fallacies that are relevant to networking](#Rewinding-fallacies-that-are-relevant-to-networking)
* [Networking protocols](#Networking-protocols)
  + [Internet protocol suite](#Internet-protocol-suite)

The previous lesson taught us about the end nodes of a distributed system, which treats the **network** that connects them as a black box.

End nodes connected through a network

> This chapter will examine the various components of this *network*, which facilitates communication between the nodes that form a distributed system.

Applications typically rely on a set of well-specified protocols which allow these applications to perform their functions at a high-level of proficiency, without the need to deal with low-level details. This means that people can build applications in many cases without the knowledge of how these lower levels functions work.

However, this knowledge does enable us to create **scalable**, **efficient**, and **fault-tolerant** distributed systems and also troubleshoot issues more efficiently, as they arise.

This chapter contains a brief overview of the basic technologies and protocols used to interconnect multiple computing nodes.

## Rewinding fallacies that are relevant to networking[#](#Rewinding-fallacies-that-are-relevant-to-networking)

If we revisit the fallacies of distributed computing, we will notice that many of them are relevant to this chapter:

* The network is reliable.
* The latency is zero.
* The bandwidth is infinite.
* The topology doesn’t change.
* The transport cost is zero.
* The network is homogeneous.

> We encourage the reader to keep these fallacies in mind, as they go through the lessons of this chapter.

## Networking protocols[#](#Networking-protocols)

There are many different networking protocols and technologies in use nowadays that to cover them all in a single course would be nothing short of a herculean task. As a result, this course will only focus on covering the **Internet protocol suite**, which is the most pre-dominantly used protocol these days.

However, the problems solved by these protocols are general and they rely on fundamental principles that manifest in other models as well, such as the **OSI** model.

### Internet protocol suite[#](#Internet-protocol-suite)

The Internet protocol suite follows a layered architecture, where the overall functionality is divided into separate layers that contain a set of distinct protocols. Each layer provides a service to the next layer above and makes use of the services provided by the layer below.

Starting from the top, there are five layers, namely:

* The application layer
* The transport layer
* The network layer
* The link layer
* The physical layer

When data is received from the layer above, each layer wraps this data along with the necessary metadata for the corresponding protocol, as is shown in the illustration below. This metadata is typically referred to as ***headers***, while the actual data is referred to as a ***payload***.

Layers of the Internet protocol suite

When data is passed from lower-level layers to higher-level layers, the reverse process is followed. In this case, the *payload* is extracted and handed off to the layer above. These processes are also known as ***encapsulation*** and ***decapsulation*** accordingly.

> **Note:** This chapter will examine each of those layers and their protocols to understand the problems that each layer attempts to tackle and how they are solved. We will follow a bottom-up approach starting from the layers at the bottom of the stack and moving up one step at a time.

Backlesson

Mark As CompletedComplete

Next

Quiz on Event Ordering

The Physical Layer

Ask

[Rewinding fallacies that are relevant to networking](#Rewinding-fallacies-that-are-relevant-to-networking)

[Networking protocols](#Networking-protocols)

[Internet protocol suite](#Internet-protocol-suite)

---


# The Physical Layer

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Physical Layer

# The Physical Layer

We'll cover the following...

* [Services provided by the physical layer](#Services-provided-by-the-physical-layer)
  + [Line coding](#Line-coding)
  + [Modulation/demodulation](#Modulationdemodulation)
  + [Carrier sense and collision detection](#Carrier-sense-and-collision-detection)
  + [Auto-negotiation](#Auto-negotiation)
* [Transmission medium](#Transmission-medium)
  + [Guided media](#Guided-media)
    - [Twisted pair cabling](#Twisted-pair-cabling)
    - [Coaxial cable](#Coaxial-cable)
    - [Fiber-optic cable](#Fiber-optic-cable)
  + [Unguided media](#Unguided-media)
* [Technologies that provide physical layer services](#Technologies-that-provide-physical-layer-services)
  + [Ethernet](#Ethernet)
  + [Wi-fi](#Wi-fi)
* [Providing physical layer services to computer](#Providing-physical-layer-services-to-computer)

The **physical layer** is responsible for the transmission of data in the form of raw bits over a physical link between two connected nodes.

> Note: The data is transmitted through a medium that can take up many different forms, as we will see later on.

## Services provided by the physical layer[#](#Services-provided-by-the-physical-layer)

Now we will see some of the services that are provided by the physical layer:

### Line coding[#](#Line-coding)

This is the process of encoding digital data in the form of bits, into a pattern of voltage, current, or photons that can be transmitted through a physical medium.

Some examples of line coding are unipolar, polar, bipolar, and Manchester code, as we can see in the following illustration.

Different line codes

* In **unipolar line coding**, binary 1 is encoded as positive voltage and binary 0 is encoded as zero voltage.
* In **polar line coding**, binary 1 is encoded as positive voltage and binary 0 is encoded as negative voltage.
* In **bipolar line coding**, binary 0 is encoded as zero voltage and binary 1 is encoded alternately as a positive or negative voltage.
* In **Manchester line coding**, a binary 0 is encoded as a transition from low to high voltage, while a binary 1 is encoded as a transition from high to low voltage.

Each encoding comes with its share of pros and cons. As a result, the suitability of the encoding pattern depends on other factors, such as the transmission medium.

### Modulation/demodulation[#](#Modulationdemodulation)

This is the process of mixing a signal that corresponds to the digital data we want to transmit, known as the ***data signal*** or the ***message signal*** with a separate periodic signal, known as the ***carrier signal***. This is done to convert the signal into a form that is more suitable for transmission.

For example, the frequency of a carrier signal depends on the data that is transmitted. Multiple data signals can be sent over a channel, if we use multiple carriers at slightly different frequencies. This also has practical benefits. Antennas need to be about one-tenth the length of the signal’s wavelength, so it’s economical to use higher frequencies.

The three basic types of modulation are:

* Amplitude modulation
* Frequency modulation
* Phase modulation

### Carrier sense and collision detection[#](#Carrier-sense-and-collision-detection)

This is the process that is used to determine whether or not another device is transmitting data over the medium, and if another device transmitted data concurrently in the medium, which led to a collision and potential loss/corruption of the transmitted data.

### Auto-negotiation[#](#Auto-negotiation)

This is the process used to make two or more sides of a network connection agree on the same set of parameters used for communication, such as speed and transmission mode for example *simplex* or *duplex*.

In practice, devices advertise what they can support, and then the highest performance transmission mode supported on both sides is selected.

## Transmission medium[#](#Transmission-medium)

There are many different physical media, which can be classified into two main categories:

* Guided media
* Unguided media

### Guided media[#](#Guided-media)

**Guided media** uses a physical path or conductor to transmit the signal in a specific direction. That’s why it is also called **wired communication**.

Some examples of wired media are:

#### Twisted pair cabling[#](#Twisted-pair-cabling)

Twisted pair cabling is a type of wiring in which two conductors of a single circuit are twisted together to improve electromagnetic compatibility through the reduction of electromagnetic radiation from the pair and external electromagnetic interference from other sources. These cables are typically made of copper wires.

#### Coaxial cable[#](#Coaxial-cable)

Coaxial cable is a type of electrical cable, which consists of an inner conductor that is surrounded by a concentric conducting shield. The conductor and the conducting shield are separated by a dielectric (insulating material).

#### Fiber-optic cable[#](#Fiber-optic-cable)

A fiber-optic cable contains one or more optical fibers, which are used to carry light. Typically, these fibers are individually coated with plastic layers and contained in a protective tube that is suitable for the environment where the cable will be deployed.

### Unguided media[#](#Unguided-media)

Unguided media broadcasts the signal through the air, and does not direct the signal. This is why it is also known as **wireless communication**.

Some examples of wireless media are radio waves, microwaves, and infrared light. These are all different forms of electromagnetic radiation with different frequencies.

## Technologies that provide physical layer services[#](#Technologies-that-provide-physical-layer-services)

Many different technologies provide physical layer services, such as DSL, ISDN, Bluetooth, and USB.

> Note: Ethernet and Wi-fi are the basic underpinnings of the Internet, so we will focus on them now.

### Ethernet[#](#Ethernet)

Ethernet is part of the IEEE 802.3 standard that defines both the physical layer specifications and the associated link layer protocols, which we will examine later. It can be carried over various physical media, including coaxial cable, copper wire, and optical fiber. As a result, it comes in many different forms.

Some examples of Ethernet are 10BASE-2, 10BASE-T and 10BASE-F, where the first component indicates the speed of the standard (for example, 10Mbit/s) and the last part indicates the medium (for example, coaxial cable, twisted pair cable, or fiber-optic cable).

### Wi-fi[#](#Wi-fi)

Wi-fi is part of the IEEE 802.11 standard that defines the physical layer specifications and the associated link layer protocols used to achieve wireless communication.

## Providing physical layer services to computer[#](#Providing-physical-layer-services-to-computer)

Physical layer services are provided to a computer through a **network interface card**. This is a hardware component that connects a computer to other computers via a wired or wireless medium.

A *network interface card* is typically associated with an address called the **MAC address**, which is used to uniquely identify the device in the immediate network of devices.

Backlesson

Mark As CompletedComplete

Next

Introduction

The Link Layer - Services

Ask

[Services provided by the physical layer](#Services-provided-by-the-physical-layer)

[Line coding](#Line-coding)

[Modulation/demodulation](#Modulationdemodulation)

[Carrier sense and collision detection](#Carrier-sense-and-collision-detection)

[Auto-negotiation](#Auto-negotiation)

[Transmission medium](#Transmission-medium)

[Guided media](#Guided-media)

[Twisted pair cabling](#Twisted-pair-cabling)

[Coaxial cable](#Coaxial-cable)

[Fiber-optic cable](#Fiber-optic-cable)

[Unguided media](#Unguided-media)

[Technologies that provide physical layer services](#Technologies-that-provide-physical-layer-services)

[Ethernet](#Ethernet)

[Wi-fi](#Wi-fi)

[Providing physical layer services to computer](#Providing-physical-layer-services-to-computer)

---


# The Link Layer - Services

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Link Layer - Services

# The Link Layer - Services

Learn about the responsibility of the link layer and the services provided by it.

We'll cover the following...

* [Services provided by the link layer](#Services-provided-by-the-link-layer)
  + [Framing](#Framing)
  + [Link access](#Link-access)
    - [Channel partitioning protocols](#Channel-partitioning-protocols)
    - [Random access protocols](#Random-access-protocols)
    - [Taking-turn protocols](#Taking-turn-protocols)
  + [Reliable delivery](#Reliable-delivery)
    - [Achieving reliable delivery](#Achieving-reliable-delivery)
  + [Error detection and error correction](#Error-detection-and-error-correction)
    - [Checksum technique](#Checksum-technique)
    - [Cyclic redundancy checks](#Cyclic-redundancy-checks)
* [Link layer as a bridge](#Link-layer-as-a-bridge)

While the **physical layer** is responsible for the transmission of good signal through a physical medium, the **link layer** is responsible for the movement of a packet of information from one node to a neighboring node. In this context, we will consider a node to be a neighbouring node if it is connected through a single communication link, regardless of whether it’s wired or wireless.

## Services provided by the link layer[#](#Services-provided-by-the-link-layer)

The link layer can provide the following services:

### Framing[#](#Framing)

This process involves the encapsulation of payloads from the higher layers of the stack into the link layer packet, commonly referred to as a **frame**.

### Link access[#](#Link-access)

A physical link may be shared between multiple nodes, which means that there must be a way to mediate access to this link, so that the nodes can coordinate with each other to ensure only one of them transmits data at a given time. This is achieved through protocols known as **medium access control (MAC) protocols**. These protocols can be grouped into three main categories:

* Channel partitioning protocols
* Random access protocols
* Taking-turn protocols

#### Channel partitioning protocols[#](#Channel-partitioning-protocols)

Channel partitioning protocols partition the channel into parts that can be used concurrently by more than one node. There are three main types of channel partitioning protocols:

* **Time-division multiple access:** This type of protocol is used to assign separate time slots to the nodes for when they are allowed to transmit.
* **Frequency-division multiple access:** This type of protocol is used to assign the specific frequencies on which the nodes are allowed to transmit.
* **Code-division multiple access:** In this protocol type, nodes can transmit concurrently but encode their data using a different encoding scheme.

#### Random access protocols[#](#Random-access-protocols)

As the name implies, random access protocols allow any node to transmit at the full rate of a channel whenever they want, which means that transmissions from multiple nodes may collide and the nodes may need to retransmit that data.

There are many random access protocols, but two of the most well-known and widely adopted protocols are the ALOHA protocol and the CSMA protocol.

* The **ALOHA protocol** is quite simple. When the nodes have data, they transmit it. If they receive data from other nodes while transmitting some other data, they try transmitting the same data again later.
* The **CSMA protocol**, which stands for carrier sense multiple access, is slightly more elaborate since the nodes listen to the channel before transmitting, and they start transmitting only if the channel is idle.

> **Note**: There are multiple variants of CSMA, all of which handle collisions differently, but we will not cover them in this course.

#### Taking-turn protocols[#](#Taking-turn-protocols)

Taking-turn protocols allow nodes to coordinate with each other to acquire access to the medium.

Two of the main taking-turn protocols are:

* The **polling protocol:** This protocol is used to designate a node as the leader node, which is responsible for passing the access to the medium sequentially through the nodes.
* The **token-passing protocol:** This protocol is used where nodes work without a leader node to sequentially pass access to the medium through the nodes. They perform this task on their own by passing a special message (the token), which gives each node access to the medium.

If a wireless network switches from ALOHA to CSMA without changing the physical channel, how and why would collision behavior change during peak traffic? Provide your answer in the widget given below.

Want to know the correct answer?

Collisions Under ALOHA vs CSMA

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

### Reliable delivery[#](#Reliable-delivery)

**Reliable delivery** is the guarantee that the data transmitted over the medium will be received by its destination, regardless of potential complications that might happen. As is explained later on, this reliable delivery is available only at some of the higher layers, so not all of the link layer protocols provide this service.

For performance reasons reliable delivery is often provided in links that are prone to high error rates, such as wireless links. However, in order to avoid extra overhead costs, it is typically not provided for low error rate links, such as wired links.

#### Achieving reliable delivery[#](#Achieving-reliable-delivery)

Reliable delivery is achieved through the transmission of acknowledgment messages from the recipient and retries by the sender.

### Error detection and error correction[#](#Error-detection-and-error-correction)

**Error detection** is the process used to identify the cases in which an error pops up during transmission— due to signal attenuation and electromagnetic noise. This process is also used to recover from that error, through detection of the data that were altered and in which way.

To accomplish this process of error detection and correction, the data is sent alongside an additional piece of redundant data that can be used to determine whether the data have was received as it was originally transmitted or changed in any way. There are many techniques to carry out this process but checksums and cyclic redundancy checks (CRC) are the most common ones.

#### Checksum technique[#](#Checksum-technique)

In **checksumming techniques**, the stream of data is treated as a sequence of k-bit integers, which are summed up to produce the checksum that is sent along with the data.

#### Cyclic redundancy checks[#](#Cyclic-redundancy-checks)

When we use **cyclic redundancy checks**, a list of bits is appended to the data that needs to be sent, so that the resulting number is exactly divisible by a pre-agreed number.

## Link layer as a bridge[#](#Link-layer-as-a-bridge)

> **Note**: The physical layer consists of the specifications of the hardware components, which participate in the transmission of data on a physical medium.

The link layer contains some parts that are implemented in hardware, that is, in the network interface card and other parts that are implemented in software, that is, in device drivers.

The higher layers are implemented exclusively in software. For example, they either come in as part of the kernel of the OS or in third-party libraries.

As a result, the link layer essentially forms a bridge between the hardware and the software.

> **Note**: This is true in the general case, but there are always exceptions, and there may be more in the future given the rapid progress in the evolution of hardware components. As an example, the TCP offload engine is a technology that offloads the processing of higher layers to the network controller in order to achieve higher performance.

Backlesson

Mark As CompletedComplete

Next

The Physical Layer

The Link-Layer Protocols

Ask

[Services provided by the link layer](#Services-provided-by-the-link-layer)

[Framing](#Framing)

[Link access](#Link-access)

[Channel partitioning protocols](#Channel-partitioning-protocols)

[Random access protocols](#Random-access-protocols)

[Taking-turn protocols](#Taking-turn-protocols)

[Reliable delivery](#Reliable-delivery)

[Achieving reliable delivery](#Achieving-reliable-delivery)

[Error detection and error correction](#Error-detection-and-error-correction)

[Checksum technique](#Checksum-technique)

[Cyclic redundancy checks](#Cyclic-redundancy-checks)

[Link layer as a bridge](#Link-layer-as-a-bridge)

---


# The Link-Layer Protocols

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Link-Layer Protocols

# The Link-Layer Protocols

Learn about the link-layer protocols.

We'll cover the following...

* [Ethernet](#Ethernet)
  + [Hub](#Hub)
  + [Switch](#Switch)
* [Wifi](#Wifi)
  + [Ad-hoc mode](#Ad-hoc-mode)
  + [Infrastructure mode](#Infrastructure-mode)
* [Association](#Association)
* [Hidden terminal problem](#Hidden-terminal-problem)
* [Types of frames](#Types-of-frames)

As was mentioned earlier, Ethernet and Wi-fi are the protocols that are widely used to connect devices in wired or wireless settings. Hence, we will provide a quick overview of their basic workings here.

## Ethernet[#](#Ethernet)

Ethernet went through various phases and evolved over time. This meant that changes were made in the specifications, both at the hardware level and on the associated protocols.

Initially, Ethernet aimed to connect multiple computers over a shared coaxial cable, which would act as a broadcast-transmission medium. This topology is also known as a **bus topology**, as shown in the following illustration.

Bus topology

This meant that any data transmitted by a node would be received by all of the other nodes connected to that particular cable.

The network interface card was responsible for reading the metadata of each packet and passing the packets only to the processor they were addressed. In order to carry out this process, each network interface card owns one or multiple unique addresses, which are known as **MAC (media access control) addresses**. These are 48-bit numbers, which are allocated by the IEEE association.

Every Ethernet frame contains a source and a destination MAC address with the latter being used by a network interface card to identify the frames destined to it. There are also some special addresses which allow us to send a frame to multiple network interface cards at a given time. One such example is the **broadcast address**, which is only composed of bits set to one (also represented as FF:FF:FF:FF:FF:FF) and is accepted by all the nodes. The frame also contains other fields, as shown in the illustration below.

The structure of an Ethernet frame

* The **preamble** is a static value, which is used to synchronize the clocks of the sender and the receiver so that the subsequent data is translated in the right way by the recipient.
* The **EtherType** field contains an identifier, which indicates the network-layer protocol the data should be passed to.
* The **payload field** carries the data of the network-layer protocol
* The **CRC** is used to detect bit errors.

Since the medium is shared, if two stations attempt to transmit at the same time, a collision may occur, which can lead to corruption of the transmitted data. Therefore, early versions of Ethernet used a variant of CSMA, known as **CSMA/CD**, to recover from such collisions and transmit data successfully.

For the CSMA/CD protocol to operate efficiently, the specific length limits for a cable segment are specified. This keeps the propagation delay of a collision and signals degradation down to tolerable levels.

Later on, the *bus topology* was replaced by a ***star topology***, in which multiple nodes were connected to a device called repeater or hub with twisted-pair copper wire, as shown in the illustration below.

Hub-based star topology

### Hub[#](#Hub)

A hub is a physical-layer device, which acts on individual bits rather than frames. When a bit arrives from one interface, the hub recreates the bit, boosts its signal strength, and transmits the bit onto the other interfaces. As a result, Ethernet with a hub-based star topology remains a shared-broadcast medium, which means that CSMA/CD is still used.

> **Note**:There are advantages to using star topology as opposed to bus topology. For example, star topology allows for easier installation into buildings that already use star topology cable plans for telephony and better fault-tolerance, as it is able to able to easily disconnect faulty peers and prevent them from affecting other devices on the network.

The next and most recent evolution led to the replacement of hubs at the center of the star topology with devices called switches, which operate at the link layer. This is shown in the following illustration.

Switch-based star topology

### Switch[#](#Switch)

A **switch** receives link-layer frames and forwards them to the specific outgoing links they are addressed to. In order to do this, the switch maintains a switch table that maps MAC addresses to the corresponding interfaces that lead to them. This is done automatically, without the need for manual configuration or extra protocols.

The switch table is initially empty, and the switch adds entries to the table by inspecting the source addresses of incoming frames and associating them to the interface they arrived from.

> **Note:** Every time a switch receives an incoming frame, it searches for an entry that contains the destination address in the table. Recent advancements mean that switches may be able to perform forwarding based on more complicated logic, using more information than just the destination MAC address. One such example of this is the OpenFlow protocol. However, we intentionally focused on the original and simplest use here.

For each frame, a switch finds the interface that corresponds to the destination address. If there is no such entry, the frame is forwarded to all the other interfaces, that is, all interfaces except the one it was received on. This is called **flooding** and is the reason why switches are said to be self-learning or plug-and-play devices.

In cases where nodes are directly connected to switches in a full-duplex mode, there is no possibility of a collision, which means that there is no need for a medium access control protocol, such as CSMA/CD, and the link’s bandwidth is utilized more efficiently.

> **Note:** The use of a switch instead of a hub can also lead to the overall reduction of traffic. Reduced broadcast traffic can, in turn, lead to increased performance in the network.

## Wifi[#](#Wifi)

Wi-Fi uses two basic modes of operation:

* Ad-hoc mode
* Infrastructure mode

### Ad-hoc mode[#](#Ad-hoc-mode)

In **ad-hoc mode**, each node transmits data directly to other nodes.

### Infrastructure mode[#](#Infrastructure-mode)

In **infrastructure mode**, communication typically goes through a central access point (AP), which connects wireless devices (stations) to a wired network. Infrastructure mode is used more widely and in most everyday scenarios, so we will focus on that.

In this mode, there is a **basic service set (BSS)**, which is a group of stations that are all connected to the same access point. Each access point is associated with an identifier, known as the **Service Set Identifier (SSID)**, which is configured by the administrator.

> **Note:** Every wireless station needs to be associated with an access point before it can send or receive data to or from the rest of the network.

## Association[#](#Association)

Association is performed in the following way: APs periodically transmit special messages, called **beacon frames**, which contain the access point’s SSID and MAC address. The wireless station listens for these messages and selects one of them for association or presents them to the user. The user selects a message via the user interface. This process of listening to the medium for beacon frames is known as ***passive scanning***.

A wireless device can also perform ***active scanning*** by broadcasting a probe frame that is received by all the access points within the wireless device’s range. Access points respond to the *probe request frame* with a *probe response frame*. The device sends an *association request frame* to the access point, and the access point responds with an *association response frame* to associate with an AP.

Structure of a Wi-fi network

Once the association is complete, the device starts to send and receive data frames to and from the network.

Given that there can be many wireless devices sharing the same medium, a **multiple access protocol** is needed to coordinate the transmissions. For this reason, 802.11 makes use of CSMA with collision avoidance (CSMA/CA).

***Collision detection*** is replaced with ***collision avoidance***, because the received signal is, typically, weak compared to the strength of the transmitted signal at the 802.11 adapter. Hence, it is costly to build hardware that can detect a collision.

Compared to wired links, wireless links suffer from higher signal attenuation and interference, which makes it more likely for transmitted data to be corrupted. For this reason, an **acknowledgment protocol** is used where a recipient replies to a data message with an **acknowledgment message** to let the sender know that the message was received intact. If the message is not received intact or if the acknowledgment message is lost, the sender will try to send the message again.

The stations introduce additional delays when they sense that the channel is not idle, in order to ensure that another node is not trying to send a frame at the same time. This is the *collision avoidance* part and is introduced because in this protocol, the nodes do not stop transmitting when there is a collision (that is, there is no *collision detection*).

## Hidden terminal problem[#](#Hidden-terminal-problem)

Wireless links are also subject to a problem known as the **hidden terminal problem**. There are cases where two stations are unable to detect each other’s transmissions because they are too far from each other, while still being within the access point range. This is shown in the following illustration.

The hidden terminal problem

The Wifi protocol contains an optional mode, where a station can transmit a specific message to the access point to get access to transmit, known as **Request to Send (RTS)**. If no other device is transmitting, the access point replies with a message, known as **Clear to Send (CTS)**. The CTS is received by all the devices associated with the access point, which reserves the medium for the corresponding station.

## Types of frames[#](#Types-of-frames)

In general, there are three types of frames, namely:

* **Data frames:** These are used to transmit data payloads between nodes.
* **Control frames:** These are used to facilitate the exchange of data frames, CTS/RTS and acknowledgment frames are examples of control frames.
* **Management frames:** These are used for the maintenance or discontinuation of communication. Beacon frames or probe requests are examples of management frames.

The frame structure shares many similarities with Ethernet.

The payload contains the payload of an encapsulated higher-level protocol and a CRC that protects against transmission errors.

The frame contains four MAC addresses as can be seen in the following illustration.

* Address 1 is the direct receiver
* Address 2 is the direct transmitter
* Address 3 is the indirect receiver/transmitter

Sending a packet through the access point

These addresses correspond to the access point, the source station, and the destination station, respectively, for frames that are sent by a station to the access point in order to be delivered to another station. Alternatively, they correspond to the destination station, the access point, and the source station, respectively, for frames that are sent by an access point to the final destination station. The frame also contains sequence numbers for deduplication purposes, a duration field used for reserving the channel, and a frame control field that contains various sub-fields, such as the protocol version, the type of the frame (for example, data, control, or management), and so on.

Backlesson

Mark As CompletedComplete

Next

The Link Layer - Services

The Network Layer

Ask

[Ethernet](#Ethernet)

[Hub](#Hub)

[Switch](#Switch)

[Wifi](#Wifi)

[Ad-hoc mode](#Ad-hoc-mode)

[Infrastructure mode](#Infrastructure-mode)

[Association](#Association)

[Hidden terminal problem](#Hidden-terminal-problem)

[Types of frames](#Types-of-frames)

---


# The Network Layer

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Network Layer

# The Network Layer

Learn about the network layer, the protocols it follows, and the limitations it encounters.

We'll cover the following...

* [Functionalities that help to provide network layer service](#Functionalities-that-help-to-provide-network-layer-service)
  + [Control plane](#Control-plane)
  + [Data plane](#Data-plane)
* [Protocols](#Protocols)
  + [Internet protocol](#Internet-protocol)
    - [Structure](#Structure)
* [Address Resolution Protocol (ARP)](#Address-Resolution-Protocol-ARP)
  + [Delivering packets across multiple networks](#Delivering-packets-across-multiple-networks)
  + [Routing table](#Routing-table)
    - [Populating routing table](#Populating-routing-table)
  + [Autonomous system (AS)](#Autonomous-system-AS)
    - [Intra-autonomous system routing protocol](#Intra-autonomous-system-routing-protocol)
    - [Inter-autonomous system routing protocol](#Inter-autonomous-system-routing-protocol)
* [Limitations of the network layer](#Limitations-of-the-network-layer)

While the ***link layer*** is responsible for transferring packets between nodes that are directly linked, the ***network layer*** transfers packets between nodes that are not directly linked and might belong to different networks.

## Functionalities that help to provide network layer service[#](#Functionalities-that-help-to-provide-network-layer-service)

The functionalities that help the network layer transfer packets between nodes, which are not directly linked and may belong to different networks, can be divided into two main areas: the **control plane** and the **data plane**.

### Control plane[#](#Control-plane)

The **control plane** is the part of the network layer that gathers all the necessary meta-information, which is needed to route data packets between nodes.

### Data plane[#](#Data-plane)

The **data plane** is the part of the network layer that routes data packets between nodes, while leveraging information provided by the control plane.

## Protocols[#](#Protocols)

> **Note:** There are many different protocols that are followed inside the network layer, but it is impractical to cover them all in this lesson. Hence, we will focus on the most central ones in this course.

Every network interface comes with a MAC address, which is used to address the frames at the link layer. However, this address is assigned statically and is not hierarchical, which makes it unsuitable for routing packets in a network. As a result, the network layer introduces a second form of address, called the **IP (Internet Protocol) address**.

### Internet protocol[#](#Internet-protocol)

The IP addresses are assigned statically, either by an administrator or dynamically by the network.

IP addresses are also hierarchical, which means that each address is part of a network that can contain multiple addresses and where the network can also be part of a larger network.

The IP protocol evolved with time to address user needs, and the structure of IP addresses changed along with it. The resultant changes are:

* An IP v4 address is a 32-bit number.
* An IP v6 address is a 128-bit number.

> **Note:** The adoption of IP v6 is an ongoing process. Therefore, we will give examples using IP v4. We will refer to it as IP for the sake of brevity.

#### Structure[#](#Structure)

IP addresses are represented with dot-decimal notation, consisting of four decimal numbers that represent 8 bits and a 0-255 range, which are then separated by a dot.

An example of an IP address is 172.16.254.1.

An IP address is structurally composed of two parts:

* The first part contains the higher-order bits, which are common for all addresses in the network and is known as the **network prefix**.
* The second part of the IP address represents the identifier of the node in the network.

Networks are connected with each other via special devices, called routers, which are capable of routing packets properly across networks so that they reach their destination successfully.

The following illustration shows an example of three different subnets connected to each other via three routers.

An example of multiple subnets interconnected via routers

> **Note:** The central protocol in the network layer is the **IP protocol.**

IP has the task of delivering packets, called **datagrams**, from a node to another node. It delivers datagrams that can potentially reside in a different network. These datagrams are encapsulated into link layer frames (for instance, Ethernet frames) in order to be sent across a link. They are also composed of a set of headers and a payload that corresponds to the packet of the next layer in the network stack. Over here, the main headers of interest are the source and destination IP address, the protocol of the higher layer, and the version of the IP protocol that is used.

## Address Resolution Protocol (ARP)[#](#Address-Resolution-Protocol-ARP)

> Note: We will explore some protocols of the network layer a bit more to understand how a packet is delivered between different networks.

Nodes are, typically, addressed globally in the Internet via their IP addresses. However, for a packet to eventually reach a node, its neighboring node must know its MAC address to be able to craft a link-layer packet addressed to it. This mapping from an IP address to a MAC address is performed by the **ARP protocol**.

> **Note:** Whether ARP is a link-layer or a network-layer protocol is a controversial debate. Some people claim that it’s a *network-link layer* because its packets are encapsulated in a *link-layer protocol* frame. Conversely, other people claim that it’s a link-layer protocol because it is not routable and is only exchanged inside the boundaries of a single network.

> In the context of this chapter, the ARP protocol was presented as part of the network layer, because we believe it is easier to understand when following a bottom-up approach.

In order for a node to identify the MAC address of a node with a specific IP address, it can send an ARP request message to all the nodes on the local network (using the broadcast MAC address as the destination address), including the IP address in the request. The ARP message will be encapsulated in a link-layer frame. In the case of Ethernet, for instance, this would mean that the frame’s payload will be the ARP message and the type will correspond to the ARP type (0x0806).

> **Note:** For the sake of brevity, we will not go into the details of the structure of an ARP message.

Each of the nodes that receive the ARP request will check if the IP address matches theirs and if that’s the case, they will reply with an ARP response message that will contain their MAC address. The nodes also store these mappings in a local ARP table, which acts as a cache to avoid repetitive requests for the same information.

We answered the question of how the network layer delivers packets inside the same network, but the question still remains on how it delivers packets across multiple networks.

### Delivering packets across multiple networks[#](#Delivering-packets-across-multiple-networks)

This is achieved through the use of routers. Routers maintain special routing tables, which contain information on how specific IP addresses can be reached. More specifically, the routing table maintains entries that contain the following fields:

* **Network destination and network mask:** Together, these fields form a network identifier.
* **Gateway:** A gateway is the next node to which the packet is to be sent in order for it to reach its final destination. This final destination can be a specific IP address of a router if the network is accessible via some router. It can also have the value 0.0.0.0 if the network is accessible locally, which would mean there is a direct link to the destination IP address and the packet can be sent directly to it.
* **Interface:** This field corresponds to the network interface through which the gateway can be reached.

### Routing table[#](#Routing-table)

Routing tables are also maintained by regular nodes for the same purpose. Every time a node needs to send a network layer packet, it performs a lookup on its routing table with the destination IP of the packet to identify where this packet needs to be routed in order to reach this IP. Then, the packet is sent through the appropriate interface to the corresponding gateway.

We can now look back at our previous example and see how these routing tables will look and how the packets will flow across the networks. For instance, the routing table for the node with IP 240.1.1.1 may show the following form:

| Destination | Network mask | Gateway | Interface |
| --- | --- | --- | --- |
| 0.0.0.0 | 0.0.0.0 | 240.1.1.3 | if1 |
| 240.1.1.0 | 255.255.255.0 | 0.0.0.0 | if1 |

The next question, we may encounter, at this point is: How is this routing table populated in the first place?

#### Populating routing table[#](#Populating-routing-table)

Routing tables are populated when routers exchange information about the IP addresses that are reachable through them. The routers then use this information to form a map of the network in the form of a routing table. Of course, this is an intentionally simplified description of the population process.

### Autonomous system (AS)[#](#Autonomous-system-AS)

In practice, multiple nodes from one or more networks can be grouped into an **autonomous system (AS)**, which contains a group of routers that are under the same administrative control.

#### Intra-autonomous system routing protocol[#](#Intra-autonomous-system-routing-protocol)

Routers within the same AS run the same routing algorithm to share information about each other. As a result, the routing algorithm running within an autonomous system is called an **intra-autonomous system routing protocol**. An example of such a protocol is the **open shortest path first protocol (OSPF)**.

> **Note:** The layer to which OSPF belongs is also a controversial topic. It is encapsulated inside the IP, but it is placed on the link layer because OSPF packets flow only across a single link and do not traverse routers to travel more than one hop.

#### Inter-autonomous system routing protocol[#](#Inter-autonomous-system-routing-protocol)

An autonomous system needs to exchange some information with other autonomous systems in order to be able to route packets to them. This is the task of an inter-autonomous system routing protocol. An example of such a protocol is the **border gateway protocol (BGP)**, which consists of external **BGP (eBGP)** and internal **BGP (iBGP)**.

*eBGP* runs between two routers in different autonomous systems to exchange neighboring information between them, and *iBGP* runs between two routers in the same autonomous systems to propagate this information inside the autonomous system.

> **Note:** In fact, BGP is run by most Internet service providers (ISPs) to establish routing between themselves.

Intra-AS and inter-AS routing

## Limitations of the network layer[#](#Limitations-of-the-network-layer)

Before we move to the next layer, it would be useful for us to reflect first on what the limitations of the network layer are.

* The network layer does not provide any guarantees that the messages sent from a node will, eventually, be delivered to the destination node. The exchange of messages is unsuccessful, either when a router fails or when a router is forced to drop the packet due to network congestion.

> Routers store received packets in memory, until they transmit them on the network. If the packets arrive at a greater rate than they can be transmitted, the router may be forced to drop some packets to avoid running out of memory. The **queuing algorithm** used by the router governs how packets are buffered in memory and/or dropped. Some examples of a queuing algorithm include: **first-in-first-out, priority queueing**, and **weighted fair queueing.**

* The network layer does not provide any ordering guarantees either. If node A sends two messages in a sequence to the same node, this does not mean that the other node will receive them in the same order. The packets may follow different paths through the network or some routers in the network may not necessarily preserve the order of the packets. As a result, the network layer does not provide reliable nor in-order delivery.
* The network layer is also unable to provide strict throughput or timing guarantees since there is no way for applications to reserve the resources of the network for a specific period of time. Instead, they use any bandwidth that is available at the time of transmission of data. This is an important thing to keep in mind when we are building a distributed system, because we need to ensure that we do not make invalid assumptions.

> This comes down to the fact that the IP protocol is a ***packet-switched protocol***. There are other ***circuit-switched protocols*** that can provide strict throughput guarantees, but these come with their own drawbacks of course.

Backlesson

Mark As CompletedComplete

Next

The Link-Layer Protocols

The Transport Layer

Ask

[Functionalities that help to provide network layer service](#Functionalities-that-help-to-provide-network-layer-service)

[Control plane](#Control-plane)

[Data plane](#Data-plane)

[Protocols](#Protocols)

[Internet protocol](#Internet-protocol)

[Structure](#Structure)

[Address Resolution Protocol (ARP)](#Address-Resolution-Protocol-ARP)

[Delivering packets across multiple networks](#Delivering-packets-across-multiple-networks)

[Routing table](#Routing-table)

[Populating routing table](#Populating-routing-table)

[Autonomous system (AS)](#Autonomous-system-AS)

[Intra-autonomous system routing protocol](#Intra-autonomous-system-routing-protocol)

[Inter-autonomous system routing protocol](#Inter-autonomous-system-routing-protocol)

[Limitations of the network layer](#Limitations-of-the-network-layer)

---


# The Transport Layer

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Transport Layer

# The Transport Layer

Learn about the services that are provided by the transport layer.

We'll cover the following...

* [Achieving transport layer service](#Achieving-transport-layer-service)
  + [User datagram protocol](#User-datagram-protocol)
    - [Structure of datagram](#Structure-of-datagram)
  + [Transmission control protocol](#Transmission-control-protocol)
    - [The 3-way handshake](#The-3-way-handshake)
    - [Data transfer](#Data-transfer)
    - [Benefits](#Benefits)
* [Pros of UDP over TCP](#Pros-of-UDP-over-TCP)
* [Deciding which protocol to use](#Deciding-which-protocol-to-use)

The network layer provides ***node-to-node communication*** while the transport layer provides the service of ***application-to-application communication.***

The application-to-application communication service is useful because there can be many different applications running in a node that want to communicate with one of the applications running in a different node.

## Achieving transport layer service[#](#Achieving-transport-layer-service)

Application-to-application communication is achieved via the concept of **ports**, where each node can have many different applications running and listening on different ports for data from the network.

Some of the protocols in the transport layer can also provide more services on top of this fundamental one. We will briefly cover the **transmission control protocol (TCP)** and the **user datagram protocol (UDP)**, the two most commonly used and well-known protocols of the *transport layer*.

### User datagram protocol[#](#User-datagram-protocol)

UDP is a simple protocol that applications can use to send messages to each other. These messages are called datagrams.

Similar to the IP protocol, it is a **connectionless protocol**, which means that an application in a host can send a message to an application on a different host, without setting up a communication channel first. All it needs to do is to specify the IP address of the destination node and the port that the corresponding application is listening to.

#### Structure of datagram[#](#Structure-of-datagram)

A datagram is composed of a **payload** that corresponds to the application message and a **header**, which contains fields for the source and destination ports, the length of the datagram, and an optional checksum.

Structure of UDP datagram

### Transmission control protocol[#](#Transmission-control-protocol)

TCP is a more complex protocol, which can provide more services. TCP is a **connection-oriented protocol**, which means that a connection between a client and a server needs to be established before application data can be sent. This is achieved via a **3-way handshake**.

Structure of TCP packet

#### The 3-way handshake[#](#The-3-way-handshake)

The **3-way handshake** is used to establish a connection and negotiate several parameters for it.

For example, a crucial parameter that is selected during this phase is the **size of in-memory buffers**, which will be used to temporarily hold received data before it can be delivered to the application.

This process starts when the client sends a request to initiate a connection (SYN), continues when the server responds with a confirmation of the connection along with a request to initiate a connection in the reverse direction (ACK & SYN), ends when the client responds with a confirmation (ACK). After this process is complete, a connection is established between the two sides that can be used to exchange data.

#### Data transfer[#](#Data-transfer)

Data is sent from one node to the other as a stream of bytes. As a result, the application needs to indicate the beginning and end of an application message in this stream, through **delimiters** or special headers that designate the message size.

#### Benefits[#](#Benefits)

There are benefits of TCP.

**In-order delivery**

TCP provides reliable and **in-order delivery**. This means that any data sent from the sender is guaranteed to be delivered eventually to the recipient and in the order they were sent. This is achieved through the use of a sophisticated acknowledgement protocol.

Achieving in-order delivery: The sender tags the data sent with a sequence number that is aligned with the number of bytes contained in the payload. The recipient sends back acknowledgements, indicating the sequence number up to which the recipient has received the data successfully. As a result, the sender is able to resend data that wasn’t acknowledged after a specific amount of time. The recipient is also able to deliver data to the application in the order they were sent using these sequence numbers.

**Flow control and congestion control**

TCP also provides flow control and congestion control, which means the rate at which data is transmitted by the sender is managed carefully to avoid overloading the recipient or the overall network.

**Flow control** is achieved when the recipient includes information in the acknowledgements about how much space is available in their receive buffer so that the sender can reduce the transmission rate when the buffer starts getting full.

**Congestion control** is achieved through the adjustment of the number of outstanding and unacknowledged packets on the sender side, in accordance with the perceived packet loss.

**Packet loss** is usually hard to identify precisely at the two ends of a connection, so the nodes use heuristics to get an approximation. For example, the sender assumes a packet to be lost if it is not acknowledged within a specific time window.

> **Note**: We intentionally avoided getting into the details of this acknowledgement protocol, because it contains a lot of optimisations and different variations that are a full subject on their own. As a result, if one looks at the structure of a *TCP packet*, it is more complex than that of *UDP packets*. The header contains a lot of additional fields for the aforementioned functionalities, such as a sequence number, an acknowledgement number, a window size, and so on.

## Pros of UDP over TCP[#](#Pros-of-UDP-over-TCP)

After the previous analysis, we might think TCP is superior to UDP since it provides more services to the application layer. Of course, this is not true because all of these guarantees come with certain tradeoffs.

* The fact that TCP requires a connection to be established before any data exchange can occur, makes it more heavyweight and slower compared to UDP.
* The same applies to the services of reliable and in-order delivery, which can introduce a lot of memory overhead and network traffic due to the need to maintain connection state and message buffers and perform retries for data that is considered lost.
* Data in TCP is sent and received as a byte stream without any boundary indicators, which means that the application layer needs to add boundary indicators along with the necessary parsing and buffering. Conversely, data in UDP is sent and received as messages with explicit boundaries.
* UDP also provides better control over when a message will be transmitted on the network, as compared to TCP that must abide by several parameters that control when data sent from an application should be transmitted in the network. For example, Nagle’s algorithm works by combining a number of small outgoing packets and sending them all at once to utilize the network more efficiently, which means that the data sent from an application may not be transmitted immediately.

## Deciding which protocol to use[#](#Deciding-which-protocol-to-use)

It is useful to understand the pros and cons of each protocol in order to make the right decision when building an application on top of them. Below are some examples of applications and how they could benefit from the characteristics of each protocol:

* A real-time video and audio application (for example, a video conference) might benefit from UDP since it can tolerate occasional packet loss and does not benefit much from packets that arrive extremely late.
* An application that requires a fast exchange of a relatively small request followed by a single response might benefit from UDP because it does not require a connection to be established first, thereby making this interaction very fast.

> DNS is an example of such an application and we will study it in the [next](https://www.educative.io/collection/page/10370001/4891237377638400/5590375350140928#dns) lesson.

* An application where the recipient needs to receive all the data from the sender and in the right order can benefit from TCP’s reliable and in-order delivery. Examples of such applications include e-mail transfer (SMTP), file transfer (FTP), or transfer of web content (HTTP).

Backlesson

Mark As CompletedComplete

Next

The Network Layer

The Application Layer

Ask

[Achieving transport layer service](#Achieving-transport-layer-service)

[User datagram protocol](#User-datagram-protocol)

[Structure of datagram](#Structure-of-datagram)

[Transmission control protocol](#Transmission-control-protocol)

[The 3-way handshake](#The-3-way-handshake)

[Data transfer](#Data-transfer)

[Benefits](#Benefits)

[Pros of UDP over TCP](#Pros-of-UDP-over-TCP)

[Deciding which protocol to use](#Deciding-which-protocol-to-use)

---


# The Application Layer

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

The Application Layer

# The Application Layer

Learn about the purpose of the application layer and the two main protocols that it follows.

We'll cover the following...

* [Domain name system](#Domain-name-system)
  + [Users of DNS](#Users-of-DNS)
* [Hypertext Transfer Protocol](#Hypertext-Transfer-Protocol)
  + [HTTP request and response structure](#HTTP-request-and-response-structure)
    - [Request message](#Request-message)
    - [Response message](#Response-message)

The **application layer** relies on the transport layer for the data transfer and is responsible for defining the syntax and semantics of this data as well as the protocol of exchanges between the two sides.

This is probably the most crowded layer with a vast number of protocols. In this lesson, we will explore two of the protocols that form the foundation of the world wide web, namely: **Domain Name System (DNS) protocol** and the **Hypertext Transfer Protocol**
(HTTP).

## Domain name system[#](#Domain-name-system)

DNS is a system used to map human-friendly names, called **domain names**, to **IP addresses**. This is useful because these domain names are easier for humans to remember and use, and they can also be agnostic to the actual network topology of an application, making them a better addressing scheme for applications, unlike IP addresses.

### Users of DNS[#](#Users-of-DNS)

The users of the DNS system can be classified into two broad categories.

**Clients** that want to resolve a domain name into an IP address in order to send a data packet, and **servers** that store and serve this information to clients.

The DNS specifies a protocol, which defines the data structures that the servers can maintain and how clients can request the data they need. For example, one type of record is the so-called A record, which contains the IP address for the associated domain name.

For a client to find the IP address for a specific domain name, they need to send a DNS query message to a DNS server that contains the necessary information, such as the domain name that needs to be resolved and the record type that is requested (A).

The DNS servers form a hierarchy with three basic layers:

* The root servers
* The top-level domain servers
* The authoritative servers

The client needs to know the *IP addresses* of the **root servers**, which are published by the Internet Corporation of Assigned Names and Numbers (ICANN) as the official “root zone file”.

Under normal conditions, DNS uses UDP as a transport protocol, and a resolution of a domain name consists of a single UDP request from the client followed by a single UDP reply from the server.

Resolving a domain name in order to make an HTTP request

## Hypertext Transfer Protocol[#](#Hypertext-Transfer-Protocol)

HTTP is an application layer protocol for distributed, collaborative, hypermedia information systems. In other words, it can be used for distributing various pieces of information throughout the Internet, where each piece of information can link to a different piece of information.

HTTP also functions as a **request-response protocol** between clients and servers. For example, the client can be a browser requesting a web page and the server can be a computer hosting this webpage.

HTTP makes use of **TCP** as the underlying transport layer protocol and uses its own headers to specify the size of a message.

> **Note:** There are many versions of the HTTP protocol, and HTTP/3 uses UDP instead of TCP mostly for performance reasons. However, when talking about HTTP here, we refer to the first version of HTTP for simplicity.

### HTTP request and response structure[#](#HTTP-request-and-response-structure)

The following illustration shows the structure of an HTTP request and the associated response.

Requesting a webpage via HTTP

#### Request message[#](#Request-message)

The request message consists of the following parts that are separated by <CR><CR><CR><LF><LF><LF> (a carriage return character followed by a line feed character):

* A request line that contains the request method (for example, GET) and the location of the resource that is requested (for example, /index.html)
* Some header fields (for example, Host)
* An empty line
* An optional message body, populated in case the data needs to be submitted to the server (for example, when a request is made to update
  data, instead of a request to retrieve data)

#### Response message[#](#Response-message)

The response message consists of the following parts (again separated
by <CR><CR><CR><LF><LF><LF>):

* A status line that includes the status code and a message, indicating
  the reason for success or failure (for example, 200 OK)
* Some header fields (for example, Content-Type)
* An empty line
* An optional message body, which is populated when the servers need to send data associated with a resource as part of the response

Backlesson

Mark As CompletedComplete

Next

The Transport Layer

Taking a Step Back

Ask

[Domain name system](#Domain-name-system)

[Users of DNS](#Users-of-DNS)

[Hypertext Transfer Protocol](#Hypertext-Transfer-Protocol)

[HTTP request and response structure](#HTTP-request-and-response-structure)

[Request message](#Request-message)

[Response message](#Response-message)

---


# Taking a Step Back

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Taking a Step Back

# Taking a Step Back

Take a look at the big picture of networks in distributed systems.

We'll cover the following...

Now that we have examined each layer more closely, we should take a step back and look at the big picture.

At this point, we realize how much complexity underlies a seemingly simple request from your web browser to Google and how many moving parts are involved in this transfer. Of course, the same applies to most **distributed systems** nowadays since they work on top of the same or a similar network infrastructure.

The following illustration shows an example of a big network like the **Internet** and the layers that are involved at every step.

The Internet from high above

> **Note:** The devices shown in the illustration above are **end hosts**, **switches** and **routers**. Switches are the one with only two layers shown next to them. Routers have three layers, while end hosts have five.

When we see layers missing from a node, then that means the node is agnostic to this layer. For example:

* Switches will forward Ethernet frames without inspecting the network packet encapsulated within.
* Routers will route IP packets without inspecting the TCP or UDP packets encapsulated within.

We hope it’s clear by now that each one of these layers provides a useful abstraction that we can leverage to build our applications.

However, it is still beneficial to understand the main mechanisms the layers use to build applications.

Knowing the services that each protocol provides is useful when we are evaluating different protocols to use for our application.

Knowing the mechanisms they use under the hood is useful for understanding the costs of these services and for troubleshooting issues when they arise.

Of course, this chapter only scratched the surface to give us a general idea of the main parts that are involved and the roles they play in this process.

> **Note:** For the interested readers who want to gain a deeper understanding of the various mechanisms and techniques that are used by these protocols, there are a lot of good books to learn from. They can also take our course [Grokking Computer Networking for Software Engineers](https://www.educative.io/courses/grokking-computer-networking) to learn more on this topic.

Backlesson

Mark As CompletedComplete

Next

The Application Layer

Quiz on Networking

Ask

---


# Quiz on Networking

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Networking

# Quiz on Networking

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

True or False: While sending data in the Internet Protocol (IP) model, the application layer comes after the network layer.

A.

True

B.

False

---

1 / 12

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Taking a Step Back

Introduction

Ask

---


# Introduction

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction

# Introduction

Let's look into the problem of security in distributed systems.

We'll cover the following...

* [Fallacy about security in distributed systems](#Fallacy-about-security-in-distributed-systems)
* [Core problems](#Core-problems)

Another big problem in the field of distributed systems is **Security**. Most of the chapters in this course have examined the scenario when things go wrong, e.g., when hardware or software failures happen. However, earlier, we assumed that the nodes do not act maliciously, This chapter will focus on the fallacies and core problems of security in the distributed systems.

![](images/image_1764833983.0157814.svg)![](images/6299690416078848.svg)

## Fallacy about security in distributed systems[#](#Fallacy-about-security-in-distributed-systems)

At the beginning of the course, in [this](https://www.educative.io/courses/distributed-systems-practitioners/fallacies-of-distributed-computing) lesson, we mentioned the following fallacy of distributed computing:

* The network is secure.

The previous chapter illustrated that the network that distributed systems use can be extensive and have a lot of different components, each of which is under the control of a different organization. So, it is crucial to ensure the system we are building will function properly and securely even when third parties are acting against this purpose.

## Core problems[#](#Core-problems)

Three core security-related problems come up frequently when designing distributed systems which are the following:

* Authentication
* Confidentiality
* Integrity

This chapter will focus on these three areas.

Backlesson

Mark As CompletedComplete

Next

Quiz on Networking

Authentication

Ask

[Fallacy about security in distributed systems](#Fallacy-about-security-in-distributed-systems)

[Core problems](#Core-problems)

---


# Authentication

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Authentication

# Authentication

Let's explore what authentication is and what are the approaches to perform authentication.

We'll cover the following...

* [User-to-system authentication](#User-to-system-authentication)
  + [The knowledge factors](#The-knowledge-factors)
  + [The ownership factors](#The-ownership-factors)
  + [The inherence factors](#The-inherence-factors)
* [Achieving the highest degree of security](#Achieving-the-highest-degree-of-security)
  + [Example](#Example)
* [Practices to follow when doing password-based authentication](#Practices-to-follow-when-doing-password-based-authentication)
  + [Avoid storing the password in plaintext](#Avoid-storing-the-password-in-plaintext)
* [System-to-system authentication](#System-to-system-authentication)

**Authentication** is the process of determining whether someone or something is who or what it declares itself to be.

One way to authenticate a user of the system is to ask user for Email address and Password

When we build systems, the problem of authentication comes up in two main contexts:

* When a user tries to authenticate to a computing system (**user-to-system**).
* When a system tries to authenticate to another system (**system-to-system**).

## User-to-system authentication[#](#User-to-system-authentication)

When we discuss user-to-system authentication, there are three main categories of approaches in which authentication can be performed, known as **authentication factors**. We will discuss these factors in the following section:

### The knowledge factors[#](#The-knowledge-factors)

The knowledge factors correspond to something the authenticated entity knows. For example, this could be a **password** or the **answer to a question**.

### The ownership factors[#](#The-ownership-factors)

The ownership factors correspond to something the authenticated entity has. For example, this could be an **ID card** or a **hardware authentication device**.

### The inherence factors[#](#The-inherence-factors)

The inherence factors correspond to something the authenticated entity is or does. For example, this could be a biometric identifier, such as a **fingerprint** or **DNA**.

## Achieving the highest degree of security[#](#Achieving-the-highest-degree-of-security)

To achieve the highest degree of security, a system should ideally use multiple authentication factors, a technique known as **multi-factor authentication**.

### Example[#](#Example)

**Two-factor authentication (2FA)** is an example of multi-factor authentication. Many applications nowadays use two-factor authentication (2FA).

In two-factor authentication (2FA), the user needs to provide a password first, and then they receive a one-time code in a personal device that they have to provide back to the system. In this way, even if the password of the user gets compromised, a malicious actor will be unable to access the system on behalf of the user without also getting access to their personal device.

Created with Fabric.js 3.6.6

1 / 5

User enters a Password first along with the Username

Created with Fabric.js 3.6.6

1 / 5

A One Time Password is sent to the user's personal device (phone)

Created with Fabric.js 3.6.6

1 / 5

User receives a One Time Password in the personal device (phone)

Created with Fabric.js 3.6.6

1 / 5

The user enters the One Time Password received on the personal device

Created with Fabric.js 3.6.6

1 / 5

User is now Logged In

## Practices to follow when doing password-based authentication[#](#Practices-to-follow-when-doing-password-based-authentication)

There are several good practices when doing password-based authentication.

### Avoid storing the password in plaintext[#](#Avoid-storing-the-password-in-plaintext)

The system should avoid storing the password in plaintext so that it is not readily accessible to system administrators and cannot get leaked in case the database gets compromised.

One way to mitigate this issue is to compute the hash of the password and store the value instead. Even in that case, though, the attacker might be able to compute the original value of the password by precomputing a table of hashes for many possible values and then checking all the leaked hashes against this table. This process is known as a **rainbow attack**.

The left table contains passwords in plain text, while the right table contains the hash of passwords

To make rainbow attack computationally harder, one can make use of a **salt**.

Salt is a random piece of data generated for every password and appended to the password before calculating the hash value. It can be stored alongside the password hash so that the same operation can be repeated when trying to authenticate an existing user.

Salt makes rainbow attacks harder to execute because the attacker would have to calculate every possible combination of the salt with all the possible passwords. One cannot do this in advance, but only after discovering some salts, e.g., due to a data leak. These are some of the many good practices we can follow to store passwords more securely.

## System-to-system authentication[#](#System-to-system-authentication)

In system-to-system authentication, the knowledge and ownership factors are the ones that are mainly used.

For example, system AAA might create an account with credentials for a separate system BBB. These credentials might be injected at runtime on system BBB, which will provide them to system AAA in order to authenticate before invoking any operations. Alternatively, system AAA might register public keys for other systems that can use the corresponding private keys for authentication (e.g., in SSH).

Backlesson

Mark As CompletedComplete

Next

Introduction

Confidentiality

Ask

[User-to-system authentication](#User-to-system-authentication)

[The knowledge factors](#The-knowledge-factors)

[The ownership factors](#The-ownership-factors)

[The inherence factors](#The-inherence-factors)

[Achieving the highest degree of security](#Achieving-the-highest-degree-of-security)

[Example](#Example)

[Practices to follow when doing password-based authentication](#Practices-to-follow-when-doing-password-based-authentication)

[Avoid storing the password in plaintext](#Avoid-storing-the-password-in-plaintext)

[System-to-system authentication](#System-to-system-authentication)

---


# Confidentiality

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Confidentiality

# Confidentiality

Learn about confidentiality and the techniques to achieve confidentiality.

We'll cover the following...

* [Achieving confidentiality](#Achieving-confidentiality)
  + [Encryption](#Encryption)
    - [Symmetric encryption](#Symmetric-encryption)
    - [Asymmetric encryption](#Asymmetric-encryption)
    - [Comparison between symmetric and asymmetric encryption](#Comparison-between-symmetric-and-asymmetric-encryption)
  + [Use cases of encryption](#Use-cases-of-encryption)
    - [Encryption in transit](#Encryption-in-transit)
    - [Encryption at rest](#Encryption-at-rest)

**Confidentiality** refers to the process of protecting information from being accessed by unauthorized parties.

## Achieving confidentiality[#](#Achieving-confidentiality)

The main technique to achieve confidentiality is **encryption**.

### Encryption[#](#Encryption)

Encryption is the process of converting the original representation of some information, known as **plaintext**, into an alternative form, known as **ciphertext**. The ciphertext can be converted back to the original plaintext only by specific authorized parties, and any other parties should not be able to infer anything about the plaintext by looking at the corresponding ciphertext.

For technical reasons, encryption is typically achieved through the use of a **pseudo-random** encryption key, where decryption is achieved through the use of the corresponding decryption key.

There are two main encryption schemes: symmetric and asymmetric.

#### Symmetric encryption[#](#Symmetric-encryption)

Symmetric encryption is the simplest kind of encryption, where there is a single key that can be used both as the encryption and decryption key, as shown in the following illustration:

Symmetric encryption

#### Asymmetric encryption[#](#Asymmetric-encryption)

*Asymmetric encryption* uses two separate keys, an encryption key and a decryption key, as shown in the following illustration:

Asymmetric encryption

* The encryption key is a **public** key shared with everyone who needs to send encrypted messages to an entity.
* The decryption key is a **private** key and it is used only by this entity to decrypt incoming messages.

#### Comparison between symmetric and asymmetric encryption[#](#Comparison-between-symmetric-and-asymmetric-encryption)

*Symmetric encryption* is generally faster than *asymmetric encryption*, but it suffers from a **bootstrapping problem** because one needs to find a secure way to exchange the symmetric key in the first place.

As a result, many protocols initially use asymmetric encryption to exchange a symmetric key, and then it is used for symmetric encryption for the remaining communication.

### Use cases of encryption[#](#Use-cases-of-encryption)

There are two main use cases of encryption, known as **encryption in transit** and **encryption at rest**.

#### Encryption in transit[#](#Encryption-in-transit)

Encryption in transit is used to encrypt data transferred through a network, which protects the disclosure of this data to intermediaries in this transfer.

#### Encryption at rest[#](#Encryption-at-rest)

Encryption at rest is used to encrypt data stored on computers and storage devices, which protects this data if other security measures fail and malicious actors gain access to the systems where the data is stored.

Backlesson

Mark As CompletedComplete

Next

Authentication

Integrity

Ask

[Achieving confidentiality](#Achieving-confidentiality)

[Encryption](#Encryption)

[Symmetric encryption](#Symmetric-encryption)

[Asymmetric encryption](#Asymmetric-encryption)

[Comparison between symmetric and asymmetric encryption](#Comparison-between-symmetric-and-asymmetric-encryption)

[Use cases of encryption](#Use-cases-of-encryption)

[Encryption in transit](#Encryption-in-transit)

[Encryption at rest](#Encryption-at-rest)

---


# Integrity

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Integrity

# Integrity

Let's examine what integrity is and how we can achieve it.

We'll cover the following...

* [Achieving integrity](#Achieving-integrity)
  + [Hash value](#Hash-value)
* [Techniques that provide both integrity and authentication](#Techniques-that-provide-both-integrity-and-authentication)
  + [Message authentication codes](#Message-authentication-codes)
  + [Digital signature](#Digital-signature)

**Integrity** refers to the process of preserving the accuracy and completeness of data over its entire lifecycle so that it cannot be modified in an unauthorized or undetected manner. This modification can happen maliciously (e.g., by an intermediary in the network) or inadvertently (e.g., because of a software or hardware failure).

## Achieving integrity[#](#Achieving-integrity)

> Note: We have discussed in the previous chapter some techniques that can protect against accidental modifications, such as **checksums** and **cyclic redundancy checks**, so here we will focus on malicious modification that is more relevant in the context of security.

### Hash value[#](#Hash-value)

A simple approach to protect the *integrity* of data is to calculate the hash value for a piece of data and send both the data and the hash, as shown in the following illustration:

Created with Fabric.js 3.6.6

1 / 9

A system where there is a sender, a receiver, and the communication network

Created with Fabric.js 3.6.6

1 / 9

Sender has some data in plaintext

Created with Fabric.js 3.6.6

1 / 9

Sender calculates the hash of the data using the hash function

Created with Fabric.js 3.6.6

1 / 9

Sender puts the data and the corresponding hash in a message and sends the message on the network

Created with Fabric.js 3.6.6

1 / 9

The message is forwarded to the receiver

Any malicious entity could modify the data, but we can detect some malicious entity attacks if that malicious entity could not figure out the correct hash function, as shown in the following illustration.

Created with Fabric.js 3.6.6

1 / 10

A system where there is a sender, a receiver, and the communication network

Created with Fabric.js 3.6.6

1 / 10

Sender has some data in plaintext

Created with Fabric.js 3.6.6

1 / 10

Sender calculates the hash of the data using the hash function

Created with Fabric.js 3.6.6

1 / 10

Sender puts the data and the corresponding hash in a message and sends the message on the network

Created with Fabric.js 3.6.6

1 / 10

A malicious entity enters the network

However, this approach suffers from an obvious problem:

* Suppose if we send the hash alongside the data, any malicious actor that can modify the data might be able to figure out the hash function used and adjust the hash accordingly. As a result we would be unable to detect the modified data.

Consequently, we usually need a combination of *integrity* and *authentication*, i.e., be certain that the hash corresponds to the data and that the sender has calculated the hash and not someone else.

We can achieve this with similar techniques to the ones described previously. Following are some techniques that provide both *integrity* and *authentication*.

## Techniques that provide both integrity and authentication[#](#Techniques-that-provide-both-integrity-and-authentication)

We will consider two techniques for ensuring integrity and authentication.

### Message authentication codes[#](#Message-authentication-codes)

**Message authentication codes** make use of a **shared secret key** in order to generate a tag for a message that can then be verified against the data using the shared key. It is shown in the following illustration.

Created with Fabric.js 3.6.6

1 / 7

Sender requests the Key generator to generate a secret key

Created with Fabric.js 3.6.6

1 / 7

There is a Sender, a Receiver, and a communication Network in a communication system

Created with Fabric.js 3.6.6

1 / 7

Sender has a message, ands wants to send this message to the Receiver

Created with Fabric.js 3.6.6

1 / 7

On the Sender side, message is first sent for creating the tag against the message

Created with Fabric.js 3.6.6

1 / 7

Sender generates a tag for the message using a shared secret key, the tagged message is then sent over the network

This technique suffers from similar problems as symmetric encryption.

### Digital signature[#](#Digital-signature)

Digital signatures use **asymmetric cryptography**, where an algorithm generates a public and a private key.

The private key is only known to the sender of the message, who can use it to sign a message producing a digital signature.

The recipients can then make use of the shared public key in order to verify that the digital signature is valid and was generated by the sender.

This is shown in the following illustration.

Created with Fabric.js 3.6.6

1 / 7

Sender requests the Key generator to generate a private and a public key

Created with Fabric.js 3.6.6

1 / 7

There is a Sender, a Receiver, and a communication Network in a communication system

Created with Fabric.js 3.6.6

1 / 7

Sender has a message, ands wants to send this message to the Receiver

Created with Fabric.js 3.6.6

1 / 7

On the Sender side, the message is first sent for sign

Created with Fabric.js 3.6.6

1 / 7

The sender uses the private key to produce the digital signature for the message , the signed message is then sent over the network

Similar to asymmetric encryption, digital signatures can be used to protect the *integrity* and *authenticity* of data transmitted through a network or stored in a system.

Backlesson

Mark As CompletedComplete

Next

Confidentiality

A Cryptography Primer

Ask

[Achieving integrity](#Achieving-integrity)

[Hash value](#Hash-value)

[Techniques that provide both integrity and authentication](#Techniques-that-provide-both-integrity-and-authentication)

[Message authentication codes](#Message-authentication-codes)

[Digital signature](#Digital-signature)

---


# A Cryptography Primer

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

A Cryptography Primer

# A Cryptography Primer

Let's learn the basic idea of cryptography and look into some basic mechanisms behind the techniques mentioned in the previous lessons.

We'll cover the following...

* [Cryptography](#Cryptography)
  + [Cipher](#Cipher)
    - [Example](#Example)
  + [Categories of ciphers](#Categories-of-ciphers)
    - [Stream cipher](#Stream-cipher)
    - [Block ciphers](#Block-ciphers)
* [Message Authentication Code (MAC)](#Message-Authentication-Code-MAC)
  + [Providing both confidentiality and integrity](#Providing-both-confidentiality-and-integrity)

> **Cryptography** is a very vast field. So, we will learn only the basics of cryptography in this section.

## Cryptography[#](#Cryptography)

One of the most central pieces in cryptography is the **cipher**.

### Cipher[#](#Cipher)

A **cipher** is an algorithm for converting a piece of data, called plaintext, into another piece of data, called ciphertext, which appears as random data and reveals no information about the original data.

We can also define a *cipher* as a pair of efficient algorithms (E,D)(E, D)(E,D) where:

* EEE: K×M→CK \times M \to CK×M→C is an encryption function receiving a plaintext (M) and a key (K) as an input and providing a ciphertext (C) as an output.
* DDD: K×C→MK \times C \to MK×C→M is a decryption function receiving a *ciphertext* (C) and a key (K) as an input and providing the original *plaintext* (M) as an output.

#### Example[#](#Example)

The **one-time pad** is the simplest example of a **secure cipher** and it simply uses an XORXORXOR operation:

* E(k,m)=kE(k, m) = kE(k,m)=k XORXORXOR mmm
* D(k,c)=kD(k, c) = kD(k,c)=k XORXORXOR ccc

XORXORXOR is used in this case, because it has a very interesting property:

* if YYY is a random variable with an unknown distribution in {0,1}N\lbrace 0,1\rbrace^N{0,1}N and XXX is an independent variable with a uniform distribution in {0,1}N\lbrace 0,1\rbrace^N{0,1}N, then Z=XZ = XZ=X XORXORXOR YYY is a variable with a uniform distribution in {0,1}N\lbrace 0,1\rbrace^N{0,1}N.

This means that using XORXORXOR with a uniformly distributed variable XXX will remove the underlying patterns in variable YYY.

This makes the one-time pad a *secure cipher* under a very strong definition of security, known as **semantic security**,

> *Note*: In Semantic security, the ciphertext does not reveal any information about the plaintext. However, practically it is not easy , because the key needs to be of the same size as the encrypted message. It is generally proven that perfect secrecy requires a key size equal to or larger than the message size, which makes it quite impractical to have perfectly secure algorithms. For this reason, we can use many different definitions of security depending on the case.

### Categories of ciphers[#](#Categories-of-ciphers)

There are two main categories of ciphers: stream ciphers and block ciphers.

#### Stream cipher[#](#Stream-cipher)

A **stream cipher** is a cipher that converts *plaintext* into ciphertext by encrypting one plaintext digit (e.g., bit) at a time with the corresponding digit of a pseudorandom keystream, which is generated based on a random key as shown in the following illustration.

Structure of a stream cipher

This cipher is useful when the full size of the *plaintext* is not known in advance.

*Stream ciphers* are semantically secure, so *semantic security* is one of the alternative definitions for *stream ciphers*.

When using a cipher stream, one needs to be careful not to use the same key more than once to preserve its security.

#### Block ciphers[#](#Block-ciphers)

Contrary to *stream* ciphers, *block* ciphers operate on fixed-length groups of bits, called **blocks**.

Most block ciphers are classified as **iterated block ciphers**, which means they transform fixed-size blocks of plaintext into identically sized blocks of ciphertext by repeatedly applying an invertible transformation, known as a **Round function**.

The following illustration shows an example of an iterated block cipher, known as **substitution-permutation network**, which performs several alternating rounds of substitutions (**S-boxes**) followed by permutations (**P- boxes**). In order to be secure, these operations must have specific properties, e.g., the S-boxes should not have any linearities. The key for every round is derived from the original encryption key.

Structure of a substitution-permutation network

> **Note**: A *block cipher* by itself allows encryption only of a single data block of the *plaintext*.

To encrypt multiple blocks (the whole plaintext), each block cipher can be used in different ways, called **modes of operation**.

An example of a block cipher is the **cipher-block chaining mode (CBC)**, which selects and adds a random initialization vector to an XORXORXOR. Before getting encrypted, XORXORXOR manners to the first *plaintext* block. Then the resultant *ciphertext* block is used as the new initialization vector for the next plaintext block, as shown in the following illustration:

CBC mode of encryption

> The mentioned ciphers provide *confidentiality*, but not necessarily *integrity* since a man in the middle could potentially alter the *ciphertext* in a way that would decrypt into a valid plaintext.

## Message Authentication Code (MAC)[#](#Message-Authentication-Code-MAC)

A message authentication code (MAC) is a mechanism that can provide *integrity* but not *confidentiality*.

It consists of three main functions:

* A key-generating function
* A signing function that can generate a tag for plaintext
* A verifying function that can verify whether a tag is valid for a specific *plaintext*.

MACs can be constructed from other cryptographic primitives, such as block ciphers algorithms or cryptographic hash functions.

### Providing both confidentiality and integrity[#](#Providing-both-confidentiality-and-integrity)

When we combine a cipher and a message authentication code, it can provide authenticated encryption, a form of encryption that simultaneously provides *confidentiality* and *integrity*.

Out of these techniques, only one combination was proven secure, where the plaintext is first encrypted and then a MAC is produced based on the resulting ciphertext. This technique is also known as **encrypt-then-MAC**.

Backlesson

Mark As CompletedComplete

Next

Integrity

Symmetric/Asymmetric Encryption and Digital Signatures

Ask

[Cryptography](#Cryptography)

[Cipher](#Cipher)

[Example](#Example)

[Categories of ciphers](#Categories-of-ciphers)

[Stream cipher](#Stream-cipher)

[Block ciphers](#Block-ciphers)

[Message Authentication Code (MAC)](#Message-Authentication-Code-MAC)

[Providing both confidentiality and integrity](#Providing-both-confidentiality-and-integrity)

---


# Symmetric/Asymmetric Encryption and Digital Signatures

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Symmetric/Asymmetric Encryption and Digital Signatures

# Symmetric/Asymmetric Encryption and Digital Signatures

Let's explore the categories of public-key encryption schemes and how digital signatures assure the integrity of a signature.

We'll cover the following...

* [Intractable problems](#Intractable-problems)
  + [Types](#Types)
    - [The discrete logarithm problem](#The-discrete-logarithm-problem)
      * [The factoring problem](#The-factoring-problem)
* [Categories of public-key encryption systems](#Categories-of-public-key-encryption-systems)
  + [Trapdoor function](#Trapdoor-function)
  + [Diffie-Helman key exchange](#Diffie-Helman-key-exchange)
* [Digital signatures](#Digital-signatures)

As we have already explained, **symmetric** **cryptography** is mainly based on randomization. On the other hand, **asymmetric cryptography** does not rely only on randomization because it allows an easy computation in the forward direction (e.g., generating the key pair), but makes the inverse computation extremely hard (e.g. discovering the private key from the public key). The main building block for asymmetric cryptography is so-called **intractable problems**.

## Intractable problems[#](#Intractable-problems)

Intractable problems are problems for which there is no known efficient algorithm to solve.

### Types[#](#Types)

There are two main types of intractable problems:

#### The discrete logarithm problem[#](#The-discrete-logarithm-problem)

The discrete logarithm problem is about calculating the logarithm of a number, which is relatively easy for real numbers, but an extremely hard problem in modular arithmetic.

##### The factoring problem[#](#The-factoring-problem)

The factoring problem of distinguishing prime numbers from composite numbers and resolving the composite numbers into their prime factors.

## Categories of public-key encryption systems[#](#Categories-of-public-key-encryption-systems)

There are two basic categories of public-key encryption systems:

* those based on **trapdoor functions**
* those based on **Diffie-Hellman key exchange**

### Trapdoor function[#](#Trapdoor-function)

A trapdoor function is a function that is easy to calculate one way but has a secret that is required to calculate in the opposite direction.

RSA (Rivest-Shamir-Adleman) is one of the most widely used trapdoor functions. Its security hardness relies on the properties of modular arithmetic. To invert the RSA function, an attacker must factor a number, known to be an intractable problem.

With a trapdoor function, a symmetric authentication encryption scheme, and a hash function, we can build a public key encryption system that provides authenticated encryption.

### Diffie-Helman key exchange[#](#Diffie-Helman-key-exchange)

**Diffie-Helman** is a protocol used for key exchange based on the discrete logarithm problem. The two sides can use Diffie-Helman to exchange securely a private key that can then be used to perform *symmetric encryption*.

## Digital signatures[#](#Digital-signatures)

**Digital signatures** can be used to assure the *integrity* of a signature over a piece of data without any need for *confidentiality*.

As we learned previously, *message authentication codes* (MAC) solve the same problem, but they need a shared private key. Instead, when using *digital signatures* we want to generate signatures using a private key that can then be verified by anyone who has access to our public key. We can build it on top of trapdoor functions in a similar way as described before, but the trapdoor function is used in the opposite way.

For example, *asymmetric encryption* uses the *trapdoor function* when encrypting a message and the inverse *trapdoor function* when decrypting a message. On the other hand, digital signatures use the *inverse* trapdoor function when signing a message and the *forward* trapdoor function when validating a signature.

Evaluate your understanding of security in distributed systems by engaging with our AI Mentor in the widget provided below. The AI Mentor will ask a total of six questions. To get started, say hello to Edward in the widget below, and it will lead the way.

Want to know the correct answer?

Powered by AI

14 Prompts Remaining

Prompt AI WidgetOur tool is designed to help you to understand concepts and ask any follow up questions. Ask a question to get started.

In the next chapter, we will look at some examples of protocols and standards used for security purposes and we will relate them to the principles and techniques learned in the previous chapters.

Backlesson

Mark As CompletedComplete

Next

A Cryptography Primer

Quiz on Security

Ask

[Intractable problems](#Intractable-problems)

[Types](#Types)

[The discrete logarithm problem](#The-discrete-logarithm-problem)

[The factoring problem](#The-factoring-problem)

[Categories of public-key encryption systems](#Categories-of-public-key-encryption-systems)

[Trapdoor function](#Trapdoor-function)

[Diffie-Helman key exchange](#Diffie-Helman-key-exchange)

[Digital signatures](#Digital-signatures)

---


# Quiz on Security

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Security

# Quiz on Security

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

What is authentication used for?

A.

To determine when a file was last modified

B.

To determine whether someone or something is who or what they claim to be

C.

To determine whether our internet connection is secure

---

1 / 6

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Symmetric/Asymmetric Encryption and Digital Signatures

Transport Layer Security (TLS)

Ask

---


# Transport Layer Security (TLS)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Transport Layer Security (TLS)

# Transport Layer Security (TLS)

Let's look into the Transport Layer Security (TLS) protocol.

We'll cover the following...

* [Parts of TLS protocol](#Parts-of-TLS-protocol)
* [Modes of operation in TLS](#Modes-of-operation-in-TLS)
* [Uses of TLS protocol](#Uses-of-TLS-protocol)

The Transport Layer Security (TLS) protocol is a cryptographic protocol designed to provide secure communication over an insecure network.

It can provide *confidentiality*, *authentication*, and *integrity*.

It typically runs above a reliable transport layer protocol, such as TCP.

> Note: However, equivalent protocols for unreliable transport layer protocols, such as DTLS, can work on top of UDP.

The sides participating in the communication are typically the **client** and the **server**, where the client is responsible for initiating the TLS connection.

## Parts of TLS protocol[#](#Parts-of-TLS-protocol)

The TLS protocol has two main parts.

In the **handshake part**, the two sides negotiate the parameters to establish a connection.

In the **data exchange part**, the two sides can exchange data securely.

## Modes of operation in TLS[#](#Modes-of-operation-in-TLS)

TLS has different modes of operation depending on whether authentication needs to be performed and whether one or both sides need to be authenticated.

> Note: When both sides are authenticated, this is commonly known as **mutual TLS**.

As a result, the workflow of the protocol will differ slightly. Here we will study the most common case, where only the server is authenticated. The following illustration shows the workflow in this case.

Created with Fabric.js 3.6.6

1 / 11

To initiate a TLS connection, the client sends a ClientHello message with a list of cipher suites supported by the client along with a client random number (nonce)

Created with Fabric.js 3.6.6

1 / 11

The server responds with a ServerHello message that contains a server random number (nonce) and the selected cipher suite which contains a symmetric encryption algorithm (e.g., AES), a key exchange algorithm (e.g., RSA), and a MAC algorithm (e.g., HMAC)

Created with Fabric.js 3.6.6

1 / 11

The server sends a ServerKeyExchange (this message is sent only for specific cipher suites)

Created with Fabric.js 3.6.6

1 / 11

The server sends a Certificate message that contains the server’s public key contained in a certificate

Created with Fabric.js 3.6.6

1 / 11

The server sends a ServerHelloDone message that indicates it is done with handshake negotiation

* The client sends a `ClientHello` message to initiate a TLS connection. This message contains a list of cipher suites supported by the client along with a client random number (nonce).
* The server responds with a `ServerHello` message that contains a random server number (nonce) and the selected cipher suite. This cipher suite will contain a *symmetric encryption* algorithm (e.g., AES), a key exchange algorithm (e.g., RSA), and a MAC algorithm (e.g., HMAC).
* The server will also send a `ServerKeyExchange` (this message is sent only for specific cipher suites), a `Certificate` message that contains the server’s public key in a certificate, and a `ServerHelloDone` message that indicates it is done with handshake negotiation.
* The client will then verify the server’s certificate, extract its public key, generate a preliminary key, encrypt it with the server’s public key, and send it across through a `ClientKeyExchange` message.
* At this point, the client and the server use the random numbers (nonces) that were exchanged previously along with the preliminary key to compute a common secret through a key derivation function. This is subsequently used to generate all other key data (e.g., encryption keys, initialization vectors, etc.).
* The client will then send a `ChangeCipherSpec` message that indicates everything will be encrypted from now on. This message is followed by an encrypted `Finished` message containing a hash and a MAC over all the previously exchanged handshake messages. The server will do the same thing in the other direction. This exchange of messages ensures no man-in-the-middle could tamper with previous messages to degrade security, e.g. by modifying the list of supported cipher suites.
* At this point, the handshake is complete and the two sides will exchange `Application` messages that will be authenticated and encrypted.

## Uses of TLS protocol[#](#Uses-of-TLS-protocol)

One of the most common uses of TLS is in the HTTPS protocol, which is an extension of the HTTP protocol where data is exchanged securely between the server and the client over TLS. It can be used to encrypt communications for any application, email, file transfer, and voice over IP.

Backlesson

Mark As CompletedComplete

Next

Quiz on Security

Public-Key Infrastructure (PKI)

Ask

[Parts of TLS protocol](#Parts-of-TLS-protocol)

[Modes of operation in TLS](#Modes-of-operation-in-TLS)

[Uses of TLS protocol](#Uses-of-TLS-protocol)

---


# Public-Key Infrastructure (PKI)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Public-Key Infrastructure (PKI)

# Public-Key Infrastructure (PKI)

Let's learn about the public-key infrastructure in detail.

We'll cover the following...

* [Certificates](#Certificates)
  + [X.509 certificate](#X509-certificate)
* [Certificate issuance](#Certificate-issuance)
* [Certificate chain](#Certificate-chain)
* [Rules for a certificate chain to be valid](#Rules-for-a-certificate-chain-to-be-valid)
* [Mechanisms to revoke certificates](#Mechanisms-to-revoke-certificates)

When using the public-key cryptography, one common problem is that how can a client ensure the server is who they claim to be?

In theory, a malicious party could generate a second keypair and present the public key to us, which we would use to encrypt to send the data. Even though the data is encrypted, they can stil be sent to the wrong party, who would be able to then decrypt them with their private key. To ensure the client is talking to the server it expects, we can make use of **certificates**.

## Certificates[#](#Certificates)

Certificates are digital documents that bind a public key to a specific entity. They are used by clients for authentication purposes.

These certificates can have different formats, but X.509 is a common standard defining one format for protocols, such as TLS.

### X.509 certificate[#](#X509-certificate)

An X.509 certificate contains a public key, and the identity of this public key belongs to it. This identity is represented by a so-called distinguished name, which uniquely identifies the entity and consists of various attributes, such as a common name, an organization name, a locality name, etc.

> Note: The values for each of these fields can differ for each use case.

When we use of TLS certificates for websites, the common name is populated with the domain name of the website, so a certificate binds a public key to a specific domain name.

## Certificate issuance[#](#Certificate-issuance)

Certificates are issued by specific organizations, called **certificate authorities**, which sign these certificates in order to attest the ownership of this public key to the associated entity.

> Note: Before signing the certificates, the certificate authority first verifies the identity of the party that makes the request.

Certificate authorities can issue a web certificate by asking the party to prove that they have control over the associated domain, e.g., by uploading specific content to a website served by this domain.

## Certificate chain[#](#Certificate-chain)

The certificate authorities also generate certificates for their own public keys, but these certificates are signed by their own private key and are known as self-signed certificates. As a result, they act as trusted third parties, which are trusted both by the owner and the users of the certificate. Sometimes, this can get more complicated with certificate authorities issuing certificates for the public keys of other certificate authorities that they can then use to issue other certificates. In this case, these certificates can form a certificate chain, as shown in the following illustration:

An example of certificate chain

The certificate at the bottom of the chain is known as the **target certificate**, and the certificate at the top of the chain is known as the **root certificate**.

A **certificate chain** is used to ensure that the public key and other metadata contained in the *target certificate* belongs to its subject. This is true only when a certificate chain is valid.

## Rules for a certificate chain to be valid[#](#Rules-for-a-certificate-chain-to-be-valid)

A valid certificate chain must comply with the following rules:

* The issuer of each certificate (except the root one) must match the subject of the next certificate in the list.
* Each of those certificates (except the root one) must also be signed by the secret key corresponding to the next certificate in the chain, i.e., the signature of the certificate must be verified successfully using the public key in the next certificate.
* The root certificate should be signed by the trusted entity; that is why it is also known as a **trust anchor**. For this purpose, applications are typically given a list of trusted root certificates. This is done through various mechanisms, e.g., web browsers come with a predetermined set of pre-installed root certificates, so TLS certificates issued from major certificate authorities will work instantly.

> The list of trusted root certificates is curated with only trustworthy organizations. For example, in some cases certificate authorities have failed to operate safely, and as a result, they were removed from these lists.

## Mechanisms to revoke certificates[#](#Mechanisms-to-revoke-certificates)

The certificate authorities have issued various mechanisms to revoke certificates when the private key of the associated entity gets compromised. Some of these mechanisms are:

* The **certificate revocation lists CRLs**
* The **online certificate status protocol (OCSP)**

This whole system for managing the creation, storage, and distribution of digital certificates is known as **public key infrastructure (PKI)**.

If a browser removes a root CA from its trusted list due to unsafe operation, how does that decision affect existing certificate chains presented by websites that were issued by that CA? Provide your answer in the widget given below.

Want to know the correct answer?

Impact of Removing a Root CA

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Transport Layer Security (TLS)

Web of Trust (PGP)

Ask

[Certificates](#Certificates)

[X.509 certificate](#X509-certificate)

[Certificate issuance](#Certificate-issuance)

[Certificate chain](#Certificate-chain)

[Rules for a certificate chain to be valid](#Rules-for-a-certificate-chain-to-be-valid)

[Mechanisms to revoke certificates](#Mechanisms-to-revoke-certificates)

---


# Web of Trust (PGP)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Web of Trust (PGP)

# Web of Trust (PGP)

Let's explore how the web of trust solves the problem of a public-key infrastructure.

We'll cover the following...

* [Key signing party](#Key-signing-party)

When using a **public-key infrastructure**, one has to trust at least the root certificate authorities, which means the overall system is subject to some form of centralization. An alternative approach that aspired to solve the same problem in a more decentralized way is the **web of trust**.

In the web of trust, there are no certificate authorities that are essentially trusted by everyone. Instead, the various parties sign each other’s public keys, thus endorsing the association of the public key with the person or entity listed in the corresponding certificate. This is done at a **key signing party**.

## Key signing party[#](#Key-signing-party)

A **key signing party** is an event where people present their public keys to other people along with proofs of their identity (e.g. passports) who then digitally sign their public key. Each party can also assign a specific degree of trust to other parties, which can then be used to build a more elaborate voting scheme, as shown in the following illustration:

An example of web of trust

Alice can assign complete trust to Charlie, but only marginal trust to Bob. This means that public keys from certificates that Charlie has signed will be automatically trusted.

However, to trust public keys that Bob has signed, these keys must also be signed by other marginally trusted parties. This scheme is flexible, and users can adjust these thresholds accordingly. In this way, all the parties form a web of trust.

> Note: OpenPGP is a standard built on the concept of the web of trust.

Backlesson

Mark As CompletedComplete

Next

Public-Key Infrastructure (PKI)

OAuth Protocol

Ask

[Key signing party](#Key-signing-party)

---


# OAuth Protocol

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

OAuth Protocol

# OAuth Protocol

Let's study the OAuth protocol and learn how it works.

We'll cover the following...

* [Entities in OAuth protocol](#Entities-in-OAuth-protocol)
  + [Resource owner](#Resource-owner)
  + [Client](#Client)
  + [Resource server](#Resource-server)
  + [Authorization server](#Authorization-server)
* [Workflow of the OAuth protocol](#Workflow-of-the-OAuth-protocol)

In the World Wide Web, the client can be a **web browser**, and the server can be an **application server**.

However, there are more complex scenarios that involve more parties. One such scenario is when a server needs a client’s authorization to retrieve the client’s data from a different server. For example, this could happen when an e-mail application wants to retrieve the email accounts of your friends in a separate social media application in order to add them to your contacts list. **OAuth** is a protocol that allows this to happen in a secure way.

> Note: There are multiple versions of this protocol with significant changes, but we will discuss the OAuth 2.0 version in this lesson.

## Entities in OAuth protocol[#](#Entities-in-OAuth-protocol)

There are four main entities in OAuth protocol.

### Resource owner[#](#Resource-owner)

The **resource owner** is the person who gives access to some portion of their data.

### Client[#](#Client)

The **client** is the application that attempts to get access to some of the user’s data, e.g., the e-mail application in the above example.

### Resource server[#](#Resource-server)

The **resource server** is the application that contains the user’s data to be accessed, e.g., the social media application in the above example.

### Authorization server[#](#Authorization-server)

The **authorization server** is the server that presents the interface where the user approves or denies the request to their data. In simpler cases, it can be the same as the resource server, but in more complex scenarios, it can be different.

## Workflow of the OAuth protocol[#](#Workflow-of-the-OAuth-protocol)

The following illustration contains a visualization of the main flow in the OAuth protocol:

Created with Fabric.js 3.6.6

1 / 15

Created with Fabric.js 3.6.6

1 / 15

Created with Fabric.js 3.6.6

1 / 15

Created with Fabric.js 3.6.6

1 / 15

Created with Fabric.js 3.6.6

1 / 15

* Initially, the user visits the website of the client application. The client applications redirect the user to a specific webpage of the authorization server dedicated to OAuth. The request to the authorization server contains some additional data, such as a redirect URI back to the client application, the category of user data that is requested, the ID of the client application, etc.
* The authorization server returns a web page to the user that presents a detailed message about the requested data and the client application that is making the request. The user is given the option to authorize or reject this request.

> Note: If the user isn’t logged in to the authorization server, a login prompt will be shown first.

* When the user approves the request, the authorization server will redirect the user back to the client’s application. Specifically, the user will be redirected back to the redirect URI contained in the original request, but this URI will be enriched with some additional data. One crucial piece of data is an authorization code vended by the authorization server that will represent the permission the user gave to the application code to access their data.
* The client application will then make a request to the authorization server providing this authorization code in exchange for an access token. Apart from the authorization code, the client application will also provide their client identifier along with a client secret.
* The client application can then use this access token to make a request to the resource server requesting the user’s data.

When encountering this workflow for the first time, one might question why there is a need for both the authorization code and the access token. The main reason behind this is that the web browser is considered much more insecure when compared to the client application on the backend. So, only the authentication code is exposed to the web browser that cannot retrieve the user’s data without the client’s secret that is securely stored by the client application.

Backlesson

Mark As CompletedComplete

Next

Web of Trust (PGP)

Quiz on Security Protocols

Ask

[Entities in OAuth protocol](#Entities-in-OAuth-protocol)

[Resource owner](#Resource-owner)

[Client](#Client)

[Resource server](#Resource-server)

[Authorization server](#Authorization-server)

[Workflow of the OAuth protocol](#Workflow-of-the-OAuth-protocol)

---


# Quiz on Security Protocols

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Security Protocols

# Quiz on Security Protocols

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

Which of the protocols makes use of TLS?

A.

FTP

B.

HTTPS

C.

UDP

---

1 / 4

Submit Answer

Backlesson

Mark As CompletedComplete

Next

OAuth Protocol

Introduction

Ask

---


# Introduction

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction

# Introduction

Learn some practical examples of the distributed systems.

We'll cover the following...

Now we will examine some specific examples of the distributed systems.

Some of these systems are commercially available and widely used. Some of them have been developed and used internally in companies, but their design has been shared publicly via academic papers. The goal of the next few chapters is twofold:

* To provide an overview of the basic categories of distributed systems.
* To explain how these systems use the principles we learned so far.

However, keep in mind that some of the systems described in the next chapters might have evolved since the time of writing. As a reference, the table below contains the versions of the associated systems at the time of writing, when applicable.

| System | Version |
| --- | --- |
| HDFS | 3.1.2 |
| Zookeeper | 3.5.5 |
| Hbase | 2.0 |
| Cassandra | 3.11.4 |
| FaunaDB | 2.7 |
| Kafka | 2.3.1 |
| Kubernetes | 1.13.12 |
| Corda | 4.1 |
| Spark | 2.4.4 |
| Flink | 1.8 |

> We will see the details of these systems one by one in the next few chapters.

Backlesson

Mark As CompletedComplete

Next

Quiz on Security Protocols

Hadoop Distributed File System and Google File System

Ask

---


# Hadoop Distributed File System and Google File System

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Hadoop Distributed File System and Google File System

# Hadoop Distributed File System and Google File System

Learn what GFS and HDFS are. Look into the requirements and the architecture of GFS.

We'll cover the following...

* [Fault tolerance](#Fault-tolerance)
* [Scalability](#Scalability)
* [Optimized for batch operations](#Optimized-for-batch-operations)
* [GFS architecture](#GFS-architecture)
  + [Partitioning and replication](#Partitioning-and-replication)
  + [Network topology](#Network-topology)
  + [Balancing disk and network bandwidth](#Balancing-disk-and-network-bandwidth)
  + [Placing replicas](#Placing-replicas)

Google File System (GFS) is a proprietary distributed file system developed by Google. It is also the inspiration for the Hadoop Distributed File System (HDFS), a distributed file system developed as an [Apache project](https://www.apache.org).

> Note: The basic design principles are similar for these two systems, with some small differences.

The **core** requirements of distributed file systems are as follows:

## Fault tolerance[#](#Fault-tolerance)

The system should continue to function despite any node failures.

## Scalability[#](#Scalability)

The system should be able to scale to huge volumes of stored information.

## Optimized for batch operations[#](#Optimized-for-batch-operations)

The system should be optimized for use-cases that involve batch operations, such as applications that perform processing and analysis of huge datasets. This implies that *throughput* is more important than *latency*, and most of the files are expected to be mutated by appending data rather than overwriting existing data.

## GFS architecture[#](#GFS-architecture)

The following illustration gives an overview of the GFS architecture:

Created with Fabric.js 3.6.6

1 / 7

There are three kinds of nodes in the system: The manager, which holds a global catalogue of files, the client, which requests file operations and chunkservers which store files

Created with Fabric.js 3.6.6

1 / 7

Files consist of one or more chunks. The manager maintains a mapping of file chunks to chunkservers

Created with Fabric.js 3.6.6

1 / 7

Chunks are replicated across multiple chunk servers which maintain chunk consistency

Created with Fabric.js 3.6.6

1 / 7

A client wishing to perform an operation on a file sends a request to the mater with the filename and index of the chunk within that file, which is needed

Created with Fabric.js 3.6.6

1 / 7

The manager responds with the chunk server ID (where the required chunk can be found) and chunk handle

> **Note:** In the original research paper describing GFS, the authors use the term “master”, but we’ll use the term “GFS manager,” “manager node,” or simply “manager” to refer to the same thing.

A GFS cluster consists of a single **manager node** and multiple **chunk server nodes**.

* Chunk server nodes store and serve the data of the files.
* The manager node maintains the file system metadata, informing clients about which chunk servers store a specific part of a file and performing necessary administration tasks, such as garbage collection of orphaned chunks or data migration during failures.

> **Note**: The HDFS architecture is similar, but the manager node is called **Namenode**, and the chunkserver nodes are called **Datanodes**.

### Partitioning and replication[#](#Partitioning-and-replication)

Each file is divided into fixed-size chunks, identified by an immutable and globally unique 64-bit chunk handle assigned by the manager during chunk creation.

Chunk servers store chunks on local disks as regular files. The system employs both partitioning and replication:

* Partitions files across different chunk servers.
* Replicates each chunk on multiple chunk servers.

The former improves *performance* and the latter improves *availability* and *data reliability*.

> Note: The manager node is not involved in the transfer of file data to ensure good performance and scalability.

### Network topology[#](#Network-topology)

The system considers the network topology of a data center, which usually consists of multiple racks of servers. This has several implications, e.g., bandwidth into or out of a rack may be less than the aggregate bandwidth of all the machines within the rack, and a failure of a single shared resource in a rack (a network switch or power circuit) can essentially bring all the machines of the rack down.

### Balancing disk and network bandwidth[#](#Balancing-disk-and-network-bandwidth)

When GFS creates a new chunk and places its initially empty replicas, a manager tries to use chunk servers with below-average disk space utilization. It also tries to use chunk servers with low numbers of recent creations since that can reliably predict imminent heavy write traffic. In this way, the manager attempts to balance disk and network bandwidth utilization across the cluster.

### Placing replicas[#](#Placing-replicas)

When deciding where to place the replicas, the manager also follows a chunk replica placement policy that is configurable. By default, it will attempt to store two replicas at two different nodes that reside in the same rack while storing the third replica at a node that resides in a separate rack. This process is a trade-off between high *network bandwidth* and *data reliability*.

Backlesson

Mark As CompletedComplete

Next

Introduction

Creating and Reading Files

Ask

[Fault tolerance](#Fault-tolerance)

[Scalability](#Scalability)

[Optimized for batch operations](#Optimized-for-batch-operations)

[GFS architecture](#GFS-architecture)

[Partitioning and replication](#Partitioning-and-replication)

[Network topology](#Network-topology)

[Balancing disk and network bandwidth](#Balancing-disk-and-network-bandwidth)

[Placing replicas](#Placing-replicas)

---


# Creating and Reading Files

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Creating and Reading Files

# Creating and Reading Files

Let's understand how clients can create files and read data from files in a distributed file system.

We'll cover the following...

* [Create operation](#Create-operation)
* [Read operation](#Read-operation)
  + [Responsibilities of clients](#Responsibilities-of-clients)
  + [Responsibilities of the manager](#Responsibilities-of-the-manager)

The clients can create and read files from the distributed file system using a GFS client library linked to the application that abstracts some implementation details.

For example, the applications can operate based on byte offsets of files. The client library can translate these byte offsets to the associated chunk index and communicates with the manager to retrieve the chunk handle for the provided chunk index and the location of associated chunk servers. Finally, It contacts the appropriate chunkserver (most likely the closest one) to retrieve the data.

## Create operation[#](#Create-operation)

The manager node maintains the metadata about the filesystem. As a result, an operation that creates a file needs only to contact the manager node, which creates the file locally.

The manager node uses locking while creating new files to handle the concurrent requests safely. More specifically, a read lock is acquired on the directory name, and a write lock is acquired on the file name.

## Read operation[#](#Read-operation)

The following illustration displays the workflow for a read operation:

Created with Fabric.js 3.6.6

1 / 5

The manager holds a global catalogue of files consisting of one or more chunks and, the chunk servers store files where chunks are replicated across multiple chunk servers to maintain chunk consistency

Created with Fabric.js 3.6.6

1 / 5

A client wants to read the data on the chunk servers, so it first communicates with the manager to retrieve the chunk handle for the provided chunk index and the location of the associated chunkservers

Created with Fabric.js 3.6.6

1 / 5

The manager responds with the chunk server ID (where the required chunk can be found) and chunk handle

Created with Fabric.js 3.6.6

1 / 5

The client connects to the appropriate chunk server (most likely the closest one) to retrieve the data

Created with Fabric.js 3.6.6

1 / 5

The client receives the chunk data from the chunk server

### Responsibilities of clients[#](#Responsibilities-of-clients)

Clients cache the metadata for chunk locations locally, so they only have to contact the manager for new chunks or when the cache has expired.

During the migration of chunks due to failures, clients organically request fresh data from the manager when they realize the old chunk servers cannot serve the data for the specified chunk anymore.

> Note: On the other hand, clients do not cache the actual chunk data since they are expected to stream through huge files and have working sets that are too large to benefit from caching.

### Responsibilities of the manager[#](#Responsibilities-of-the-manager)

The manager stores:

* the file and chunk namespaces
* the mapping from files to chunks
* the chunk locations

All metadata is stored in the manager’s memory. The namespaces and the mappings are also kept persistent by logging mutating operations (e.g. file creation, renaming etc.) to an operation log that is stored on the manager’s local disk and replicated on remote machines. This is shown in the following illustration:

Created with Fabric.js 3.6.6

1 / 6

A system with a manager node and three chunk servers

Created with Fabric.js 3.6.6

1 / 6

The manager keeps metadata in its Memory

Created with Fabric.js 3.6.6

1 / 6

The manager snapshots the metadata and writes mutations log to the local Disk

Created with Fabric.js 3.6.6

1 / 6

The manager replicates the metadata snapshot and mutation log to other servers

Created with Fabric.js 3.6.6

1 / 6

The manager fails

The manager node also checkpoints its memory state to the disk when the log grows significantly. As a result, in case of the manager’s failure, the image of the filesystem can be reconstructed by loading the last checkpoint in memory and replaying the operation log from this point forward.

Backlesson

Mark As CompletedComplete

Next

Hadoop Distributed File System and Google File System

Writing and Deleting Files

Ask

[Create operation](#Create-operation)

[Read operation](#Read-operation)

[Responsibilities of clients](#Responsibilities-of-clients)

[Responsibilities of the manager](#Responsibilities-of-the-manager)

---


# Writing and Deleting Files

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Writing and Deleting Files

# Writing and Deleting Files

Learn how clients write and delete data on files in a distributed file system.

We'll cover the following...

* [Write operations](#Write-operations)
  + [Atomic and linearizable file namespace mutations](#Atomic-and-linearizable-file-namespace-mutations)
  + [Concurrency support](#Concurrency-support)
* [Delete operations](#Delete-operations)
* [Partial failures in write workflow](#Partial-failures-in-write-workflow)

The clients can write and delete files from the distributed file system by using a GFS client library linked into the application that abstracts some implementation details.

For example, the applications can operate based on byte offsets of files. The client library can translate these byte offsets to the associated chunk index and communicate with the manager to retrieve the chunk handle for the provided chunk index as well as the location of associated chunk servers. Finally, it contacts the appropriate chunk server (most likely the closest one) to retrieve the data.

## Write operations[#](#Write-operations)

Following are some write operations that clients can perform in a GFS system:

### Atomic and linearizable file namespace mutations[#](#Atomic-and-linearizable-file-namespace-mutations)

File namespace mutations are atomic and linearizable. This is achieved by executing this operation in a single node, the manager node. The operation log defines a total global order for these operations. The manager node also uses **read-write locks** on the associated namespace nodes to perform proper serialization on any concurrent writes.

### Concurrency support[#](#Concurrency-support)

GFS supports multiple concurrent writers for a single file. The following illustration illustrates how this works:

Created with Fabric.js 3.6.6

1 / 8

A GFS system with three nodes: client, manager and chunk server replicas

Created with Fabric.js 3.6.6

1 / 8

The client asks the manager about the chunkserver that contain the relevant chunks

Created with Fabric.js 3.6.6

1 / 8

The manager replies to the client with the chunkserver that contain the relevant chunks

Created with Fabric.js 3.6.6

1 / 8

The client pushes the data to all replicas

Created with Fabric.js 3.6.6

1 / 8

The client sends a write request to the primary replica, which identifies the data pushed earlier and assigns consecutive serial numbers to all the mutations

**1. Identifying chunk servers**

The client communicates with the manager node to identify the chunk servers that contain the relevant chunks.

**2. Pushing data to all replicas**

The client starts pushing the data to all the replicas using some form of chain replication.

The chunk servers are put in a chain depending on the network topology and data is pushed linearly along the chain.

For instance, the client pushes the data to the first chunk server in the chain, which pushes the data to the second chunk server. It helps fully utilize each machine’s network bandwidth avoiding bottlenecks in a single node.

The manager grants a lease for each chunk to one of the chunk servers, which is nominated as the primary replica, responsible for serializing all the mutations on this chunk.

**3. Writing data to all replicas**

After all the data is pushed to the chunk servers, the client sends a write request to the primary replica, identifying the data pushed earlier.

The primary assigns consecutive serial numbers to all the mutations, applies them locally, and then forwards the write request to all secondary replicas, which apply the mutations within the same serial number imposed by the primary.

**4. Acknowledge the write to the client**

After the secondary replicas have acknowledged the write to the primary replica, then the primary replica can acknowledge the write to the client.

## Delete operations[#](#Delete-operations)

Delete operations are also executed initially at the manager node only. The manager node makes use of the same locking scheme as when creating a file. Instead of completely removing the file, the manager node moves it into a hidden namespace where it can still be accessed (and undeleted) until it’s been permanently deleted. After a specific period of time, if the file still remains in this namespace, it is permanently removed, and all the associated references to chunks, etc. The actual content of the chunks is removed by the chunk servers lazily later on through a process of garbage collection.

## Partial failures in write workflow[#](#Partial-failures-in-write-workflow)

The write workflow described above is vulnerable to partial failures.

Think about the scenario where the primary replica crashes in the middle of performing a write. After the lease expires, a secondary replica can request the lease and start imposing a new serial number that might disagree with the writes of other replicas in the past. As a result, a write might be persisted only in some replicas or it might be persisted in different orders in different replicas.

> Note: GFS provides a custom consistency model for write operations which we will discuss in the [next](https://www.educative.io/courses/distributed-systems-practitioners/gfs-consistency-model) lesson.

Backlesson

Mark As CompletedComplete

Next

Creating and Reading Files

GFS Consistency Model

Ask

[Write operations](#Write-operations)

[Atomic and linearizable file namespace mutations](#Atomic-and-linearizable-file-namespace-mutations)

[Concurrency support](#Concurrency-support)

[Delete operations](#Delete-operations)

[Partial failures in write workflow](#Partial-failures-in-write-workflow)

---


# GFS Consistency Model

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

GFS Consistency Model

# GFS Consistency Model

Learn about the GFS consistency model for write operations.

We'll cover the following...

* [A region within a file](#A-region-within-a-file)
* [GFS’s extra mutation operation](#GFSs-extra-mutation-operation)
  + [Record appends](#Record-appends)
* [How applications accommodate the GFS consistency model](#How-applications-accommodate-the-GFS-consistency-model)
* [Mutation operation in HDFS](#Mutation-operation-in-HDFS)
* [GFS and HDFS summarised](#GFS-and-HDFS-summarised)

GFS provides a custom consistency model for write operations.

The state of a file region after a mutation depends on the type of mutation, whether it succeeds or fails and whether there are concurrent mutations.

> **Note:** A file region is **consistent** if all clients will always see the same data, regardless of the replica they read from.

## A region within a file[#](#A-region-within-a-file)

A region is defined after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety.

A region can be:

* **Defined and consistent:** When a mutation succeeds without interference from concurrent writes, the affected region is defined. All clients will always see what the mutation has written.
* **Undefined but consistent:** Concurrent successful mutations leave the region undefined but consistent. All the clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations.
* **Both inconsistent and undefined:** A failed mutation makes the region inconsistent. Different clients may see different data at times.

The following illustration shows these differences:

Created with Fabric.js 3.6.6

1 / 3

The file region is consistent, and defined, because the client can see what it wrote in all of the three Nodes

Created with Fabric.js 3.6.6

1 / 3

The file region is consistent but undefined because neither client can see what they wrote

Created with Fabric.js 3.6.6

1 / 3

Neither client can see what they wrote, and also the replicas have different data because the write failed in one replica

## GFS’s extra mutation operation[#](#GFSs-extra-mutation-operation)

Besides regular writes, GFS also provides an extra mutation operation called **record appends**.

### Record appends[#](#Record-appends)

A record append causes data to be appended atomically at least once even, in the presence of concurrent mutations but at an offset of GFS’s choosing, which is returned to the client.

Clients are supposed to retry failed record appends and GFS guarantees that each replica will contain the data of the operation as an atomic unit at least once in the same offset.

However, GFS may insert padding or record duplicates in between. As a result, successful record appends create defined regions interspersed with inconsistent regions.

The following table contains a summary of the GFS consistency model. You can see how write works in GFS:

## Summary of GFS consistency model

|  |  |  |
| --- | --- | --- |
|  | Write | Record Append |
| Serial success | *defined* | *defined interspersed with inconsistent* |
| Concurrent success | *consistent but undefined* |  |
| Failure | *inconsistent* | |  |

## How applications accommodate the GFS consistency model[#](#How-applications-accommodate-the-GFS-consistency-model)

Applications can accommodate this relaxed consistency model of GFS by applying a few simple techniques at the application layer:

* Using appends rather than overwrites
* Checkpointing
* Writing self-validating and self-identifying records

Appending is far more efficient and more resilient to application failures than random writes.

Each record prepared by a writer can contain extra information like checksums so that its validity can be verified. A reader can then identify and discard extra padding and record fragments using these checksums.

> **Note:** If occasional duplicates are not acceptable, e.g., if they could trigger non-idempotent operations, the reader can filter them out using unique record identifiers selected and persisted by the writer.

## Mutation operation in HDFS[#](#Mutation-operation-in-HDFS)

HDFS takes a slightly different path to simplify the semantics of mutating operations.

* HDFS supports only a single writer at a time.
* It supports only append (and not overwrite) operations.
* It also does not provide a record append operation, since there are no concurrent writes.
* It handles partial failures in the replication pipeline a bit differently, removing failed nodes from the replica set completely to ensure file content is the same in all replicas.

## GFS and HDFS summarised[#](#GFS-and-HDFS-summarised)

Both GFS and HDFS provide applications with the information where a region of a file is stored. This enables the applications to schedule processing jobs to run in nodes that store the associated data, minimizing network congestion and improving the system’s overall throughput. This principle is also known as **moving computation to the data**.

Now that you’ve gone through the important concepts of Google File System (GFS) and Hadoop Distributed File System (HDFS), test your knowledge by interacting with the AI Mentor below. You’ll answer a total of five questions focused on the workings of GFS and HDFS. To get started, say hello to Edward in the widget below, and it will lead the way.

Want to know the correct answer?

Powered by AI

16 Prompts Remaining

Prompt AI WidgetOur tool is designed to help you to understand concepts and ask any follow up questions. Ask a question to get started.

Backlesson

Mark As CompletedComplete

Next

Writing and Deleting Files

Quiz on Distributed File Systems

Ask

[A region within a file](#A-region-within-a-file)

[GFS’s extra mutation operation](#GFSs-extra-mutation-operation)

[Record appends](#Record-appends)

[How applications accommodate the GFS consistency model](#How-applications-accommodate-the-GFS-consistency-model)

[Mutation operation in HDFS](#Mutation-operation-in-HDFS)

[GFS and HDFS summarised](#GFS-and-HDFS-summarised)

---


# Quiz on Distributed File Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed File Systems

# Quiz on Distributed File Systems

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

What is the benefit of using chain replication in GFS?

A.

The bandwidth required for replication is shared amongst replicas uniformly

B.

It ensures consistency

C.

Some replicas have priority over others

---

1 / 5

Submit Answer

Backlesson

Mark As CompletedComplete

Next

GFS Consistency Model

Coordination Service

Ask

---


# Coordination Service

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Coordination Service

# Coordination Service

Let's have an overview of coordination in distributed systems.

We'll cover the following...

* [Coordination as an API](#Coordination-as-an-API)
  + [Chubby](#Chubby)
  + [Zookeeper](#Zookeeper)
  + [etcd](#etcd)

It must have become evident by now that **coordination** is a central aspect of distributed systems.

Even though each component of a distributed system might function correctly in isolation, one needs to ensure that they will also function correctly when operating simultaneously. This can be achieved through some form of coordination between these components.

## Coordination as an API[#](#Coordination-as-an-API)

As illustrated in the chapter about [consensus](https://www.educative.io/courses/distributed-systems-practitioners/defining-the-consensus-problem), this coordination can be quite complicated with many edge cases. Consequently, implementing these coordination algorithms on every new system from scratch would be inefficient and would also introduce a lot of risk for bugs.

On the contrary, if there was a separate system that could provide this form of coordination as an API, it would be a lot easier for other systems to offload any coordination function to this system.

Several different systems were born out of this need which are listed below:

### Chubby[#](#Chubby)

Chubby was a system implemented internally in Google and used from several different systems for coordination purposes.

### Zookeeper[#](#Zookeeper)

Zookeeper is a system that was partially inspired from Chubby, it was originally developed in Yahoo and later became an Apache project.

Many companies have widely used it to perform coordination in distributed systems, including some systems that are part of the Hadoop ecosystem.

### etcd[#](#etcd)

[etcd](https://etcd.io) is another coordination system that implements similar coordination primitives and later formed the basis of Kubernetes’ control plane.

> These three systems have a lot of similarities, but they also slightly differ from each other.

In short, this chapter will focus on Zookeeper, providing an overview of its design. It will also explain the basic differences of the other two systems where relevant.

Backlesson

Mark As CompletedComplete

Next

Quiz on Distributed File Systems

Zookeeper

Ask

[Coordination as an API](#Coordination-as-an-API)

[Chubby](#Chubby)

[Zookeeper](#Zookeeper)

[etcd](#etcd)

---


# Zookeeper

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Zookeeper

# Zookeeper

Let’s explore the Zookeeper’s API for coordination purposes.

We'll cover the following...

* [Zookeeper’s API operations](#Zookeepers-API-operations)
* [Types of nodes](#Types-of-nodes)
* [Zookeeper’s API benefits](#Zookeepers-API-benefits)
* [Zookeeper ensemble](#Zookeeper-ensemble)
* [Zookeeper protocol](#Zookeeper-protocol)
* [Zookeeper’s sync operation](#Zookeepers-sync-operation)

**Zookeeper’s API** is essentially a hierarchical namespace similar to a filesystem.

> **Chubby** also provides a hierarchical namespace, while **etcd** provides a key-value interface.

In the illustration below, we can see:

* Every name is a sequence of path elements separated by a slash (/).
* Every name represents a data node (called **znode**), which can contain a piece of metadata and children nodes.

For example, the node “/a/b” is considered a child of the node “/a”.

Hierarchical namespace in Zookeeper

## Zookeeper’s API operations[#](#Zookeepers-API-operations)

The Zookeeper’s API contains basic operations that can create nodes, delete nodes, check if a specific node exists, list the children of a node and read or set the data of a node.

## Types of nodes[#](#Types-of-nodes)

There are two types of znodes: **regular nodes** and **ephemeral nodes**.

* Regular nodes are created and deleted explicitly by the clients.
* Ephemeral nodes can be removed by the system when the session that created them expires (i.e., due to a failure).

## Zookeeper’s API benefits[#](#Zookeepers-API-benefits)

When a client creates a new node, it can set a **sequential flag**. Nodes created with this flag have the value of a monotonically increasing counter appended to a provided prefix.

Zookeeper also provides an API that allows clients to receive notifications for changes without polling, called **watches**.

On read operations, clients can set a **watch flag**, so that they are notified by the system when the information returned has changed.

A client connects to Zookeeper initiating a session, which needs to be maintained open by sending heartbeats to the associated server. If a Zookeeper server does not receive anything from a client for more than a specified timeout, it considers the client faulty and terminates the session. This deletes the associated ephemeral nodes and unregisters any watches registered via this session.

The update operations can take an expected version number, which enables the implemented conditional updates to resolve any conflicts arising from concurrent update requests.

## Zookeeper ensemble[#](#Zookeeper-ensemble)

Zookeeper nodes form a cluster, called a Zookeeper ensemble.
One of the nodes is designated as the **leader** and the rest of the nodes are the **followers**.

Created with Fabric.js 3.6.6

1 / 8

A system of five nodes: a leader, a client, and three follower nodes

Created with Fabric.js 3.6.6

1 / 8

The client sends a read request to follower

Created with Fabric.js 3.6.6

1 / 8

Follower responds to the client's read request

Created with Fabric.js 3.6.6

1 / 8

The client sends a write request to the follower

Created with Fabric.js 3.6.6

1 / 8

Follower forwards the write request to the leader

## Zookeeper protocol[#](#Zookeeper-protocol)

Zookeeper uses a custom atomic broadcast protocol, called Zookeeper atomic broadcast protocol **(Zab)**, which was proposed by Junqueira et al. and exploited by Medeiros.

This protocol is used to elect the leader and replicate the write operations to the followers.

> **Note**: Chubby uses Paxos protocol for this purpose, while etcd uses Raft protocol.

Each of the nodes has a copy of the Zookeeper state in memory. Also the changes are recorded in a durable, write-ahead log which can be used for recovery.

All the nodes can serve read requests using their local database.

Followers have to forward any write requests to the leader node, wait until the request has been successfully replicated and broadcasted, and then respond to the client.

Reads can be served locally without any communication between nodes, so they are extremely fast.

## Zookeeper’s sync operation[#](#Zookeepers-sync-operation)

A follower node might be lagging behind the leader node, so client reads might not necessarily reflect the latest performed write t, thus not providing linearizability. For this reason, Zookeeper provides an additional operation called **sync** that clients can use to reduce the possibility of stale data.

This operation will be directed to the current leader, who will put it at the tail of the queue that contains pending requests to be sent to the corresponding follower.

The follower will wait for the completion of any pending sync operations before replying to subsequent read operations.

It is important to note that the sync operation does not need to go through the broadcast protocol and thus reach a majority quorum, it is just placed at the end of the leader’s queue and forwarded only to the associated follower.

> **Note:** In contrast, in Chubby, both read and write requests are directed to the leader. This has the benefit of increased consistency but the downside of decreased throughput. To mitigate this, Chubby clients cache extensively and the leader is responsible for invalidating the caches before completing writes. This makes the system a bit more sensitive to client failures.

As a result, read operations are not linearizable with respect to write operations even if a sync operation is used first.

Backlesson

Mark As CompletedComplete

Next

Coordination Service

Guarantees Provided by Zookeeper

Ask

[Zookeeper’s API operations](#Zookeepers-API-operations)

[Types of nodes](#Types-of-nodes)

[Zookeeper’s API benefits](#Zookeepers-API-benefits)

[Zookeeper ensemble](#Zookeeper-ensemble)

[Zookeeper protocol](#Zookeeper-protocol)

[Zookeeper’s sync operation](#Zookeepers-sync-operation)

---


# Guarantees Provided by Zookeeper

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Guarantees Provided by Zookeeper

# Guarantees Provided by Zookeeper

Let's look into the Zookeeper's consistency model and the guarantees that it provides.

We'll cover the following...

* [Zookeeper’s consistency model](#Zookeepers-consistency-model)
  + [Safety Guarantees](#Safety-Guarantees)
    - [Linearizable writes](#Linearizable-writes)
    - [Sequentially consistent reads](#Sequentially-consistent-reads)
    - [FIFO client order](#FIFO-client-order)
* [Liveness and durability guarantees](#Liveness-and-durability-guarantees)
  + [Liveness](#Liveness)
  + [Durability](#Durability)

## Zookeeper’s consistency model[#](#Zookeepers-consistency-model)

The formal consistency model by Zookeeper lies between *sequential consistency* and *linearizability*, called ordered sequential consistency.

### Safety Guarantees[#](#Safety-Guarantees)

Zookeeper provides the following safety guarantee:

#### Linearizable writes[#](#Linearizable-writes)

All requests that update the state of Zookeeper are linearizable and respect precedence. This means that each write operation will take effect atomically at some point between when the client issues the request and receives the corresponding response.

However, merely stating that write operations are linearizable is meaningless since we need to perform read operations to notice their effects.

#### Sequentially consistent reads[#](#Sequentially-consistent-reads)

Read operations will take effect in some sequential order that respects the order of each client’s operations. As they are ordered sequentially consistent.

#### FIFO client order[#](#FIFO-client-order)

Zookeeper executes all the clients’ requests in the exact order in which they are sent.

> Note: Zookeeper also provides an **ordering guarantee**. If a client is waiting for a change, the client will see the notification event before it sees the new state of the system. As a result, when a client receives a notification and performs a read, the result will reflect all writes at least up to the one that triggered this notification.

## Liveness and durability guarantees[#](#Liveness-and-durability-guarantees)

Zookeeper also provides liveness and durability guarantees.

### Liveness[#](#Liveness)

If a majority of servers are active and communicating, the service will be available.

### Durability[#](#Durability)

If the service responds successfully to a change request, that change will persist across any number of failures as long as a quorum of servers is eventually able to recover.

Backlesson

Mark As CompletedComplete

Next

Zookeeper

Zookeeper's ZAB Protocol

Ask

[Zookeeper’s consistency model](#Zookeepers-consistency-model)

[Safety Guarantees](#Safety-Guarantees)

[Linearizable writes](#Linearizable-writes)

[Sequentially consistent reads](#Sequentially-consistent-reads)

[FIFO client order](#FIFO-client-order)

[Liveness and durability guarantees](#Liveness-and-durability-guarantees)

[Liveness](#Liveness)

[Durability](#Durability)

---


# Zookeeper's ZAB Protocol

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Zookeeper's ZAB Protocol

# Zookeeper's ZAB Protocol

Let’s explore the phases of the ZAB protocol.

We'll cover the following...

* [ZAB protocol Phases](#ZAB-protocol-Phases)
  + [Leader election](#Leader-election)
  + [Discovery](#Discovery)
  + [Synchronization](#Synchronization)
  + [Broadcast](#Broadcast)

As mentioned previously, the **Zookeeper atomic broadcast protocol (ZAB)** is used to agree on a leader in the ensemble, synchronize the replicas, manage the broadcast of update transactions, and recover from a crashed state to a valid state.

This protocol shares a lot of characteristics with other consensus protocols, such as Paxos or Raft.

In ZAB, transactions are identified by a specific type of identifier, called **zxid**. This identifier consists of two parts <e,c><e, c><e,c>, where eee is the epoch number of the leader that generates the transaction and ccc is an integer acting as a counter for this epoch.

The counter ccc is incremented every time a new transaction is introduced by the leader, while eee is incremented when a new leader becomes active.

## ZAB protocol Phases[#](#ZAB-protocol-Phases)

The protocol consists of four basic phases as shown in the following illustration:

Created with Fabric.js 3.6.6

1 / 6

All nodes are initialized in the Leader election phase

Created with Fabric.js 3.6.6

1 / 6

Node B is designated as the prospective leader, and the quorum has been obtained

Created with Fabric.js 3.6.6

1 / 6

The prospective leader queries the other Nodes for the most up to date sequence of accepted transactions, and establishes a new epoch

Created with Fabric.js 3.6.6

1 / 6

The leader synchronizes all replicas using its updated history

Created with Fabric.js 3.6.6

1 / 6

The prospective leader is considered elected

### Leader election[#](#Leader-election)

In the first phase, the state election initializes the peers. This phase gets terminated as soon as a quorum of peers votes for a leader. This leader is prospective and will become an established leader only at the end of phase three.

### Discovery[#](#Discovery)

In the second phase, the leader communicates with the followers to discover the most up-to-date sequence of accepted transactions among a quorum and establish a new epoch so previous leaders cannot commit new proposals.

### Synchronization[#](#Synchronization)

In the third phase, the leader synchronizes the replicas in the ensemble using the leader’s updated history from the previous phase. The leader is established at the end of this phase.

### Broadcast[#](#Broadcast)

In the last phase, the leader receives write requests and performs broadcasts of the associated transactions. This phase lasts until the leader loses its leadership, which is essentially maintained via heartbeats to the followers.

> Note: Practically, Zookeeper uses a leader election algorithm called **Fast Leader Election** (**FLE**), to employ an optimisation. It attempts to elect a leader that has the most up-to-date history from a quorum of processes. This algorithm minimizes the data exchange between the leader and the followers in the Discovery phase.

Backlesson

Mark As CompletedComplete

Next

Guarantees Provided by Zookeeper

Examples of Powerful Primitives by Zookeeper API

Ask

[ZAB protocol Phases](#ZAB-protocol-Phases)

[Leader election](#Leader-election)

[Discovery](#Discovery)

[Synchronization](#Synchronization)

[Broadcast](#Broadcast)

---


# Examples of Powerful Primitives by Zookeeper API

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Examples of Powerful Primitives by Zookeeper API

# Examples of Powerful Primitives by Zookeeper API

Let's discuss some examples of primitives built by using the Zookeeper's API.

We'll cover the following...

* [Configuration management](#Configuration-management)
* [Group membership](#Group-membership)
* [Simple locks](#Simple-locks)
* [Locks without herd effect](#Locks-without-herd-effect)

The Zookeeper API can be used to build powerful primitives. Some examples are as follows:

## Configuration management[#](#Configuration-management)

Zookeeper’s API can configure management simply by publishing the node with some configuration information. Create a znode zcz\_czc​ and write the configuration as the znode’s data.

The znode’s path is provided to the other nodes of the system, which obtain the configuration by reading zcz\_czc​. They also register a watch so that they are informed when this configuration changes. If that happens, they are notified and perform a new read to get the latest configuration.

## Group membership[#](#Group-membership)

A node zgz\_gzg​ is designated to represent the group. When a node wants to join the group, it creates an ephemeral child node under zgz\_gzg​. If each node has a unique name or identifier, this can be used as the name of the child node.

Alternatively, the nodes can use the sequential flag to obtain a unique name assignment from Zookeeper. These nodes can also contain additional metadata for the group members, such as addresses and ports.

Nodes can obtain the members of the group by listing the children of zgz\_gzg​. If a node also wants to monitor changes in the group membership, it can register a watch. When nodes fail, their associated ephemeral nodes are automatically removed, which signals their removal from the group.

## Simple locks[#](#Simple-locks)

We can implement lock by simply using a **lock file** represented by a znode.

To acquire a lock, a client tries to create the designated znode with the ephemeral flag. If the create succeeds, the client holds the lock. Otherwise, the client can set a watch to notify the created node .So when the lock is released, it can attempt to re-acquire it. The lock is released when the client explicitly deletes the znode or when it dies.

## Locks without herd effect[#](#Locks-without-herd-effect)

The process of acquiring a lock file suffers from the herd effect. If many clients are waiting to acquire a lock, they will all be notified simultaneously. They will attempt to acquire the lock even though only one can acquire it, thus creating unnecessary contention.

There is a different way to implement locks to avoid this problem. All the clients compete for the lock file to create a sequential, ephemeral znode with the same prefix (i.e. /lock-). The client with the smallest sequence number will acquire the lock. The rest of the clients will register watches for the znode with the next lower sequence number. Once a node gets notified, it checks if it’s now the lowest sequence number, which means it can acquire the lock. Otherwise, it registers a new watch for the next znode with the lower sequence number.

> Note:Many more primitives such as read/write locks, barriers etc can be built in the similar pattern by using the Zookeeper’s API . These patterns in Zookeeper are usually called [recipes](https://zookeeper.apache.org/doc/current/recipes.html).

Test your knowledge of the important concepts of the distributed coordination service by interacting with the widget below. Use the widget to answer a total of seven questions focused on “coordination as an API.” To get started, say hello to Edward in the widget below, and it will lead the way.

Want to know the correct answer?

Powered by AI

16 Prompts Remaining

Prompt AI WidgetOur tool is designed to help you to understand concepts and ask any follow up questions. Ask a question to get started.

Backlesson

Mark As CompletedComplete

Next

Zookeeper's ZAB Protocol

Quiz on Distributed Coordination Service

Ask

[Configuration management](#Configuration-management)

[Group membership](#Group-membership)

[Simple locks](#Simple-locks)

[Locks without herd effect](#Locks-without-herd-effect)

---


# Quiz on Distributed Coordination Service

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed Coordination Service

# Quiz on Distributed Coordination Service

We'll cover the following...

In the following quiz, test yourself on what you have learned in this chapter:

Technical Quiz

1.

Which of the following nodes are deleted explicitly by the clients?

A.

Ephemeral nodes

B.

Regular nodes

---

1 / 2

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Examples of Powerful Primitives by Zookeeper API

Introduction

Ask

---


# Introduction

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction

# Introduction

Let's have a look at the four basic categories of the distributed datastores in this chapter.

We'll cover the following...

In this chapter, we will examine some basic categories of distributed data stores. It is impossible to cover all available datastores here. Because each data store can have some unique characteristics that make it different from the rest of the category, it is not easy to establish clear boundaries and classify them into well-defined categories. For this reason, datastores are grouped based on their most basic architectural characteristics and their historical origins.

Based on the above criteria, this chapter will explore four distributed datastores, **BigTable**/**HBase**, **Cassandra**, **Spanner**, and **Fauna DB**. We will learn to draw comparisons against these and will understand the strengths and weaknesses of each one.

![](images/image_1764834307.9379876.svg)![](images/4959772423094272.svg)

Backlesson

Mark As CompletedComplete

Next

Quiz on Distributed Coordination Service

BigTable/HBase Architecture

Ask

---


# BigTable/HBase Architecture

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

BigTable/HBase Architecture

# BigTable/HBase Architecture

Let's explore what BigTable and HBase are, and look into the data model and architecture of HBase.

We'll cover the following...

* [HBase data model](#HBase-data-model)
  + [Goal of HBase](#Goal-of-HBase)
* [HBase Architecture](#HBase-Architecture)
  + [The HManager](#The-HManager)
  + [Region servers](#Region-servers)
  + [Usage of Zookeeper in HBase](#Usage-of-Zookeeper-in-HBase)
  + [Data storage](#Data-storage)
  + [META table](#META-table)
  + [Creation of ephemeral node](#Creation-of-ephemeral-node)

BigTable is a distributed storage system initially developed in Google and was the inspiration for [HBase](https://hbase.apache.org), a distributed datastore that is part of the Apache Hadoop project.

> Note that the architecture of these two systems is very similar to each other, so we will focus only on HBase, which is an open-source system.

## HBase data model[#](#HBase-data-model)

HBase provides a sparse, multi-dimensional sorted map as a data model, as shown in the following illustration:

HBase data model and physical layout

The map is indexed by a **row key**, a **column key** (e.g. C1, C2, C4 etc.) and a **timestamp**, while each value in the map is an uninterpreted array of bytes.

The columns are further grouped in column families (e.g. CF1, CF2 etc.). All members of a column family are physically stored together on the filesystem and the user can specify tuning configurations for each column family, such as compression type or in-memory caching.

Column families need to be declared upfront during schema definition, but columns can also be created dynamically. Furthermore, the system supports a small number of column families, but an unlimited number of columns.

The keys are also uninterpreted bytes and rows of the table are physically stored in the lexicographical order of the keys. Each table is partitioned horizontally using range partitioning based on the row key into segments, called
**regions** (e.g. [A, D], [E, K] etc.).

> Note that the ranges correspond to the regions.

### Goal of HBase[#](#Goal-of-HBase)

The main goal of HBase data model and the architecture is to allow the user to control the physical layout of data, so that related data are stored near each other.

## HBase Architecture[#](#HBase-Architecture)

The following illustration shows the high-level architecture of HBase, which is also based on **manager-worker** architecture. The leader is called **HManager** and the followers are called **region servers**:

![](images/image_1764834324.4667053.svg)![HBase high-level architecture](images/6627390045421568.svg "HBase high-level architecture")

HBase high-level architecture

### The HManager[#](#The-HManager)

The HManager is responsible for:

* Assigning regions to region servers
* Detecting the addition and expiration of region servers
* Balancing region server load
* Handling schema changes

### Region servers[#](#Region-servers)

Each region server:

* Manages a set of regions
* Handles read and write requests to the loaded regions.
* Splits regions that have grown too large.

> Note that like other primary-backup distributed systems, clients do not communicate with the primary for data flow operations but only for control flow operations to prevent it from becoming the system’s performance bottleneck.

### Usage of Zookeeper in HBase[#](#Usage-of-Zookeeper-in-HBase)

Hbase uses **Zookeeper** to:

* Perform a leader election to decide the manager node
* Maintain group membership of region servers
* Store the bootstrap location of HBase data
* Store schema information
* Access control lists

### Data storage[#](#Data-storage)

Each region server stores the data for the associated regions in **HDFS**, which provides the necessary redundancy.

A region server can be collocated at the same machine as an HDFS datanode to enable data locality and minimize network traffic.

### META table[#](#META-table)

There is a special HBase table, called the META table, which contains the mapping between regions and region servers in the cluster.

The location of this META table is stored in Zookeeper. As a result, the first time a client needs to read/write to HBase, it first communicates with Zookeeper to retrieve the region server that hosts the META table, then contacts this region server to find the region server containing the desired table and finally sends the read/write operation to that server.

The client caches locally the location of the META table and the data already read from this table for future use.

### Creation of ephemeral node[#](#Creation-of-ephemeral-node)

HManagers initially compete to create an ephemeral node in Zookeeper. The first becomes the active manager, while the second one listens for notifications from Zookeeper of the active manager failure.

Similarly, region servers create ephemeral nodes in Zookeeper at a directory monitored by the HManager. In this way, the HManager is aware of region servers that join/leave the cluster, so that it can assign regions accordingly.

Backlesson

Mark As CompletedComplete

Next

Introduction

Appends and Read Operations in HBase

Ask

[HBase data model](#HBase-data-model)

[Goal of HBase](#Goal-of-HBase)

[HBase Architecture](#HBase-Architecture)

[The HManager](#The-HManager)

[Region servers](#Region-servers)

[Usage of Zookeeper in HBase](#Usage-of-Zookeeper-in-HBase)

[Data storage](#Data-storage)

[META table](#META-table)

[Creation of ephemeral node](#Creation-of-ephemeral-node)

---


# Appends and Read Operations in HBase

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Appends and Read Operations in HBase

# Appends and Read Operations in HBase

Let's inspect how appends are more efficient than random writes and how we can optimize the inefficiency of read operations.

We'll cover the following...

* [Appends](#Appends)
  + [MemStore](#MemStore)
  + [HFile](#HFile)
  + [Write ahead log (WAL)](#Write-ahead-log-WAL)
  + [BlockCache](#BlockCache)
* [Inefficiency of read operations](#Inefficiency-of-read-operations)
  + [Optimizing read operations](#Optimizing-read-operations)
    - [Bloom filters](#Bloom-filters)

## Appends[#](#Appends)

**Appends** are more efficient than random writes, especially in a filesystem like HDFS. Region servers try to take advantage of this fact by employing the following components for storage and data retrieval.

### MemStore[#](#MemStore)

MemStore is used as a write cache. Writes are initially written in this data structure, which is stored in-memory and can be sorted efficiently before being written to disk. Writes are buffered in this data structure and periodically written to HDFS after being sorted.

### HFile[#](#HFile)

This is the file in HDFS that stores sorted key-value entries on disk.

### Write ahead log (WAL)[#](#Write-ahead-log-WAL)

It stores operations that are not persisted to permanent storage and are only stored in the MemStore. WAL is also stored in HDFS and is used for recovery in the case of a region server failure.

### BlockCache[#](#BlockCache)

**BlockCache** is the read-cache that stores frequently read data in memory and evicts the least recently used data when the cache is full.

As a result, write operations go through WAL and MemStore first and then eventually end up being stored in HFiles, as shown in the following illustration:

> Note: This pattern originates from a data structure, called a **log-structured merge (LSM)** tree.

Read and write data flow in HBase

## Inefficiency of read operations[#](#Inefficiency-of-read-operations)

Read operations have to read from the MemStore, the BlockCache, and the existing HFiles and merge the results. This can be quite inefficient, so several optimizations are used to make the read operations efficient.

### Optimizing read operations[#](#Optimizing-read-operations)

As mentioned previously, columns are grouped by their column family and stored separately. As a result, only the HFiles containing the required column family need to be queried. All the entries in an HFile are stored in lexicographical order, and they contain an index at the end of the file, which can be kept in memory, so read can find the required data without reading the whole file.

Each HFile also contains the time range of the entries contained in it to avoid unnecessary reads of files that cannot contain the requested data.

#### Bloom filters[#](#Bloom-filters)

[Bloom filters](https://en.wikipedia.org/wiki/Bloom_filter) reduce the number of HFiles that need to be read; special data structures make it easy to identify whether some data is not contained in a file using minimal memory. There is also a background process, called **compaction**, which merges multiple HFiles into a single HFile removing older versions of data that are not needed anymore, thus reducing the number of HFiles that need to be inspected during read operations.

Backlesson

Mark As CompletedComplete

Next

BigTable/HBase Architecture

Guarantees Provided by HBase

Ask

[Appends](#Appends)

[MemStore](#MemStore)

[HFile](#HFile)

[Write ahead log (WAL)](#Write-ahead-log-WAL)

[BlockCache](#BlockCache)

[Inefficiency of read operations](#Inefficiency-of-read-operations)

[Optimizing read operations](#Optimizing-read-operations)

[Bloom filters](#Bloom-filters)

---


# Guarantees Provided by HBase

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Guarantees Provided by HBase

# Guarantees Provided by HBase

We'll cover the following...

* [Atomicity](#Atomicity)
* [Consistency & Isolation](#Consistency--Isolation)
* [Durability](#Durability)
* [Mapping between HBase and Bigtable](#Mapping-between-HBase-and-Bigtable)

The HBase provides the *atomicity*, *consistency* and *isolation*, and *durability* guarantee. These guarantees are discussed in detail in the following section:

## Atomicity[#](#Atomicity)

Operations that mutate a single row are atomic. For example:

* An operation that returns a success code has completely succeeded.
* An operation that returns a failure code has completely failed.
* An operation that times out may have succeeded or may have failed. However, it cannot have partially succeeded or failed.
* This is true even if the mutation crosses multiple column families within a row. This is achieved by fine-grained, per-row locking.

> **Note**: HFiles are essentially immutable, so only the MemStore needs to participate. This makes the process very efficient.

Operations that mutate multiple rows will not be atomic. For example, a mutative operation on rows `a`, `b` and `c` may return having mutated some but not all of the rows. In this case, the operation will return a list of codes, some of which may be successes, failures, or timeouts.

Hbase provides a conditional operation, called **checkAndPut**, which happens atomically like the typical compareAndSet (CAS) operation found in many hardware architectures.

## Consistency & Isolation[#](#Consistency--Isolation)

Single-row reads/writes are linearizable.When a client receives a successful response for any mutation, this mutation is immediately visible to both that client and any client with whom it later communicates through side channels.

HBase provides a scan operation that provides efficient iteration over multiple rows. This operation does not provide a consistent view of the table and does not exhibit snapshot isolation.

Instead:

* Any row returned by the scan is a consistent view, i.e., that a version of the complete row existed at some point in time.
* A scan operation must reflect all mutations committed prior to the construction of the scanner and may reflect some mutations committed subsequent to the construction of the scanner.

## Durability[#](#Durability)

All visible data is also durable. This means that a read will never return data that has not been made durable on a disk.Further, any mutative operation that returns a successful response has been made durable.Finally, any operation that has been made durable is stored in at least n different servers (Namenodes), where n is the configurable replication factor of HDFS.

## Mapping between HBase and Bigtable[#](#Mapping-between-HBase-and-Bigtable)

As mentioned earlier, HBase and Bigtable have a very similar architecture with slightly different names for the various components and have different dependencies. The table below contains a mapping between HBase concepts and the associated concepts in Bigtable.

| HBase | Bigtable |
| --- | --- |
| region | tablet |
| region server | tablet server |
| Zookeeper | Chubby |
| HDFS | GFS |
| HFile | SSTable |
| MemStore | Memtable |

Backlesson

Mark As CompletedComplete

Next

Appends and Read Operations in HBase

Cassandra's Data Model

Ask

[Atomicity](#Atomicity)

[Consistency & Isolation](#Consistency--Isolation)

[Durability](#Durability)

[Mapping between HBase and Bigtable](#Mapping-between-HBase-and-Bigtable)

---


# Cassandra's Data Model

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Cassandra's Data Model

# Cassandra's Data Model

This lesson explains Cassandra's design goals and its data model.

We'll cover the following...

* [Design goals of Cassandra](#Design-goals-of-Cassandra)
* [Data model](#Data-model)
  + [Table](#Table)
  + [Schema](#Schema)
  + [Primary key](#Primary-key)
    - [Partition key component](#Partition-key-component)
    - [Clustering columns component](#Clustering-columns-component)
  + [Distributing the partitions of the table over the available nodes](#Distributing-the-partitions-of-the-table-over-the-available-nodes)
  + [Replicating partitions across the nodes](#Replicating-partitions-across-the-nodes)
  + [Storage engines for nodes](#Storage-engines-for-nodes)

Cassandra is a distributed datastore that combines ideas from the Dynamo and the Bigtable paper.

> Note: Besides Dynamo there is also a separate distributed system, called DynamoDB. This is commercially available, but details around its internal architecture have not been shared publicly yet. However, this system has a lot of similarities with Cassandra, such as the data model and tunable consistency.

Cassandra was originally developed by Facebook, but it was then open-sourced and became an Apache project.During this period, it has evolved significantly from its original implementation.

> Note: The information in this chapter refers to the state of this project at the time of writing this course.

## Design goals of Cassandra[#](#Design-goals-of-Cassandra)

The main design goals of Cassandra are:

* Extremely high availability
* Performance (high throughput/low latency with emphasis on write-heavy workloads) with unbounded, incremental scalability

> Note: In order to achieve these goals Cassandra trades off some other properties, such as **strong consistency**.

## Data model[#](#Data-model)

The data model is relatively simple: it consists of keyspaces at the highest level, which can contain multiple, different tables.

### Table[#](#Table)

Each **table** stores data in sets of rows and is characterised by a schema.

### Schema[#](#Schema)

The **schema** defines the structure of each row, which consists of the various columns and their types. It also determines the primary key.

### Primary key[#](#Primary-key)

The **primary key** is a column or a set of columns that have unique values for each row. The primary key can have two components:

* The first component is the partition key and, it’s mandatory
* The second component contains the clustering columns and is optional

If both of these components are present, then the primary key is called a **compound primary key**.

> Note: Furthermore, if the partition key is composed of multiple columns, it’s called a **composite partition key**.

The following illustration contains two tables, one has a simple primary key and the other has a compound primary key.

## Tables having different keys

|  |  |
| --- | --- |
| Simple Primary Key | Compound Primary Key |
| CREATE TABLE Employees (  employee\_id uuid,  first\_name text,  last\_name text,  PRIMARY KEY (employee\_id)  ); | CREATE TABLE ProductCatalog (  product\_id uuid,  size int,  price decimal,  PRIMARY KEY (product\_id, size)  ); |

The primary key of a table is one of the most important parts of the schema because it determines how data is distributed across the system and also how it is stored in every node.

#### Partition key component[#](#Partition-key-component)

The first component of the primary key, the partition key determines the distribution of data. The rows of a table are conceptually split into different partitions, where each partition contains only rows with the same value for the defined partition key. All the rows corresponding to a single partition are guaranteed to be stored collocated in the same nodes, while rows belonging to different partitions can be distributed across different nodes.

#### Clustering columns component[#](#Clustering-columns-component)

The second component of the primary key, the clustering columns, determines how rows of the same partition will be stored on a disk. Specifically, rows of the same partition will be stored in ascending order of the clustering columns defined unless specified otherwise. The following illustration elaborates the previous example, showing how data from the two tables would be split into partitions and stored in practice:

Cassandra partitioning

We did partitioning using consistent hashing. So, the partition key determines the partition in which a row goes.

### Distributing the partitions of the table over the available nodes[#](#Distributing-the-partitions-of-the-table-over-the-available-nodes)

Cassandra distributes the partitions of a table across the available nodes using **consistent hashing**. It also uses virtual nodes to provide balanced, fine-grained partitioning. As a result, all the virtual nodes of a Cassandra cluster form a ring.

Each virtual node corresponds to a specific value in the ring, called the **token**, which determines which partitions will belong to this virtual node.

Each virtual node contains all the partitions whose partition key (when hashed) falls in the range between its token and the token of the previous virtual node in the ring, as shown in the following illustration:

> Cassandra also supports some form of range partitioning via the **ByteOrderedPartitioner**. However, this is available mostly for backward compatibility reasons, and it’s not recommended since it can cause issues with hot spots and imbalanced data distribution.

Cassandra partitioning

Every Cassandra node can be assigned multiple virtual nodes.

### Replicating partitions across the nodes[#](#Replicating-partitions-across-the-nodes)

Each partition is replicated across NNN nodes, where NNN is a number that is configurable per keyspace, and it’s called the **replication factor**. There are multiple available replication strategies that determine how the additional N−1N-1N−1 nodes are selected.

The most straightforward strategy selects the subsequent nodes clockwise in the ring. More complicated strategies also take into account the network topology of the nodes for the selection.

### Storage engines for nodes[#](#Storage-engines-for-nodes)

The storage engine for each node is inspired by **Bigtable**. It is based on a commit log containing all the mutations and a **memtable** that is periodically flushed to **SSTables**, which are also periodically merged via compactions.

Backlesson

Mark As CompletedComplete

Next

Guarantees Provided by HBase

Cassandra's Cluster Internode Communication

Ask

[Design goals of Cassandra](#Design-goals-of-Cassandra)

[Data model](#Data-model)

[Table](#Table)

[Schema](#Schema)

[Primary key](#Primary-key)

[Partition key component](#Partition-key-component)

[Clustering columns component](#Clustering-columns-component)

[Distributing the partitions of the table over the available nodes](#Distributing-the-partitions-of-the-table-over-the-available-nodes)

[Replicating partitions across the nodes](#Replicating-partitions-across-the-nodes)

[Storage engines for nodes](#Storage-engines-for-nodes)

---


# Cassandra's Cluster Internode Communication

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Cassandra's Cluster Internode Communication

# Cassandra's Cluster Internode Communication

Let's explore how the nodes in a cassandra cluster communicate with each other.

We'll cover the following...

* [Gossip protocol](#Gossip-protocol)
* [Bootstrapping](#Bootstrapping)
* [Handling requests](#Handling-requests)
  + [Conflict occurrence](#Conflict-occurrence)
  + [Conflict resolution scheme](#Conflict-resolution-scheme)
  + [Selecting a coordinator node](#Selecting-a-coordinator-node)

## Gossip protocol[#](#Gossip-protocol)

The nodes of the cluster communicate with each other periodically via a **gossip protocol**. This allows the nodes to exchange state and topology information about themselves and other nodes they know about within the cluster. New information is gradually spread throughout the cluster via this process. In this way, nodes are able to keep track of which nodes are responsible for which token ranges, so that they can route requests accordingly.

Nodes can also determine which nodes are healthy (reachable) and which are not. The system will not send requests to nodes that are unreachable.

An operator can use administrator tools to instruct a node of the cluster to remove another node that has crashed permanently from the ring. Any partitions belonging to that node will be replicated to a different node from the remaining replicas.

## Bootstrapping[#](#Bootstrapping)

The bootstrapping process will allow the first nodes to join the cluster. For this reason, a set of nodes are designated as **seed nodes** and they can be specified to all the nodes of the cluster via a configuration file or a third-party system during startup.

## Handling requests[#](#Handling-requests)

Cassandra has no notion of a leader or primary node. All replica nodes are considered equivalent. Every incoming request can be routed to any node in the cluster. This node is called the **coordinator node** and is responsible for managing the execution of the request on behalf of the client. This node identifies the nodes that contain the data for the requested partition and dispatches the requests. After successfully collecting the responses, it replies to the client.

### Conflict occurrence[#](#Conflict-occurrence)

As there is no leader and all replica nodes are equivalent, they can handle writes concurrently. As a result, there is a need for a conflict resolution scheme.

### Conflict resolution scheme[#](#Conflict-resolution-scheme)

Cassandra uses a **last-write-wins (LWW) scheme**. Every row that is written comes with a timestamp. When a read is performed, the coordinator collects all the responses from the replica nodes and returns the one with the latest timestamp.

### Selecting a coordinator node[#](#Selecting-a-coordinator-node)

The client can specify policies for the selection of the coordinator node. This policy might select coordinator nodes randomly in a round-robin fashion, select the closest node or select one of the replica nodes to reduce subsequent network hops.

Similar to the concept of seed nodes, the client driver is provided with some configuration that contains a list of contact points, which are nodes of the cluster. The client will initially try to connect to one of these nodes to acquire a view of the whole cluster and route requests everywhere.

Backlesson

Mark As CompletedComplete

Next

Cassandra's Data Model

Cassandra's Consistency Levels

Ask

[Gossip protocol](#Gossip-protocol)

[Bootstrapping](#Bootstrapping)

[Handling requests](#Handling-requests)

[Conflict occurrence](#Conflict-occurrence)

[Conflict resolution scheme](#Conflict-resolution-scheme)

[Selecting a coordinator node](#Selecting-a-coordinator-node)

---


# Cassandra's Consistency Levels

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Cassandra's Consistency Levels

# Cassandra's Consistency Levels

Let's study some available consistency levels in Cassandra and also look into the mechanisms that help Cassandra to favor high availability and performance.

We'll cover the following...

* [Consistency levels](#Consistency-levels)
  + [ALL](#ALL)
  + [QUORUM](#QUORUM)
  + [ONE](#ONE)
* [Deciding the appropriate consistency level](#Deciding-the-appropriate-consistency-level)
* [Mechanisms that help Cassandra to favor high availability and performance](#Mechanisms-that-help-Cassandra-to-favor-high-availability-and-performance)
  + [Hinted handoff](#Hinted-handoff)
  + [Read repair](#Read-repair)
  + [Anti-entropy repair](#Anti-entropy-repair)

When Cassandra nodes communicate with clients they can specify different consistency levels, which allows them to optimize for *consistency*, *availability*, or *latency* accordingly.

The client can define the desired **read consistency level** and the desired **write consistency level**, where each consistency level provides different guarantees.

## Consistency levels[#](#Consistency-levels)

Some of the available consistency levels are as follows:

### ALL[#](#ALL)

A write must be written to all replica nodes in the cluster for the associated partition.A read returns the record only after all replicas have responded, while the operation fails if a single replica does not respond.

> Note: This option provides the highest consistency and the lowest availability.

### QUORUM[#](#QUORUM)

A write must be written on a quorum of replica nodes across all datacenters.

A read returns the record after a quorum of replicas from all datacenters has replied.

> Note: This option provides a balance between strong consistency and tolerance to a small number of failures.

### ONE[#](#ONE)

A write must be written to at least one replica node.

A read returns the record after the response of a single replica node.

> Note: This option provides the highest availability but incurs a risk of reading stale data since the replica that replied might not have received the latest write.

## Deciding the appropriate consistency level[#](#Deciding-the-appropriate-consistency-level)

The two consistency levels are not independent, so one should consider the interactions between them when deciding the appropriate level.

If we assume a keyspace with replication factor NNN and clients that read with *read consistency* RRR and write with *write consistency* WWW, then a read operation is guaranteed to reflect the latest successful write as long as R+W>NR + W > NR+W>N. For instance, this could be achieved by:

* Performing both reads and writes at the QUORUM level.
* Performing reads at ONE level and writes at ALL levels, or vice versa.

In all of the above cases, at least one node from the read set will exist in the write set, thus having seen the latest write.

> Note: However, each one of them provides different levels of *availability*, *durability*, *latency*, and *consistency* for read and write operations.

## Mechanisms that help Cassandra to favor high availability and performance[#](#Mechanisms-that-help-Cassandra-to-favor-high-availability-and-performance)

As explained above, Cassandra favors high availability and performance over data consistency. As a result, it employs several mechanisms that ensure the cluster can keep processing operations even during node failures and partitions. The replicas can converge again as quickly as possible after recovery.

Some of these mechanisms are described in the following section:

### Hinted handoff[#](#Hinted-handoff)

**Hinted handoff** happens during write operations.

If the coordinator cannot contact the necessary number of replicas, the coordinator can store the result of the operation locally and forward it to the failed node after it has recovered.

### Read repair[#](#Read-repair)

**Read repair** happens during read operations.

Suppose the coordinator receives conflicting data from the contacted replicas. In that case, it resolves the conflict by selecting the latest record and forwards it synchronously to the stale replicas before responding to the read request.

### Anti-entropy repair[#](#Anti-entropy-repair)

**Anti-entropy repair** happens in the background.

Replica nodes exchange the data for a specific range, and if they find differences, they keep the latest data for each record, complying with the LWW strategy.

> Note: However, this involves big datasets, so it’s important to minimize network bandwidth consumption. For this reason, the nodes encode the data for a range in a **Merkle tree** and gradually exchange parts of the tree to discover the conflicting data that need to be exchanged.

Backlesson

Mark As CompletedComplete

Next

Cassandra's Cluster Internode Communication

Linearizability Violations in Cassandra

Ask

[Consistency levels](#Consistency-levels)

[ALL](#ALL)

[QUORUM](#QUORUM)

[ONE](#ONE)

[Deciding the appropriate consistency level](#Deciding-the-appropriate-consistency-level)

[Mechanisms that help Cassandra to favor high availability and performance](#Mechanisms-that-help-Cassandra-to-favor-high-availability-and-performance)

[Hinted handoff](#Hinted-handoff)

[Read repair](#Read-repair)

[Anti-entropy repair](#Anti-entropy-repair)

---


# Linearizability Violations in Cassandra

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Linearizability Violations in Cassandra

# Linearizability Violations in Cassandra

Let's examine two different scenarios where Cassandra violates the linearizability

We'll cover the following...

* [Without read repair](#Without-read-repair)
* [With read repair](#With-read-repair)

> It is important to note that operations on a single row are not linearizable by default, even when using majority quorums.

To understand why it is useful to learn how Cassandra handles **partial failures** and **network delays**. Let’s examine two different scenarios.

## Without read repair[#](#Without-read-repair)

In this scenario, we assume that read repair is not used. The system consists of three different replicas with a single row that contains a single column `owner` with the value `none`.

Client A initially performs a write operation to set `owner = A`. While this operation is in progress, two clients B and C perform a read operation for the owner in sequence. The majority quorum of client B contains one replica that has already received the write operation, while client C contacts a quorum with nodes that haven’t received it yet. As a result, client B reads `owner = A`, while client C reads `owner = none` even though the operation from the latter started after the operation from the former had been completed, which violates linearizability.

The following illustration shows this phenomenon:

Created with Fabric.js 3.6.6

1 / 19

A system with three Client and three Replica nodes, initially all the Replica nodes has owner value equals to none

Created with Fabric.js 3.6.6

1 / 19

Client A sends a write request to set owner equals A

Created with Fabric.js 3.6.6

1 / 19

The write request for setting owner equals A reaches the Replica 1, so it updates its owner to A

Created with Fabric.js 3.6.6

1 / 19

While the write operation is in progress, Client B sends a read request for the owner

Created with Fabric.js 3.6.6

1 / 19

he read request from client B reaches replica 3, which will also ask replica 1 before replying to the client to form a majority quorum

## With read repair[#](#With-read-repair)

The violation of linearizability in the previous example would be eliminated if read repair was used since the read from client B would propagate the value to replica 2, and client C would also read `owner = A`.

So, let’s assume that read repair is used and examine a different scenario. Client A performs a write operation again to set `owner = A`. The write succeeds in one replica and fails in the other replica. As a result, the write is considered unsuccessful, and the coordinator returns a failure response back to the client. Afterward, client B performs a read operation that uses a quorum that contains the replica where the previous write succeeded.

Cassandra performs a read repair using the LWW strategy, thus propagating the value to replica 2. Consequently, a write operation that failed has affected the state of the database, thus violating linearizability. This example is shown in the following illustration:

Created with Fabric.js 3.6.6

1 / 24

A system with three Client and three Replica nodes, initially all the Replica nodes has owner value equals to none

Created with Fabric.js 3.6.6

1 / 24

Client A sends a write request to set owner equals A

Created with Fabric.js 3.6.6

1 / 24

While the write operation is in progress, Client B sends a read request for the owner

Created with Fabric.js 3.6.6

1 / 24

The write request for setting owner equals A reaches the Replica 1, so it updates its owner to A

Created with Fabric.js 3.6.6

1 / 24

The read request from client B reaches replica 3, which will also ask replica 1 before replying to client to form a majority quorum

Backlesson

Mark As CompletedComplete

Next

Cassandra's Consistency Levels

Linearizability Guarantees by Cassandra

Ask

[Without read repair](#Without-read-repair)

[With read repair](#With-read-repair)

---


# Linearizability Guarantees by Cassandra

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Linearizability Guarantees by Cassandra

# Linearizability Guarantees by Cassandra

Learn how Cassandra provides linearizability guarantee.

We'll cover the following...

* [Implementing SERIAL](#Implementing-SERIAL)
  + [Phase one](#Phase-one)
  + [Phase two](#Phase-two)
  + [Phase three](#Phase-three)
  + [Phase four](#Phase-four)

Cassandra has another consistency level that provides linearizability guarantees. This level is called **SERIAL**, and the read/write operations executed in this level are also referred to as **lightweight transactions LWTs**.

## Implementing SERIAL[#](#Implementing-SERIAL)

This level is implemented using a 4-phase protocol based on Paxos, as shown in the following illustration:

Created with Fabric.js 3.6.6

1 / 4

In the first phase, the leader gathers votes by sending prepare message to all replica nodes, the replica node reply with a promise message in case it accepts prepare request

Created with Fabric.js 3.6.6

1 / 4

In the second phase Leader reads data from Replica nodes to check whether the condition is satisfied before proceeding with the proposal

Created with Fabric.js 3.6.6

1 / 4

In the third phase, Leader propose a value, the Replica nodes that agree at the proposed value reply with an accept message

Created with Fabric.js 3.6.6

1 / 4

In the last phase, Leader sends a commit message to all Replica nodes in order to write value to the storage, Replica nodes reply with ack message

### Phase one[#](#Phase-one)

The first phase of the protocol is called **prepare** and corresponds to the nodes trying to gather votes before proposing a value which is done in the third phase, called **propose**.

When run under the SERIAL level, the write operations are conditional using an IF clause, also known as **compare-and-set (CAS)**.

### Phase two[#](#Phase-two)

The second phase of the protocol is called **read** and is used to retrieve the data to check whether the condition is satisfied before proceeding with the proposal.

### Phase three[#](#Phase-three)

The phase three of the protocol is the same as phase one. It satisfies the same need as phase one. It proposes a value to the nodes.

### Phase four[#](#Phase-four)

The last phase of the protocol is called **commit**, and it’s used to move the accepted value into Cassandra storage and allow a new consensus round, thus unblocking concurrent LWTs again.

> Note: Read and write operations executed under SERIAL are guaranteed to be linearizable.

* Read operations will commit any accepted proposal that has not been committed yet as part of the read operation.
* Write operations under SERIAL are required to contain a conditional part.

Backlesson

Mark As CompletedComplete

Next

Linearizability Violations in Cassandra

Cassandra Performing Queries Efficiently

Ask

[Implementing SERIAL](#Implementing-SERIAL)

[Phase one](#Phase-one)

[Phase two](#Phase-two)

[Phase three](#Phase-three)

[Phase four](#Phase-four)

---


# Cassandra Performing Queries Efficiently

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Cassandra Performing Queries Efficiently

# Cassandra Performing Queries Efficiently

Look into how Cassandra tries to perform queries efficiently.

We'll cover the following...

* [Methods to perform queries efficiently](#Methods-to-perform-queries-efficiently)
  + [Secondary indexes](#Secondary-indexes)
  + [Materialized views](#Materialized-views)
* [Trade-offs with secondary indexes and materialized views](#Trade-offs-with-secondary-indexes-and-materialized-views)
* [Denormalizing data for efficiency](#Denormalizing-data-for-efficiency)
  + [Updating multiple tables](#Updating-multiple-tables)
    - [Logged and unlogged batches](#Logged-and-unlogged-batches)

In Cassandra, performing a query that does not use the primary key is guaranteed to be inefficient because it will need to perform a full table scan querying all the cluster nodes.

## Methods to perform queries efficiently[#](#Methods-to-perform-queries-efficiently)

Two alternatives can be used to solve the above problem:

* **Secondary indexes**
* **Materialized views**.

### Secondary indexes[#](#Secondary-indexes)

A secondary index can be defined on some columns of a table. This means each node will index this table locally using the specified columns. A query based on these columns will still need to ask all the system nodes, but at least each node will have a more efficient way to retrieve the necessary data without scanning all the data.

### Materialized views[#](#Materialized-views)

A materialized view can be defined as a query on an existing table with a newly defined partition key. This materialized view is maintained as a separate table, and any changes on the original table are eventually propagated to it. As a result, these two approaches are subject to the following trade-off.

## Trade-offs with secondary indexes and materialized views[#](#Trade-offs-with-secondary-indexes-and-materialized-views)

* *Secondary indexes* are more suitable for high cardinality columns, while *materialized views* are suitable for low cardinality columns as they are stored as regular tables.
* *Materialized views* are more efficient during read operations than *secondary indexes* because only the nodes that contain the corresponding partition are queried.
* *Secondary indexes* are guaranteed to be strongly consistent, while *materialized views* are eventually consistent.

## Denormalizing data for efficiency[#](#Denormalizing-data-for-efficiency)

Cassandra does not provide join operations since they would be inefficient due to the distribution of data. As a result, users are encouraged to denormalize the data by potentially including the same data in multiple tables to be queried efficiently, reading only from a minimum number of nodes. This means that any update operations on this data will need to update multiple tables, but this is expected to be quite efficient.

### Updating multiple tables[#](#Updating-multiple-tables)

Cassandra provides two flavors of batch operations that can update multiple partitions and tables: **logged** and **unlogged** batches.

#### Logged and unlogged batches[#](#Logged-and-unlogged-batches)

Logged batches provide the additional guarantee of *atomicity*, either all of the statements of the batch operation will take effect or none of them. This can help ensure that all the tables that share this denormalized data will be consistent with each other. However, this is achieved by first logging the batch as a unit in a system table which is replicated and then performing the operations, making them less efficient than *unlogged batches*.

> Note: Both logged and unlogged batches do not provide any **isolation**, so concurrent requests might only temporarily observe the effects of some of the operations.

Backlesson

Mark As CompletedComplete

Next

Linearizability Guarantees by Cassandra

Spanner's Data Model

Ask

[Methods to perform queries efficiently](#Methods-to-perform-queries-efficiently)

[Secondary indexes](#Secondary-indexes)

[Materialized views](#Materialized-views)

[Trade-offs with secondary indexes and materialized views](#Trade-offs-with-secondary-indexes-and-materialized-views)

[Denormalizing data for efficiency](#Denormalizing-data-for-efficiency)

[Updating multiple tables](#Updating-multiple-tables)

[Logged and unlogged batches](#Logged-and-unlogged-batches)

---


# Spanner's Data Model

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Spanner's Data Model

# Spanner's Data Model

Let's study the data model of Spanner.

We'll cover the following...

* [Data partitioning](#Data-partitioning)
  + [Split](#Split)
  + [Dynamic load-based splitting](#Dynamic-load-based-splitting)
  + [Parent-child relationship](#Parent-child-relationship)

[Spanner](https://cloud.google.com/spanner) is a distributed data store initially developed internally by J. C. Corbett et al. and D. F. Bacon et al. at Google and was subsequently released publicly as part of the Google platform.

The data model of Spanner is very close to the data model of classical relational databases.

A database in Spanner can contain one or more tables, which can contain multiple rows. Each row contains a value for each column that is defined, and one or more columns are defined as the primary key of the table, which must be unique for each row. Each table contains a schema that defines the data types of each column.

## Data partitioning[#](#Data-partitioning)

Spanner partitions the data of a table using **horizontal range partitioning**.

The rows of a table are partitioned in multiple segments, called **splits**.

### Split[#](#Split)

A **split** is a range of contiguous rows, where the rows are ordered by the corresponding primary key.

### Dynamic load-based splitting[#](#Dynamic-load-based-splitting)

Spanner can perform **dynamic load-based splitting**, so any split that receives an extreme amount of traffic can be partitioned further and stored in servers with less traffic.

### Parent-child relationship[#](#Parent-child-relationship)

The user can define parent-child relationships between tables so that related rows from the tables are collocated, making join operations much more efficient.

For example, a table “C” can be declared as a child table of “A”, using the `INTERLEAVE` keyword. We must also ensure that the primary key of the parent table is a prefix of the primary key of the child table.

An example in the following illustration shows a parent table **Singers** interleaved with a child table, called **Albums**.

> Note: Spanner guarantees that the row of a parent table and the associated rows of the child table will never be assigned to a different *split*.

Definition of interleaved tables and data layout

Backlesson

Mark As CompletedComplete

Next

Cassandra Performing Queries Efficiently

Spanner's Architecture

Ask

[Data partitioning](#Data-partitioning)

[Split](#Split)

[Dynamic load-based splitting](#Dynamic-load-based-splitting)

[Parent-child relationship](#Parent-child-relationship)

---


# Spanner's Architecture

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Spanner's Architecture

# Spanner's Architecture

Let's look into the architecture of Spanner in detail.

We'll cover the following...

* [Components of Spanner](#Components-of-Spanner)
  + [Universe](#Universe)
  + [Zone manager](#Zone-manager)
  + [Spanservers](#Spanservers)
  + [Location proxies](#Location-proxies)
  + [Universe manager](#Universe-manager)
  + [Placement driver](#Placement-driver)
* [Explanation](#Explanation)
  + [Leader and followers](#Leader-and-followers)
* [Benefits of Spanner](#Benefits-of-Spanner)
  + [Distributed transaction support](#Distributed-transaction-support)

## Components of Spanner[#](#Components-of-Spanner)

A Spanner deployment is called a **universe**.

### Universe[#](#Universe)

**Universe** consists of a set of **zones**, which are the units of administrative deployment, physical isolation, and replication (e.g. datacenters).

Each zone has a **zone manager** and hundreds to several thousand **spanservers**.

### Zone manager[#](#Zone-manager)

The **zone manager** assigns data to spanservers.

### Spanservers[#](#Spanservers)

**Spanservers** read/write requests from clients and store data.

### Location proxies[#](#Location-proxies)

The per-zone **location proxies** are used by clients to locate the spanservers that serve a specific portion of data.

### Universe manager[#](#Universe-manager)

The **universe manager** displays status information about all the zones for troubleshooting.

### Placement driver[#](#Placement-driver)

The placement driver handles the automated movement of data across zones, e.g., for load balancing reasons.

> **Note:** In the original research paper describing Spanner, the authors use “zone master” and “universe master.” We will use the terms “zone manager” and “universe manager” to refer to the same things.

The following illustration shows the architecture of a Spanner:

![](images/image_1764834458.620373.svg)![A spanner’s universe consists of multiple zones for durability](images/6585868358385664.svg "A spanner’s universe consists of multiple zones for durability")

A spanner’s universe consists of multiple zones for durability

## Explanation[#](#Explanation)

Each spanserver can manage multiple splits, and each split is replicated across multiple zones for availability, durability, and performance.

> Note: Each split is stored in a distributed file system, called **Colossus**, the successor of GFS, which already provides byte-level replication. However, Spanner adds another replication level to provide the additional benefits of data availability and geographic locality.

All the replicas of a split form a **Paxos group** as shown in the above illustration.

### Leader and followers[#](#Leader-and-followers)

One of the replicas is voted as the **leader** and is responsible for receiving incoming write requests and replicating them to the replicas of the group via a Paxos round.

The rest of the replicas are **followers** and can serve some kinds of read requests. This is shown in the following illustration:

Spanner provides additional replication on top of Colossus

## Benefits of Spanner[#](#Benefits-of-Spanner)

Spanner provides the following benefits by using:

* **long-lived leaders** with **time-based leader leases**, which are renewed by default every 10 seconds
* **pessimistic concurrency control** to ensure proper **isolation** between concurrent transactions, specifically two-phase locking.

The leader of each replica group maintains a lock table that maps ranges of keys to lock states for this purpose.

> Note that in practice, these locks are also replicated in the replicas of the group to cover against the failures of the leader.

### Distributed transaction support[#](#Distributed-transaction-support)

Spanner also provides support for **distributed transactions** that involve multiple splits that potentially belong to different replica groups.

This is achieved via a **two-phase commit** across the involved replica groups. As a result, each group leader also implements a transaction manager to take part in the two-phase commit. The leaders of each group are called **participant leaders**, and the follower replicas of each one of those groups are referred to as **participant followers**. More specifically, one of these groups is chosen as the coordinator for the two-phase commit protocol. The replicas of this group are referred to as coordinator leader and followers, respectively.

Backlesson

Mark As CompletedComplete

Next

Spanner's Data Model

Spanner using TrueTime

Ask

[Components of Spanner](#Components-of-Spanner)

[Universe](#Universe)

[Zone manager](#Zone-manager)

[Spanservers](#Spanservers)

[Location proxies](#Location-proxies)

[Universe manager](#Universe-manager)

[Placement driver](#Placement-driver)

[Explanation](#Explanation)

[Leader and followers](#Leader-and-followers)

[Benefits of Spanner](#Benefits-of-Spanner)

[Distributed transaction support](#Distributed-transaction-support)

---


# Spanner using TrueTime

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Spanner using TrueTime

# Spanner using TrueTime

Let's examine how Spanner provides the consistency guarantees.

We'll cover the following...

* [TrueTime API](#TrueTime-API)
  + [Implementation of TrueTime](#Implementation-of-TrueTime)
    - [Time manager machines](#Time-manager-machines)
    - [Time follower daemon](#Time-follower-daemon)

Spanner makes use of a novel API to record time, called TrueTime, which is the key enabler for most of the consistency guarantees provided by Spanner.

## TrueTime API[#](#TrueTime-API)

TrueTime API directly exposes clock uncertainty, and nodes can wait out that uncertainty when comparing timestamps retrieved from different clocks. If the uncertainty gets large because of some failure, this will manifest as increased latency due to nodes having to wait long periods.

TrueTime represents time as a ***TTInterval***, which is an interval [earliest,latest][earliest, latest][earliest,latest] with bounded time uncertainty. TrueTime API provides a method `TT.now()` that returns a TTInterval that is guaranteed to contain the absolute time during which the method was invoked.

> Note: As previously explained in the chapter about **time**, this is an assumption that there’s an idealized absolute time that uses the Earth as a single frame of reference and is generated using [multiple atomic clocks](https://en.wikipedia.org/wiki/International_Atomic_Time).

TrueTime also provides two convenience methods `TT.after(t)`, `TT.before(t)` that specify whether `t` is definitely in the past or in the future. These are essentially just wrappers around `TT.now()`, since `TT.after(t)` === `t` <<< `TT.now().earliest` and `TT.before(t)` === `t` >>> `TT.now().latest`. As a result, Spanner can assign timestamps to transactions that have global meaning and can be compared by nodes having different clocks.

### Implementation of TrueTime[#](#Implementation-of-TrueTime)

TrueTime is implemented by a set of **time manager machines** per datacenter and a **time follower daemon** per machine.

> **Note:** In the original research paper describing Spanner, the authors use “time master machine” and “timeslave machine.” We will use the terms “time manager machine” and “time follower daemon” to refer to the same things.

#### Time manager machines[#](#Time-manager-machines)

The managers can use one of two different forms of time reference, either GPS or atomic clocks, since they have different failure modes. The manager servers compare their time references periodically. They also cross-check the rate at which their reference time advances against their local clock, evicting themselves from the cluster if there is a significant divergence.

#### Time follower daemon[#](#Time-follower-daemon)

Daemons poll a variety of managers to synchronize their local clocks and advertise an uncertainty eee which corresponds to half of the interval’s width (latest−earliest)/2(latest - earliest) / 2(latest−earliest)/2.

This uncertainty depends on manager-daemon communication latency and the uncertainty of the managers’ time. This uncertainty is a sawtooth function of time that is slowly increasing between synchronization.

> In Google’s production environment, the average value of this uncertainty was reported to be just four milliseconds.

Backlesson

Mark As CompletedComplete

Next

Spanner's Architecture

Spanner Operations

Ask

[TrueTime API](#TrueTime-API)

[Implementation of TrueTime](#Implementation-of-TrueTime)

[Time manager machines](#Time-manager-machines)

[Time follower daemon](#Time-follower-daemon)

---


# Spanner Operations

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Spanner Operations

# Spanner Operations

Let's study the operations supported by the Spanner.

We'll cover the following...

* [Read-write transaction](#Read-write-transaction)
  + [Workflow](#Workflow)
  + [Spanner mitigating availability problems](#Spanner-mitigating-availability-problems)
  + [Spanner handling deadlocks](#Spanner-handling-deadlocks)
  + [Checking whether a replica is up-to-date or not](#Checking-whether-a-replica-is-up-to-date-or-not)
    - [Safe time (tsafe​)](#Safe-time-tsafe)
* [Read-only transactions](#Read-only-transactions)
  + [An interesting property](#An-interesting-property)
* [Standalone reads](#Standalone-reads)
  + [Strong read](#Strong-read)
  + [Stale read](#Stale-read)
* [Partitioned Data Manipulation Language](#Partitioned-Data-Manipulation-Language)
  + [Atomicity guarantee](#Atomicity-guarantee)

Spanner supports the following types of operations:

* Read-write transactions
* Read-only transactions
* Standalone (strong or stale) reads

## Read-write transaction[#](#Read-write-transaction)

A **read-write transaction** can contain both read and/or write operations. It provides full ACID properties for the operations of the transaction. More specifically, read-write transactions are not simply serializable, but they are **strictly serializable**.

> **Note**: Spanner documentation also refers to strict serializability with “external consistency”, but both are essentially the same guarantees.

A read-write transaction executes a set of reads and write operations atomically at a single logical point in time.

> Note: As explained earlier, Spanner achieves these properties using two-phase locking for *isolation* and two-phase commit for *atomicity* across multiple splits.

### Workflow[#](#Workflow)

The workflow for the read-write transaction follows the following sequence:

* After opening a transaction, a client directs all the read operations to the leader of the replica group that manages the split with the required rows. This leader acquires read locks for the rows and columns involved before serving the read request. Every read also returns the timestamp of any data read.
* Any write operations are buffered locally in the client until the point the transaction is committed. While the transaction is open, the client sends **keepalive** messages to prevent participant leaders from timing out a transaction.
* When a client has completed all reads and buffered all writes, it starts the two-phase commit protocol. It chooses one of the participant leaders as the coordinator leader and sends a `prepare` request to all the participant leaders along with the identity of the coordinator leader. The participant leaders involved in write operations also receive the buffered writes at this stage.
* Every participant leader acquires the necessary write locks, chooses a `prepare` timestamp s​i that is larger than any timestamps of previous transactions, and logs a `prepare` record in its replica group through Paxos. The leader also replicates the lock acquisition to the replicas to ensure they will be held even in the case of a leader failure. It then responds to the coordinator leader with the `prepare` timestamp.

The following illustration contains a visualization of this sequence:

Created with Fabric.js 3.6.6

1 / 12

A system in which there is one client and two replica groups, each replica group with one leader and two follower nodes

Created with Fabric.js 3.6.6

1 / 12

Client opens the transaction. Since the leader of replica group 1 (coordinator) manages the split with the required rows, so the client queries that leader for the data (read operation).

Created with Fabric.js 3.6.6

1 / 12

The leader acquires read locks for the rows and columns involved and then returns the result to the client

Created with Fabric.js 3.6.6

1 / 12

The client performs the write operations locally until the transaction is committed. It completes all reads and buffer all writes before starting two-phase commit protocol.

Created with Fabric.js 3.6.6

1 / 12

The two-phase commit protocol starts, the client sends a prepare request to all the participant leaders along with the identity of the coordinator leader, participant leaders also receive the buffered writes at this stage.

### Spanner mitigating availability problems[#](#Spanner-mitigating-availability-problems)

It is worth noting that the availability problems from the two-phase commit are partially mitigated in this scheme because both the participants and the coordinator are essentially a Paxos group. So, if one of the leader nodes crashes, then another replica from that replica group will eventually detect that, take over and help the protocol make progress.

### Spanner handling deadlocks[#](#Spanner-handling-deadlocks)

The two-phase locking protocol can result in **deadlocks**. Spanner resolves these situations via a wound-wait scheme, where a transaction TX1TX\_1TX1​ is allowed to abort a transaction TX2TX\_2TX2​ that holds the desired lock only if TX1TX\_1TX1​ is older than TX2TX\_2TX2​.

### Checking whether a replica is up-to-date or not[#](#Checking-whether-a-replica-is-up-to-date-or-not)

Spanner needs a way to know if a replica is up-to-date to satisfy a read operation. For this reason, each replica tracks a value called safe time (tsafet\_{safe}tsafe​).

#### Safe time (tsafet\_{safe}tsafe​)[#](#Safe-time-tsafetsafetsafe)

The tsafet\_{safe}tsafe​ is the maximum timestamp at which the replica is up-to-date. Thus, a replica can satisfy a read at a timestamp ttt if t≤tsafet \leq t\_{safe}t≤tsafe​.

This value is calculated as:

tsafe=min(tsafePaxos,tsafeTM)t\_{safe} = min({t\_{safe}}^{Paxos}, {t\_{safe}}^{TM})tsafe​=min(tsafe​Paxos,tsafe​TM)

tsafePaxos{t\_{safe}}^{Paxos}tsafe​Paxos is the timestamp of the highest-applied Paxos write at a replica group and represents the highest watermark below, which writes will no longer occur with respect to Paxos.

tsafeTM{t\_{safe}}^{TM}tsafe​TM is calculated as mini(si,gprepare)min\_i(s\_{i,g}^{prepare})mini​(si,gprepare​) overall transactions TiT\_iTi​ prepared (but not committed yet) at replica group ggg. If there are no such transactions, then tsafeTM=+∞{t\_{safe}}^{TM} = + \inftytsafe​TM=+∞.

## Read-only transactions[#](#Read-only-transactions)

**Read-only transactions** allow a client to perform multiple reads at the same timestamp, and these operations are also guaranteed to be **strictly serializable**.

### An interesting property[#](#An-interesting-property)

An interesting property of read-only transactions is that they do not need to hold any locks and block other transactions. The reason for this is that these transactions perform reads at a specific timestamp, which is selected in such a way as to guarantee that any concurrent/future write operations will update data at a later timestamp.

The timestamp is selected at the beginning of the transaction as `TT.now().latest`, and it’s used for all the read operations that are executed as part of this transaction.

In general, the read operations at timestamp treadt\_{read}tread​ can be served by any replica ggg that is up to date, which means tread≤tsafe,gt\_{read} \leq t\_{safe,g}tread​≤tsafe,g​.

More specifically:

* In some cases, a replica can be certain via its internal state and TrueTime that it is up to date enough to serve the read and does so.
* In some other cases, a replica might not be sure if it has seen the latest data. It can then ask the leader of its group for the timestamp of the last transaction it needs to apply in order to serve the read.
* In case the replica is the leader itself, it can proceed directly since it is always up to date.

## Standalone reads[#](#Standalone-reads)

Spanner also supports **standalone reads** outside the context of transactions.

Standalone reads do not differ a lot from the read operations performed as part of read-only transactions. For instance, their execution follows the same logic using a specific timestamp.

Standalone reads can be either **strong** or **stale**.

### Strong read[#](#Strong-read)

A **strong read** is a read at a current timestamp and is guaranteed to see all the data committed up until the start of the read.

### Stale read[#](#Stale-read)

A **stale read** is a read at a timestamp in the past. It can be provided by the application or calculated by Spanner based on a specified upper bound on staleness. A stale read is expected to have lower latency at the cost of stale data since it’s less likely the replica will need to wait before serving the request.

## Partitioned Data Manipulation Language[#](#Partitioned-Data-Manipulation-Language)

There is also another type of operation called partitioned **Data Manipulation Language (DML)**.

DMLallows a client to specify an update or delete operation in a declarative form, then executes in parallel at each replica group. This parallelism and the associated data locality make these operations very efficient. However, this comes with some tradeoffs.

* These operations need to be fully partitionable. This means they must be expressible as the union of a set of statements, where each statement accesses a single row of the table, and each statement accesses no other tables. Doing so ensures each replica group will execute the operation locally without any coordination with other replica groups.
* Furthermore, these operations must be idempotent because Spanner might execute a statement multiple times against some groups due to network-level retries.

### Atomicity guarantee[#](#Atomicity-guarantee)

Spanner does not provide atomicity guarantees for each statement across the entire table, but it provides atomicity guarantees per each group. It means that a statement might only run against some rows of the table, e.g., if the user cancels the operation midway or the execution fails in some splits due to constraint violations.

Backlesson

Mark As CompletedComplete

Next

Spanner using TrueTime

FaunaDB

Ask

[Read-write transaction](#Read-write-transaction)

[Workflow](#Workflow)

[Spanner mitigating availability problems](#Spanner-mitigating-availability-problems)

[Spanner handling deadlocks](#Spanner-handling-deadlocks)

[Checking whether a replica is up-to-date or not](#Checking-whether-a-replica-is-up-to-date-or-not)

[Safe time (tsafe​)](#Safe-time-tsafe)

[Read-only transactions](#Read-only-transactions)

[An interesting property](#An-interesting-property)

[Standalone reads](#Standalone-reads)

[Strong read](#Strong-read)

[Stale read](#Stale-read)

[Partitioned Data Manipulation Language](#Partitioned-Data-Manipulation-Language)

[Atomicity guarantee](#Atomicity-guarantee)

---


# FaunaDB

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

FaunaDB

# FaunaDB

Lets study the architecture of FaunaDB and the guarantees provided by it.

We'll cover the following...

* [Calvin protocol](#Calvin-protocol)
* [Abstract architecture of FaunaDB’s architecture](#Abstract-architecture-of-FaunaDBs-architecture)
* [Roles performed by FaunaDB’s nodes](#Roles-performed-by-FaunaDBs-nodes)
  + [Query coordinator](#Query-coordinator)
  + [Data replica](#Data-replica)
  + [Log replica](#Log-replica)
* [Conceptual architecture of FaunaDB](#Conceptual-architecture-of-FaunaDB)
  + [A read-write transaction request](#A-read-write-transaction-request)
  + [A read-only transaction request](#A-read-only-transaction-request)
* [Guarantees provided by FaunaDB](#Guarantees-provided-by-FaunaDB)
  + [Achieving guarantees](#Achieving-guarantees)
* [Interactive transactions](#Interactive-transactions)

[FaunaDB](https://fauna.com) is a distributed datastore inspired by the Calvin protocol for its core architecture.

## Calvin protocol[#](#Calvin-protocol)

Calvin is based on the following central idea:

By replicating inputs instead of effects to the various nodes of the system, it’s possible to have a more deterministic system where all the non-failing nodes go through the same states.

This determinism of the Calvin protocol can obviate the need for agreement protocols, such as two-phase commit, when performing distributed transactions since the nodes involved in the transaction can rely on each other, proceeding in the same way.

## Abstract architecture of FaunaDB’s architecture[#](#Abstract-architecture-of-FaunaDBs-architecture)

The abstract architecture of FaunaDB is composed of three layers.

Architecture of FaunaDB

**The sequencing layer**

The **sequencing layer** receives inputs or commands and places them in a global order, which is achieved via a consensus protocol.

This is the sequence all the nodes will execute the operations.

**The scheduling layer**

The **scheduling layer** orchestrates the execution of transactions using a deterministic locking scheme to guarantee equivalence to the serial order specified by the sequencing layer . It also allows transactions to be executed concurrently.

**The storage layer**

The **storage layer** is responsible for the physical data layout.

## Roles performed by FaunaDB’s nodes[#](#Roles-performed-by-FaunaDBs-nodes)

Every node in FaunaDB performs three roles simultaneously:

### Query coordinator[#](#Query-coordinator)

Query coordinator receives and processes a request.

> Note: The request might be processed locally or routed to other nodes, depending on its type.

### Data replica[#](#Data-replica)

The **data replica** stores data and serves them during read operations.

### Log replica[#](#Log-replica)

The **Log replica** reaches consensus on the order of inputs and adds them to the globally ordered log.

## Conceptual architecture of FaunaDB[#](#Conceptual-architecture-of-FaunaDB)

A **cluster** comprises three or more logical **datacenters** and data is partitioned inside a *datacenter* and replicated across *datacenters* for increased *performance* and *availability*.

> Note: Similar to Spanner, multiple versions of each data item are preserved in FaunaDB.

FaunaDB uses a slightly customized version of Raft for consensus. FaunaDB’s version aggregates requests and replicates them in batches to improve throughput. These batches are called **epochs** and a typical window of batching is 10 milliseconds so that the impact on latency is not significant. The ordering of requests is achieved by combining the epoch number and the request index in the batch.

The following illustration contains a conceptual view of the architecture. Each role is visualized separately to facilitate an understanding of how the various functions interoperate. However, a single node can perform all these roles, as explained previously.

Conceptual view of FaunaDB’s architecture

When a request arrives to a **query coordinator**, it speculatively executes the transaction at the latest known log timestamp to discover the data accessed by the transaction, also referred to as **read and write intents**.

The processing thereafter differs depending on the type of request.

### A read-write transaction request[#](#A-read-write-transaction-request)

If the request is a **read-write transaction**, it is forwarded to a **log replica** that makes sure it’s recorded as part of the next batch, as agreed via consensus with the other replicas.

The request is then forwarded to each **data replica** that contains associated data.

**Difference with other systems**

An interesting difference with other systems is that in FaunaDB, data transfer at this stage is *push-based*, not *pull-based*.

For example, if replica A needs to perform a write based on data owned by replica B during a transaction, replica B is supposed to send the data to replica A instead of replica A requesting them. A significant advantage of this is fewer messages that lead to reduced latency. A valid question is what happens if the node that is supposed to send the data fails. In this case, the data replica can fall back to requesting the data from other replicas of this partition.

As a result, each data replica blocks until it has received all the data needed from other replicas. Then, it resolves the transaction, applies any local writes and acknowledges the success to the query coordinator.

> Note: Data might have changed since the speculative execution of the query coordinator. If that’s the case, the transaction will be aborted and can potentially be retried, but this will be a unanimous decision since all the nodes will execute the operations in the same order. Consequently, there is no need for an agreement protocol, such as a two-phase commit.

### A read-only transaction request[#](#A-read-only-transaction-request)

If the request is a **read-only transaction**, it is sent to the replica(s) that contain the associated data or served locally if the query coordinator contains all the data.

The transaction is time-stamped with the latest known log timestamp, and all read operations are performed at this timestamp.

The client library also maintains the timestamp of the highest log position seen so far, which is used to guarantee a monotonically advancing view of the transaction order. This guarantees **causal consistency** in cases where the client switches from node A to node B, where node B lags behind node A in transaction execution from the log.

## Guarantees provided by FaunaDB[#](#Guarantees-provided-by-FaunaDB)

In terms of guarantees,

* *Read-write transactions* are **strictly serializable**
* *Read-only transactions* are just **serializable**

However, *read-only transactions* can opt-in to be *strictly serializable* by using the so-called **linearized endpoint**. In that case, the read is combined with a no-op write, and it’s executed as a regular read-write transaction going through consensus. This increases *latency*.

### Achieving guarantees[#](#Achieving-guarantees)

To achieve the above guarantees, read-write transactions make use of a **pessimistic concurrency control scheme** based on read/write locks. This protocol is deterministic, which means it guarantees that all nodes will acquire and release locks in the exact same order.

> Note: An interesting benefit of this protocol is that **deadlocks** are prevented. There is literature that examines the benefits of determinism in database systems in more detail.

The order is defined by order of the transactions in the log.

> Note: This does not prevent transactions from running concurrently. It just requires that locks for the transaction, tit\_iti​ can be acquired only after locks have been acquired (and potentially released) for all previous transactions tj(j<i)t\_j (j < i)tj​(j<i).

This means that FaunaDB must know all the data accessed by read/write transactions in advance, which means FaunaDB cannot support **interactive transactions**. As described previously, this is not strictly required since the query coordinator performs an initial reconnaissance query and includes the results in the submitted transactions. So, all the replicas can perform the reads again during the execution of the transaction and identify whether read/write sets have changed, where the transaction can be aborted and retried. This technique is called **Optimistic Lock Location Prediction (OLLP)**.

## Interactive transactions[#](#Interactive-transactions)

Interactive transactions are ones that a client can keep open and execute operations dynamically while potentially performing other operations not related to the database.

In contrast to interactive transactions, transactions in FaunaDB are declared at once and sent for processing.

FaunaDB can still simulate interactive transactions via a combination of **snapshot reads** and **compare-and-swap** operations.

Now that you’ve covered essential distributed data store concepts, test your knowledge by interacting with the AI widget below to answer six different questions focused on different distributed data stores. To get started, say hello to Edward in the widget below, and it will lead the way.

Want to know the correct answer?

Powered by AI

18 Prompts Remaining

Prompt AI WidgetOur tool is designed to help you to understand concepts and ask any follow up questions. Ask a question to get started.

Backlesson

Mark As CompletedComplete

Next

Spanner Operations

Quiz on Distributed Data Stores

Ask

[Calvin protocol](#Calvin-protocol)

[Abstract architecture of FaunaDB’s architecture](#Abstract-architecture-of-FaunaDBs-architecture)

[Roles performed by FaunaDB’s nodes](#Roles-performed-by-FaunaDBs-nodes)

[Query coordinator](#Query-coordinator)

[Data replica](#Data-replica)

[Log replica](#Log-replica)

[Conceptual architecture of FaunaDB](#Conceptual-architecture-of-FaunaDB)

[A read-write transaction request](#A-read-write-transaction-request)

[A read-only transaction request](#A-read-only-transaction-request)

[Guarantees provided by FaunaDB](#Guarantees-provided-by-FaunaDB)

[Achieving guarantees](#Achieving-guarantees)

[Interactive transactions](#Interactive-transactions)

---


# Quiz on Distributed Data Stores

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed Data Stores

# Quiz on Distributed Data Stores

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

Suppose you want to build an application to keep track of user accounts using Cassandra. Which of the following attributes would be the best fit for a primary key?

A.

The username

B.

The Address

C.

The Contact number

---

1 / 4

Submit Answer

Backlesson

Mark As CompletedComplete

Next

FaunaDB

Introduction to Kafka

Ask

---


# Kafka Levers

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Kafka Levers

# Kafka Levers

Learn how to tune the levers provided by Kafka.

We'll cover the following...

* [Tuning levers](#Tuning-levers)
  + [Trade-offs](#Trade-offs)

Kafka provides many levers to adjust the way it operates depending on the application’s needs.

## Tuning levers[#](#Tuning-levers)

The levers should be tuned carefully depending on requirements around availability, durability, and performance. For example, the user can control:

* The **replication factor** of a topic
* The **minimum size** of the ISR set (`min.insync.replicas`)
* The **number of replicas** from the ISR set that needs to acknowledge a record before it’s committed (acks)

### Trade-offs[#](#Trade-offs)

Let’s discuss some of the trade-offs of Kafka one can make using the above values.

* Setting `min.insync.replicas` to a majority quorum (e.g. (replicationfactor/2)+1)(replication factor / 2) + 1)(replicationfactor/2)+1) and acksacksacks to allallall would allow one to enforce stricter *durability* guarantees, while also achieving good *availability*. Let’s assume replicationfactor=5replication factor = 5replicationfactor=5, so there are 555 replicas per partition and min.insync.replicas=3min.insync.replicas = 3min.insync.replicas=3. This would mean up to 222 node failures can be tolerated with zero data loss, and the cluster is still available for writes and reads.
* Setting `min.insync.replicas` equal to replicationfactorreplication factorreplicationfactor and acksacksacks to allallall would provide even stronger *durability* guarantees at the expense of lower *availability*. In our previous example of replicationfactor=5replication factor = 5replicationfactor=5, this would mean that up to 444 node failures can now be tolerated with zero data loss. However, a single node failure makes the cluster unavailable for writes.
* Setting acksacksacks to 111 can provide better *performance* at the expense of weaker *durability* and *consistency* guarantees. For example, records will be considered committed and acknowledged as soon as the leader has stored them locally without waiting for any of the followers to catch up. However, in case of a leader’s failure and election of a new leader, records that the previous leader acknowledged but did not make it to the new leader yet will be lost.

What tuning levers are available in Kafka, and how do they impact system behavior? Write your answer with proper reasoning in the AI assessment widget below.

Want to know the correct answer?

What tuning levers are available in Kafka?

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Introduction to Kafka

Kafka's Messaging Guarantees

Ask

[Tuning levers](#Tuning-levers)

[Trade-offs](#Trade-offs)

---


# Kafka's Messaging Guarantees

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Kafka's Messaging Guarantees

# Kafka's Messaging Guarantees

Let's explore the messaging guarantees provided by Kafka.

We'll cover the following...

* [At-most-once semantics](#At-most-once-semantics)
* [At-least-once semantics](#At-least-once-semantics)
* [Exactly-once semantics](#Exactly-once-semantics)

Kafka can provide **at-least-once**, **at-most-once** and **exactly-once** messaging guarantees through different configurations. Let’s explore each one of them separately:

## At-most-once semantics[#](#At-most-once-semantics)

At-most-once semantics is achieved on the producer side by disabling any retries. If the write fails (e.g., due to a TimeoutException), the producer will not retry the request. Moreover the message might or might not be delivered depending on whether it had reached the broker. However, this guarantees that the message cannot be delivered more than once.

In a similar vein, consumers commit message offsets before they process them. Consequently, each message is processed once in the happy path. However, if the consumer fails after committing the offset but before processing the message. In that case the message will never be processed.

## At-least-once semantics[#](#At-least-once-semantics)

At-least-once semantics is achieved by enabling retries for producers. Since failed requests will now be retried, a message might be delivered more than once to the broker leading to duplicates. However, it’s guaranteed to be delivered at least once.

> Note: We are assuming infinite retries in this process. However, practically a maximum threshold of retries is usually performed, in which case a message might not be delivered if this limit is exhausted.

The consumer can process the message first and then commit the offset. This would mean that the message could be processed multiple times if the consumer fails after processing it but before committing the offset.

## Exactly-once semantics[#](#Exactly-once-semantics)

Exactly-once semantics is achieved by using the idempotent producer provided by Kafka. This producer is assigned a unique identifier (PID) and tags every message with a sequence number. In this way, the broker can keep track of the largest number per PID and reject duplicates.

The consumers can store the committed offsets in Kafka or an external data store.Suppose the offsets are stored in the same data store where the side-effects of the message processing are stored. In that case, the offsets can be committed atomically with the side-effects, thus providing exactly-once guarantees.

Differentiate between the at most once, at least once, and exactly once semantics in Kafka. Focus on the key difference between the three types of semantics used in Kafka. Write your answer with proper reasoning in the AI assessment widget below.

Want to know the correct answer?

Differentiate between the three types of semantics used in Kafka.

Type your answer

﻿

Evaluate

Beta

1000 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Kafka Levers

Transactions, Storage Layout, and other Guarantees

Ask

[At-most-once semantics](#At-most-once-semantics)

[At-least-once semantics](#At-least-once-semantics)

[Exactly-once semantics](#Exactly-once-semantics)

---


# Transactions, Storage Layout, and other Guarantees

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Transactions, Storage Layout, and other Guarantees

# Transactions, Storage Layout, and other Guarantees

Let’s have an overview of the transactions and the physical storage of Kafka, and the provided guarantees by it.

We'll cover the following...

* [Transactional client](#Transactional-client)
* [Physical storage of Kafka](#Physical-storage-of-Kafka)
* [Guarantees provided by Kafka](#Guarantees-provided-by-Kafka)

## Transactional client[#](#Transactional-client)

Kafka provides a **transactional client** that allows producers to produce messages to multiple partitions of a topic atomically.

A transactional client also makes it possible to commit consumer offsets from a source topic in Kafka and produces messages to a destination topic in Kafka atomically. This makes it possible to provide exactly-once guarantees for an end-to-end pipeline. This is achieved through the use of a two-phase commit protocol, where the brokers of the cluster play the role of the transaction coordinator in a highly available manner using the same underlying mechanisms for partitioning, leader election, and fault-tolerant replication.

The coordinator stores the status of a transaction in a separate log. The messages contained in a transaction are stored in their own partitions as usual.

When a transaction is committed, the coordinator is responsible for writing a commit marker to the partitions containing messages of the transactions and the partitions storing the *consumer* offsets.

Consumers can also specify the isolation level they want to read under, **read\_committed** or **read\_uncommitted**. In the former case, messages that are part of a transaction will be readable from a partition only after a commit marker has been produced for the associated transaction. This interaction is summarised in the following illustration:

Created with Fabric.js 3.6.6

1 / 9

Three main components of Kafka architecture, Transactional client, Transaction coordinators, and Brokers

Created with Fabric.js 3.6.6

1 / 9

Transactional client requests Transaction coordinator to initiate the transaction

Created with Fabric.js 3.6.6

1 / 9

Transactional client requests Transaction coordinator to add partition to the transaction

Created with Fabric.js 3.6.6

1 / 9

Transactional client requests Broker to produce messages and commits consumer offsets

Created with Fabric.js 3.6.6

1 / 9

Transactional client requests Transaction coordinator to commit/abort the transaction

## Physical storage of Kafka[#](#Physical-storage-of-Kafka)

The physical storage layout of Kafka is simple and it is shown in the following illustration. Every log partition is implemented as a set of segment files of approximately the same size (e.g., 1 GB).

Storage layout of a Kafka topic

Every time a producer publishes a message to a partition, the broker appends the message to the last segment file. For better performance, segment files are flushed to disk only after a configurable number of messages have been published or a configurable amount of time has elapsed.

> Note: This particular behavior of Kafka is configurable through the values `log.flush.interval.messages` and `log.flush.interval.ms`. It is important to note that this behaviour has implications in the aforementioned durability guarantees since some of the acknowledged records might be temporarily stored only in the memory of all in-sync replicas for some time until they are flushed to the disk.

Each broker keeps in memory a sorted list of offsets, including the offset of the first message in every segment file.

Kafka employs some more performance optimizations, such as using the [sendfile API](https://developer.ibm.com/articles/j-zerocopy) for sending data to consumers, thus minimizing copying of data and system calls.

## Guarantees provided by Kafka[#](#Guarantees-provided-by-Kafka)

Some of the guarantees provided by Kafka are the following:

* Kafka appends the messages in the order they are sent by a producer to a particular topic’s partition. If a message M1M\_1M1​ is sent by the same producer as a message M2M\_2M2​, and M1M\_1M1​ is sent first, then M1M\_1M1​ will have a lower offset than M2M\_2M2​ and appear earlier in the log.

> Note: Ordering guarantees are provided only per partition. Users of Kafka can control partitioning, as described before, to leverage the ordering guarantees.

* As explained earlier, Kafka can provide *at-least-once*, *at-most-once*, and *exactly-once* messaging semantics, depending on the configuration and the type of producers and consumers used.
* The *durability*, *availability*, and *consistency* guarantees provided by Kafka depend on the specific configuration of the cluster. For example, a topic with a replication factor of *N*, `min.insync.replicas` of N/2+1N/2 + 1N/2+1 and *acks=all* guarantees zero data loss and availability of the cluster for up to N/2N/2N/2 failures.

Backlesson

Mark As CompletedComplete

Next

Kafka's Messaging Guarantees

Quiz on Distributed Messaging Queue

Ask

[Transactional client](#Transactional-client)

[Physical storage of Kafka](#Physical-storage-of-Kafka)

[Guarantees provided by Kafka](#Guarantees-provided-by-Kafka)

---


# Quiz on Distributed Messaging Queue

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed Messaging Queue

# Quiz on Distributed Messaging Queue

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

In Kafka, how many failures can the system tolerate without losing data or becoming unavailable if we assume a setup with `replication factor` = 5, `min.insync.replicas` = 3, `acks` = all?

A.

1

B.

2

C.

3

D.

4

---

1 / 3

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Transactions, Storage Layout, and other Guarantees

Kubernetes

Ask

---


# Kubernetes

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Kubernetes

# Kubernetes

Let's have an introduction to Kubernetes and its cluster in detail.

We'll cover the following...

* [Kubernetes cluster](#Kubernetes-cluster)
  + [Worker and manager nodes](#Worker-and-manager-nodes)
  + [Achieving availability and durability](#Achieving-availability-and-durability)
  + [Kubernetes utilizing etcd](#Kubernetes-utilizing-etcd)
  + [Cluster resources](#Cluster-resources)
    - [Pod](#Pod)
    - [Persistent volume](#Persistent-volume)
    - [Job](#Job)
    - [Service](#Service)

[**Kubernetes**](https://kubernetes.io/) is a system that Google initially designed, inspired by a similar system called Borg, which was designed and developed by Verma et al. and Burns et al.. The Cloud Native Computing Foundation now maintains Kubernetes. It manages a cluster of nodes and other resources (e.g., disks), handling all the aspects of running software in the cluster, such as deployment, scaling, and discovery.

## Kubernetes cluster[#](#Kubernetes-cluster)

A Kubernetes cluster contains a set of nodes that can have two distinct roles. They can either be a worker node or a manager node.

### Worker and manager nodes[#](#Worker-and-manager-nodes)

* A **worker node** is responsible for running the user applications.
* A **manager node** is responsible for managing and coordinating the worker nodes.

Essentially, worker nodes make a set of resources available to the cluster, and manager nodes decide how these resources are allocated to the applications that need to be executed as specified by the user.

> Note that these applications can be divided into two main categories: **long-running services** that constantly run and typically respond to incoming requests, and **jobs** that run for a bounded amount of time typically doing some data processing.

### Achieving availability and durability[#](#Achieving-availability-and-durability)

For availability and durability in Kubernetes, multiple manager nodes can run in parallel, with one of them operating as the **active leader** and the rest acting as **passive followers**.

### Kubernetes utilizing etcd[#](#Kubernetes-utilizing-etcd)

Kubernetes uses etcd for various purposes, such as:

* Storing all the cluster data
* Performing leader election
* Transmitting change notifications between different parts of the cluster

> Each node has several different components for the various functionalities that run independently, i.e., as separate processes.

Suppose your active manager node fails unexpectedly. Based on the described components, what mechanism allows the cluster to continue operating, and what role does etcd play in this transition? Provide your answer in the widget given below.

Want to know the correct answer?

Handling Active Node Failures with etcd

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

### Cluster resources[#](#Cluster-resources)

The various objects of the cluster (e.g., nodes, services, jobs) are called **resources**, and they are represented in etcd as key-value entries under the right namespace.

One of the most central resources in Kubernetes is the pod.

#### Pod[#](#Pod)

A **pod** represents the smallest deployable unit of computing.

In practice, a pod is a group of one or more *containers* with shared storage/network and a specification for how to run the containers.

> A **container** is a lightweight and portable executable **image** that contains software and all of its dependencies. Kubernetes supports multiple container runtimes, with **Docker** being the most popular

#### Persistent volume[#](#Persistent-volume)

A **persistent volume** is a piece of storage in the cluster that has a lifecycle independent of any individual pod that uses it.

#### Job[#](#Job)

A **job** creates one or more pods and ensures that a specified number of them successfully terminate.

#### Service[#](#Service)

A **service** is an abstraction that defines a logical set of pods and a policy by which to access them.

Every resource is characterized by some **desired state** usually a desired number of replicas for a service. There are various components of Kubernetes that cooperate to ensure the cluster’s current state matches the desired state.

> Note that the desired state is provided by the user when creating a resource (Spec), while the current state is supplied and updated by Kubernetes (Status).

The architecture of Kubernetes is shown in the the following illustration:

![](images/image_1764834618.4724247.svg)![Kubernetes architecture](images/4520719928131584.svg "Kubernetes architecture")

Kubernetes architecture

> We will learn about the components of manager and worker nodes in the [next](https://www.educative.io/courses/distributed-systems-practitioners/components-of-manager-and-worker-nodes) lesson.

Backlesson

Mark As CompletedComplete

Next

Quiz on Distributed Messaging Queue

Components of Manager and Worker Nodes

Ask

[Kubernetes cluster](#Kubernetes-cluster)

[Worker and manager nodes](#Worker-and-manager-nodes)

[Achieving availability and durability](#Achieving-availability-and-durability)

[Kubernetes utilizing etcd](#Kubernetes-utilizing-etcd)

[Cluster resources](#Cluster-resources)

[Pod](#Pod)

[Persistent volume](#Persistent-volume)

[Job](#Job)

[Service](#Service)

---


# Components of Manager and Worker Nodes

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Components of Manager and Worker Nodes

# Components of Manager and Worker Nodes

Let’s learn about the components of manager and worker nodes in Kubernetes’ architecture and explore the concurrency control mechanism in Kubernetes.

We'll cover the following...

* [Components of the manager node](#Components-of-the-manager-node)
  + [The API Server (kube-apiserver)](#The-API-Server-kube-apiserver)
  + [The Scheduler (kube-scheduler)](#The-Scheduler-kube-scheduler)
  + [The Controller Manager (kube-controller-manager)](#The-Controller-Manager-kube-controller-manager)
* [Components of worker nodes](#Components-of-worker-nodes)
  + [The kubelet](#The-kubelet)
  + [The proxy](#The-proxy)
* [Need for the concurrency control mechanism](#Need-for-the-concurrency-control-mechanism)

## Components of the manager node[#](#Components-of-the-manager-node)

The main components of the manager node are the API Server (kube-apiserver), the Scheduler (kube-scheduler), and the Controller Manager (kube-controller-manager).

### The API Server (kube-apiserver)[#](#The-API-Server-kube-apiserver)

The **API Server** is the front-end of the Kubernetes cluster, allowing users to inspect the resources of the cluster and modify them or create new ones.

### The Scheduler (kube-scheduler)[#](#The-Scheduler-kube-scheduler)

The **Scheduler** detects newly created pods that have no nodes assigned and selects a node for them to run.

> Note that this selection of Scheduler is based on multiple criteria, such as user-specified constraints, affinity specifications, data locality, etc.

### The Controller Manager (kube-controller-manager)[#](#The-Controller-Manager-kube-controller-manager)

The **Controller Manager** runs all the available controllers in the manager node. A controller is a control loop that watches the state of the cluster through the API server making changes in order to move the current state towards the desired state

Below are some examples of controllers:

* **Node Controller:** responsible for noticing and responding to node failures
* **Replication Controller:** responsible for maintaining the correct number pods according to the replication specified by the user.
* **Endpoints Controller:** responsible for creating endpoints for services.

> **Note**: We have already studied the following illustration in the previous lesson as well. This illustration will make it easier for the reader to follow the components of manager and worker nodes.

![](images/image_1764834633.5627842.svg)![Kubernetes architecture](images/6237055783927808.svg "Kubernetes architecture")

Kubernetes architecture

## Components of worker nodes[#](#Components-of-worker-nodes)

The main components of the worker nodes are the kubelet and the proxy (kube-proxy).

### The kubelet[#](#The-kubelet)

The **kubelet** is an agent that runs on each node in the cluster, receives a set of pod specifications, and makes sure the containers described in these specifications are running and are healthy.

### The proxy[#](#The-proxy)

The **proxy** is a network proxy that maintains network rules that allow network communication to the pods from sessions inside and outside the cluster.

> Note that the worker nodes also contain software of the container runtime that is used.

## Need for the concurrency control mechanism[#](#Need-for-the-concurrency-control-mechanism)

Kubernetes operates under **eventual consistency**, it recovers from potential failures and converges back to the desired state. Since multiple components read and update the current state of the cluster, there is a need for some concurrency control to prevent anomalies arising from reduced isolation.

Kubernetes achieves this with the use of conditional updates. Every resource object has a `resourceVersion` field representing the version of the resource as stored in etcd. This version is used to perform a **compare-and-swap (CAS) operation** so that anomalies like lost updates are prevented.

Backlesson

Mark As CompletedComplete

Next

Kubernetes

Quiz

Ask

[Components of the manager node](#Components-of-the-manager-node)

[The API Server (kube-apiserver)](#The-API-Server-kube-apiserver)

[The Scheduler (kube-scheduler)](#The-Scheduler-kube-scheduler)

[The Controller Manager (kube-controller-manager)](#The-Controller-Manager-kube-controller-manager)

[Components of worker nodes](#Components-of-worker-nodes)

[The kubelet](#The-kubelet)

[The proxy](#The-proxy)

[Need for the concurrency control mechanism](#Need-for-the-concurrency-control-mechanism)

---


# Quiz

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz

# Quiz

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

Which of the following aspects of running software in the cluster can Kubernetes handle? (Select all that apply) Multi-select

A.

Deployment

B.

Scaling

C.

Discovery

---

1 / 8

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Components of Manager and Worker Nodes

Introduction to Corda

Ask

---


# Introduction to Corda

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction to Corda

# Introduction to Corda

Let's examine what Corda is and how the Corda network is built.

We'll cover the following...

* [Corda network](#Corda-network)
  + [Public and private keys](#Public-and-private-keys)
  + [Map service](#Map-service)

Corda is a platform that allows multiple parties that do not fully trust each other to maintain a distributed ledger with shared facts amongst each other.

> **Note**: By its nature, Corda is a distributed system similar to the systems analyzed previously.

A distinctive characteristic of this system is this lack of trust between the nodes that are part of the system, which also gives it a decentralization aspect. This distrust is managed through various cryptographic primitives.

> **Note**: This chapter will give a rather brief overview of Corda’s architecture. You can refer to the available whitepapers by Brown et al. and Hearn et al. for a more detailed analysis.

## Corda network[#](#Corda-network)

Each node in Corda is a **JVM runtime environment** with a unique identity on the network. A Corda network comprises many such nodes that want to transact with each other to maintain and evolve a set of shared facts.
Corda network is permissioned, which means nodes need to acquire an **X.509 certificate** from the network operator to be part of the network.

The component that issues X.509 certificates is referred to as the **doorman**. In this context, the doorman operates as a certificate authority for the nodes that are part of the network.

### Public and private keys[#](#Public-and-private-keys)

Each node maintains a public and a private key.

* The private key is used to attest to facts by signing the associated data.
* The public key is used by other nodes to verify these signatures.

This X.509 certificate creates an association between the public key of the node and a human-readable X.500 name (e.g., O=MegaCorp, L=London, C=GB).

### Map service[#](#Map-service)

The network also contains a network **map service**, which provides some form of service discovery to the nodes part of the network. The nodes can query this service to discover other nodes that are part of the network in order to transact with them.

Interestingly, the nodes do not fully trust the network operator for the distribution of this information. So each entry of this map that contains the identifying data of a node (i.e., IP address, port, X.500 name, public key, X.509 certificate, etc.) is also signed by the corresponding node. In order to avoid censorship by the network operator, the nodes can even exchange the files that contain this information with each other out-of-band and install them locally.

Backlesson

Mark As CompletedComplete

Next

Quiz

Corda's Data Model

Ask

[Corda network](#Corda-network)

[Public and private keys](#Public-and-private-keys)

[Map service](#Map-service)

---


# Corda's Data Model

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Corda's Data Model

# Corda's Data Model

Let’s study the data model of Corda in detail.

We'll cover the following...

* [States](#States)
* [Corda transaction](#Corda-transaction)
  + [Smart contract](#Smart-contract)
* [Corda’s data model for electronic money](#Cordas-data-model-for-electronic-money)
  + [Double-spend problem](#Double-spend-problem)
  + [Preventing double-spend](#Preventing-double-spend)
  + [Transaction finalization](#Transaction-finalization)
* [Fault tolerance and availability with a Notary cluster](#Fault-tolerance-and-availability-with-a-Notary-cluster)
* [Implications of permissions on Corda nodes and notaries](#Implications-of-permissions-on-Corda-nodes-and-notaries)

## States[#](#States)

States represent the shared facts between Corda nodes. States are immutable objects which can contain arbitrary data depending on the use case.

Since states are immutable, they cannot be modified directly to reflect a change in the state of the world. Instead, the current state is marked as historic and is replaced by a new state, which creates a chain of states that gives us a full view of the evolution of a shared fact over time. A **Corda transaction** does this evolution.

## Corda transaction[#](#Corda-transaction)

Corda transaction specifies the states marked as historic (also known as the input states of the transaction) and the new states that supersede them (also known as the output states of the transaction).

Of course, there are particular rules to specify the kind of states each state can be replaced by. **Smart contracts** specify these rules, and each state also contains a reference to the contract that governs its evolution.

### Smart contract[#](#Smart-contract)

The smart contract is a pure function that takes a transaction as an input and determines whether this transaction is considered valid based on the contract’s rules.

Transactions can also contain commands, which indicate the transaction’s intent regarding how the data of the states are used. Each command is also associated with a list of public keys that need to sign the transaction to be valid.

## Corda’s data model for electronic money[#](#Cordas-data-model-for-electronic-money)

The following illustration shows a simple example of the Corda’s data model for electronic money:

Created with Fabric.js 3.6.6

1 / 3

Two cash states owned by Alice issued by Banka, one with 7 GBP money and other with 3 GBP money

Created with Fabric.js 3.6.6

1 / 3

Alice combines two cash states to perform payment and transfer 10 GBP to Bob

Created with Fabric.js 3.6.6

1 / 3

Bob decides to redeem this money to get some cash from the bank

In the above illustration, each state represents an amount of money issued by a specific bank and owned by a specific party at some point in time. We can see that Alice combines two cash states to perform payment and transfer 10 GBP to Bob. After that, Bob decides to redeem this money to get some cash from the bank.

As shown in the above illustration, there are two different commands for each case. We can also guess some of the rules of the associated contract for this `Cash` state.

For a `Spend` command, the contract will verify that the sum of all input states equals the sum of all output states so that no money is lost or created out of thin air. It will most likely check that the Spend command contains all the owners of the input states as signers, which need to attest to this transfer of money.

### Double-spend problem[#](#Double-spend-problem)

In the above example, we can notice that nothing would prevent someone from spending a specific cash state to two different parties who would not be able to detect that. This is known as **double-spend**.

### Preventing double-spend[#](#Preventing-double-spend)

Double-spend is prevented in Corda via the concept of **notaries**.

A notary is a Corda service responsible for attesting that a specific state is not spent more than once.

### Transaction finalization[#](#Transaction-finalization)

In practice, every state is associated with a specific notary and every transaction that wants to spend this state needs to acquire a signature from this notary that proves that the state was not spent already by another transaction. This process is known as **transaction finalization** in Corda.

## Fault tolerance and availability with a Notary cluster[#](#Fault-tolerance-and-availability-with-a-Notary-cluster)

The notarisation services are not necessarily provided by a single node; it can also be a notary cluster of multiple nodes in order to provide better *fault tolerance* and *availability*. In that case, these nodes will form a **consensus group**.

Corda allows the consensus algorithm used by the notary service to be pluggable depending on the requirements in terms of privacy, scalability, performance, etc. For instance:

* A notary cluster might choose to use a **crash fault tolerant (CFT) consensus algorithm (e.g., Raft)** that provides **high performance** but also requires **high trust** between the nodes of the cluster.
* Alternatively, a notary cluster might choose to use a **byzantine fault tolerant (BFT) algorithm** that provides **lower performance** but also requires **less trust** between the nodes of the cluster.

## Implications of permissions on Corda nodes and notaries[#](#Implications-of-permissions-on-Corda-nodes-and-notaries)

Permissioning has different implications on regular Corda nodes and notaries.

* In the first case, it forms the foundation for authentication of communication between nodes.
* In the second case, it makes it easier to detect when a notary service deviates from a protocol (e.g., violating finality), identify the associated real-world entity, and take the necessary actions.

This means that finalized *transactions* are not reversible in Corda unless someone violates the protocol.

> **Note**: Corda is in contrast to some other distributed ledger systems where nodes are anonymous and can thus collude in order to revert historic transactions, such as Bitcoin.

As mentioned previously, in some cases, even a limited amount of protocol violation can be tolerated, i.e., when using a byzantine consensus protocol.

Backlesson

Mark As CompletedComplete

Next

Introduction to Corda

Corda's Architecture

Ask

[States](#States)

[Corda transaction](#Corda-transaction)

[Smart contract](#Smart-contract)

[Corda’s data model for electronic money](#Cordas-data-model-for-electronic-money)

[Double-spend problem](#Double-spend-problem)

[Preventing double-spend](#Preventing-double-spend)

[Transaction finalization](#Transaction-finalization)

[Fault tolerance and availability with a Notary cluster](#Fault-tolerance-and-availability-with-a-Notary-cluster)

[Implications of permissions on Corda nodes and notaries](#Implications-of-permissions-on-Corda-nodes-and-notaries)

---


# Corda's Architecture

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Corda's Architecture

# Corda's Architecture

Let's study the Corda's architecture by looking at what it provides.

We'll cover the following...

* [Problem with applications deployed in a single network](#Problem-with-applications-deployed-in-a-single-network)
* [Solution by Corda](#Solution-by-Corda)
* [Notary-change transaction](#Notary-change-transaction)
* [Corda applications](#Corda-applications)
  + [Defining nodes interaction](#Defining-nodes-interaction)
  + [Providing message serialization](#Providing-message-serialization)
    - [Messaging between nodes](#Messaging-between-nodes)
    - [Achieving exactly-once guarantee](#Achieving-exactly-once-guarantee)
  + [Performing operations in an atomic way](#Performing-operations-in-an-atomic-way)

## Problem with applications deployed in a single network[#](#Problem-with-applications-deployed-in-a-single-network)

The size of the ledger of all Corda applications deployed in a single network can become large. The various nodes of the network communicate in a peer-to-peer fashion only with the nodes they need to transact. Still the notary service seems to be something that needs to be used by all the nodes and could potentially become a *scalability* and *performance* bottleneck.

## Solution by Corda[#](#Solution-by-Corda)

To deal with the above-discussed problem, Corda supports both **vertical** and **horizontal partitioning**.

Each network can contain multiple **notary clusters** so that different applications can use different clusters (vertical partitioning). Even the same application can distribute its states between multiple notary clusters for better *performance* and *scalability* (vertical partitioning).

> **Note**: The only requirement for all input states of a transaction is to belong to the same notary. This is so that the operation of checking whether a state is **spent** and marking it as *spent* can be done atomically in a simple and efficient way without the use of distributed transaction protocols.

## Notary-change transaction[#](#Notary-change-transaction)

It is a particular transaction type provided by Corda, which allows one to change the notary associated with a state by essentially spending the state and creating a new one associated with the new notary.

In some use cases, the notary-change transaction partitions the datasets to require a minimum number of such transactions, because most transactions are expected to access states from the same partition.

For example, the partitioning of states according to geographic regions if we know in advance that most of the transactions will be accessing data from the same region. This architecture also makes it possible to use states from different applications very easily without the use of distributed transaction protocols.

> **Note**: This above described process is known as **atomic swap** and, a real use case in the financial world is **delivery-versus-payment (DvP)**.

## Corda applications[#](#Corda-applications)

Corda applications are called **CorDapps** and contain several components, of which the most important ones are the **states**, their **contracts**, and the **flows**.

The flows define the workflows between nodes used to update the ledger or simply exchange some messages.

### Defining nodes interaction[#](#Defining-nodes-interaction)

Corda provides a framework that allows the application to define the interaction between nodes as a set of blocking calls that send and receive messages. The framework is responsible for transforming this into an asynchronous, event-driven execution.

### Providing message serialization[#](#Providing-message-serialization)

Corda also provides a custom serialization framework that determines how application messages are serialized when sent across the wire and how they are deserialized when received.

#### Messaging between nodes[#](#Messaging-between-nodes)

Messaging between nodes is performed with the use of message queues, using the **Apache ActiveMQ Artemis message broker**. Specifically, each node maintains an **inbound queue** for messages received by other nodes and **outbound queues** for messages sent to other nodes. A bridge process is responsible for forwarding messages from the node’s outbound queues to the corresponding inbound queues of the other nodes.

Even though all of these moving parts can crash and restart in the middle of some operation, the platform guarantees that every node will process each message **exactly-once**.

#### Achieving exactly-once guarantee[#](#Achieving-exactly-once-guarantee)

The guarantee of every node to process each message exactly once is achieved by resending messages until they are acknowledged and having nodes keeping track of messages processed already and discarding duplicates.

Now that you have seen how Corda guarantees exactly-once delivery, what would a node do if it crashes after applying side-effects from a message but before sending an acknowledgement, and how does Corda avoid duplicating the side-effects on retry? Provide your answer in the widget given below.

Want to know the correct answer?

Corda’s Handling of Crashes to Prevent Duplicate Side-Effects

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

### Performing operations in an atomic way[#](#Performing-operations-in-an-atomic-way)

Nodes also need to acknowledge a message, store its identifier and perform any related side-effects in an atomic way. It is achieved by doing all of this in a single database transaction. All the states from the ledger that are relevant to a node are stored in its database. This part of the database is called the **vault**.

A node provides some more APIs that are used for various purposes, such as:

* Starting flows
* Querying the node’s vault

These APIs are accessed remotely via a client, which provides a remote procedure call (RPC) interface implemented on top of the existing messaging infrastructure and using the serialization protocol described before.

The following illustration contains a high-level overview of Corda’s architecture:

High-level overview of Corda’s architecture

Backlesson

Mark As CompletedComplete

Next

Corda's Data Model

Backwards Compatibility provided by Corda

Ask

[Problem with applications deployed in a single network](#Problem-with-applications-deployed-in-a-single-network)

[Solution by Corda](#Solution-by-Corda)

[Notary-change transaction](#Notary-change-transaction)

[Corda applications](#Corda-applications)

[Defining nodes interaction](#Defining-nodes-interaction)

[Providing message serialization](#Providing-message-serialization)

[Messaging between nodes](#Messaging-between-nodes)

[Achieving exactly-once guarantee](#Achieving-exactly-once-guarantee)

[Performing operations in an atomic way](#Performing-operations-in-an-atomic-way)

---


# Backwards Compatibility provided by Corda

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Backwards Compatibility provided by Corda

# Backwards Compatibility provided by Corda

Let's explore some mechanisms through which Corda preserves backwards compatibility.

We'll cover the following...

* [API & ABI backwards compatibility](#API--ABI-backwards-compatibility)
  + [Changing the structure of data exchanged between nodes](#Changing-the-structure-of-data-exchanged-between-nodes)
    - [Example: Adding nullable properties](#Example-Adding-nullable-properties)
    - [Example: Removing nullable properties and adding non-nullable properties](#Example-Removing-nullable-properties-and-adding-non-nullable-properties)
* [New backwards incompatible feature](#New-backwards-incompatible-feature)
  + [Corda solving multiple versioning problem](#Corda-solving-multiple-versioning-problem)
    - [Minimum platform version](#Minimum-platform-version)
* [Features that do not affect the whole network](#Features-that-do-not-affect-the-whole-network)
* [Multiple versioning levers provided by Corda](#Multiple-versioning-levers-provided-by-Corda)

Corda is a very interesting case study from the perspective of **backwards compatibility**.

In a distributed system, the various nodes of the system might be running different versions of the software. In many cases, the software is deployed incrementally to them and not in a single step. There is an additional challenge in a decentralized system because different organizations now control the various nodes of the systems so that these discrepancies might last longer.

Corda provides a lot of different mechanisms to preserve backwards compatibility in different areas, so let’s explore some of them.

## API & ABI backwards compatibility[#](#API--ABI-backwards-compatibility)

Corda provides API & [ABI](https://en.wikipedia.org/wiki/Application_binary_interface) backwards compatibility for all the public APIs available to CorDapps. It means that any CorDapp should run in future versions of the platform without any change or re-compilation.

Similar to other applications, CorDapps are expected to evolve, which might involve:

* Changing the structure of data exchanged between nodes
* Changing the structure of data stored in the ledger (e.g., states)

### Changing the structure of data exchanged between nodes[#](#Changing-the-structure-of-data-exchanged-between-nodes)

The **serialization framework** provides some support for the evolution of this case.

#### Example: Adding nullable properties[#](#Example-Adding-nullable-properties)

Nullable properties can be added to a class, and the framework will take care of the associated conversions. A node running an older version of the CorDapp will ignore this new property if data is sent from a node running a newer version of the CorDapp. A node running a newer version of the CorDapp will populate the property with null when receiving data from a node running the older version of the CorDapp.

#### Example: Removing nullable properties and adding non-nullable properties[#](#Example-Removing-nullable-properties-and-adding-non-nullable-properties)

Removing *nullable* properties and adding a *non-nullable* property is also possible by providing a default value. However, the serialization framework does not allow this form of data loss for data that persisted in the ledger, such as states and commands.

Since states can evolve and the ledger might contain states from many earlier versions of a CorDapp, newer versions of a contract need to contain appropriate logic that can process states from earlier versions of the CorDapp.

The contract logic for handling states from version viv\_ivi​ of the CorDapp can be removed by a subsequent release of the CorDapp only after all unspent states in the ledger are from version vjv\_jvj​ of the CorDapp, where j>ij > ij>i.

## New backwards incompatible feature[#](#New-backwards-incompatible-feature)

In some cases, the platform might introduce a new feature that is not backward compatible. The older versions of the platform cannot understand it . This feature can be problematic for two reasons:

* Two nodes running different versions of the platform might reach different conclusions with regards to the validity of a transaction.
* When validating a transaction, nodes are also supposed to validate previous transactions involved in the chain of the provenance of the states consumed in the current transaction.

This means that a node running an older version of the platform might fail to validate a transaction that was valid in the past simply because the transaction uses a feature introduced in a newer version of the platform.

### Corda solving multiple versioning problem[#](#Corda-solving-multiple-versioning-problem)

Corda solves the multiple versioning problem with the use of the **network minimum platform version**.

#### Minimum platform version[#](#Minimum-platform-version)

Every network comes with a set of parameters that every node participating in the network needs to agree on and use to interoperate with each other correctly. This set contains a parameter called `minimumPlatformVersion`, which determines the minimum platform version that the nodes must be running. Any node which is below this will not be able to start.

Any platform feature that is not backwards compatible and requires a minimum version of the platform can check this parameter and be enabled only when the network is over a specific platform version. In this way, the nodes of a network can start using a feature only after they can be certain all other nodes will also be able to use it.

This process establishes a balance between nodes in a network that are keen on using a new feature and nodes that are risk-averse and are not willing to upgrade to a new version of the platform.

> **Note**: However, this process applies only to features that have network-wide implications, e.g., ones that determine how data are stored on the ledger.

## Features that do not affect the whole network[#](#Features-that-do-not-affect-the-whole-network)

There are features that do not affect the whole network. For example changes to how two nodes interact during the execution of a flow or even how a single node executes some part of a CorDapp locally.

## Multiple versioning levers provided by Corda[#](#Multiple-versioning-levers-provided-by-Corda)

Corda provides multiple versioning levers for more fine-grained control. CorDapps provide two version numbers for this purpose: `minimumPlatformVersion` and `targetPlatformVersion`.

* `minimumPlatformVersion` indicates the minimum platform version the node must have for the CorDapp to function properly, which is essentially determined based on the necessary features to the CorDapp and the platform version they were introduced in.
* `targetPlatformVersion` indicates the highest version the CorDapp has been tested against and helps the platform disable backwards compatibility `codePaths` that might make the CorDapp less efficient or secure.

> **Note**: These two versions only have implications on the node running the CorDapp, instead of the whole network.

Another example is the fact that flows in a CorDapp can be versioned to evolve while maintaining backwards compatibility. In this way, a flow can behave differently depending on the deployed version of the CorDapp on the counterparty node. This makes it possible to upgrade a CorDapp incrementally across various nodes, instead of all of them having to do it in lockstep.

Backlesson

Mark As CompletedComplete

Next

Corda's Architecture

Quiz on Distributed Ledger

Ask

[API & ABI backwards compatibility](#API--ABI-backwards-compatibility)

[Changing the structure of data exchanged between nodes](#Changing-the-structure-of-data-exchanged-between-nodes)

[Example: Adding nullable properties](#Example-Adding-nullable-properties)

[Example: Removing nullable properties and adding non-nullable properties](#Example-Removing-nullable-properties-and-adding-non-nullable-properties)

[New backwards incompatible feature](#New-backwards-incompatible-feature)

[Corda solving multiple versioning problem](#Corda-solving-multiple-versioning-problem)

[Minimum platform version](#Minimum-platform-version)

[Features that do not affect the whole network](#Features-that-do-not-affect-the-whole-network)

[Multiple versioning levers provided by Corda](#Multiple-versioning-levers-provided-by-Corda)

---


# Quiz on Distributed Ledger

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed Ledger

# Quiz on Distributed Ledger

We'll cover the following...

In the following quiz, you will test yourself on concepts you have learned in this chapter.

Technical Quiz

1.

What is the role of the notary service in Corda?

A.

It allows multiple parties that do not fully trust each other to maintain a distributed ledger with shared facts amongst each other.

B.

It is responsible for attesting that a specific state is not spent more than once.

---

1 / 8

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Backwards Compatibility provided by Corda

Introduction

Ask

---


# Introduction

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction

# Introduction

Let's study distributed data processing systems.

We'll cover the following...

* [Categories of distributed data processing systems](#Categories-of-distributed-data-processing-systems)
  + [Batch processing systems](#Batch-processing-systems)
  + [Stream processing systems](#Stream-processing-systems)

This chapter will examine distributed systems used to process large amounts of data that would be impossible or very inefficient to process using only a single machine.

## Categories of distributed data processing systems[#](#Categories-of-distributed-data-processing-systems)

Distributed data processing systems can be classified into the following two main categories:

### Batch processing systems[#](#Batch-processing-systems)

Batch processing **systems** group individual data items into groups called **batches**, which are processed one at a time. In many cases, these groups can be quite large (e.g., all items for a day), so the main goal for these systems is usually to provide high *throughput*, but sometimes at the cost of higher latency.

### Stream processing systems[#](#Stream-processing-systems)

Stream processing systems receive and process data continuously as a stream of data items. As a result, the main goal for these systems is to provide very low latency sometimes at the cost of decreased throughput.

The following illustration helps us differentiate between a batch and a stream processing system:

Batch and stream processing

> There is also a form of processing that is essentially a hybrid between these two categories, called **micro-batch processing**. This approach processes data in batches, but these are kept very small to achieve a balance between *throughput* and *latency*.

In this chapter, we will study the following three distributed data processing systems in detail:

* Mapreduce
* Apache Spark
* Apache Flink

Backlesson

Mark As CompletedComplete

Next

Quiz on Distributed Ledger

Introduction to MapReduce

Ask

[Categories of distributed data processing systems](#Categories-of-distributed-data-processing-systems)

[Batch processing systems](#Batch-processing-systems)

[Stream processing systems](#Stream-processing-systems)

---


# Introduction to MapReduce

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction to MapReduce

# Introduction to MapReduce

Let's find the inspiration behind MapReduce. Also, look into the goal and the working of MapReduce.

We'll cover the following...

* [Inspiration](#Inspiration)
* [Idea](#Idea)
  + [Map](#Map)
  + [Reduce](#Reduce)
* [An important property of map and reduce functions](#An-important-property-of-map-and-reduce-functions)
* [Working of MapReduce](#Working-of-MapReduce)

MapReduce is a framework for batch data processing originally developed internally in Google by Dean et al… It was later incorporated in the wider Apache Hadoop framework.

## Inspiration[#](#Inspiration)

The framework draws inspiration from the field of **functional programming** and is based on the following main idea:

## Idea[#](#Idea)

Many real-word computations can be expressed with the use of two main primitive functions, **map** and **reduce**.

### Map[#](#Map)

The `map` function processes a set of key-value pairs and produces another set of intermediate key-value pairs as output.

### Reduce[#](#Reduce)

The `reduce` function receives all the values for each key and returns a single value, essentially merging all the values according to some logic

## An important property of map and reduce functions[#](#An-important-property-of-map-and-reduce-functions)

The `map` and `reduce` functions can easily be parallelized and run across multiple machines for different parts of the dataset. As a result,

* The application code is responsible for defining these two methods.
* The framework is responsible for partitioning the data, scheduling the program’s execution across multiple nodes, handling node failures, and managing the required inter-machine communication.

## Working of MapReduce[#](#Working-of-MapReduce)

Let’s see a typical example to understand better how this programming model practically works.

Suppose we have a huge collection of documents (e.g., webpages), and we need to count the number of occurrences for each word. To achieve that via MapReduce, we would use the following functions:

```python
// key: the document name



// value: the document contents



map(String key, String value) {



for(word: value.split(" ")) {



emit(word, 1)



} }



reduce(String key, Iterator<Integer> values) {



for(value: values) {



result += value;



}



emit(key, result);



}
```

The `map` function in the above code would emit a single record for each word with the value 1, while the `reduce` function would just count all these entries and return the final sum for each word.

> Note that the MapReduce framework is also based on a **manager-worker architecture**, which we will discuss in the next lesson.

Backlesson

Mark As CompletedComplete

Next

Introduction

MapReduce's Manager-Worker Architecture

Ask

[Inspiration](#Inspiration)

[Idea](#Idea)

[Map](#Map)

[Reduce](#Reduce)

[An important property of map and reduce functions](#An-important-property-of-map-and-reduce-functions)

[Working of MapReduce](#Working-of-MapReduce)

---


# MapReduce's Manager-Worker Architecture

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

MapReduce's Manager-Worker Architecture

# MapReduce's Manager-Worker Architecture

Let's study the architecture of MapReduce and the guarantees provided by it.

We'll cover the following...

* [Steps for the execution of MapReduce](#Steps-for-the-execution-of-MapReduce)
* [Storage](#Storage)
* [Guarantees provided by MapReduce](#Guarantees-provided-by-MapReduce)

The **manager** node is responsible for scheduling tasks for **worker** nodes and managing their execution, as shown in the following illustration:

![](images/image_1764834749.541138.svg)![Architecture of MapReduce](images/4842546793676800.svg "Architecture of MapReduce")

Architecture of MapReduce

Apart from the definition of the `map` and `reduce` functions, the user can also specify the number `M` of `map` tasks, the number `R` of `reduce` tasks. MapReduce can also specify the number of input or output files, and a partitioning function that defines how key-value pairs from the `map` tasks are partitioned before being processed by the `reduce` tasks. By default, a **hash partitioner** is used that selects a `reduce` task using the formula `hash(key) mod R`.

## Steps for the execution of MapReduce[#](#Steps-for-the-execution-of-MapReduce)

The execution of MapReduce proceeds in the following way:

* The framework divides the input files into `M` pieces, called **input splits**, typically between 16 and 64 MB per split.
* It then starts an instance of a manager node and multiple worker node instances on an existing cluster of machines.
* The manager selects idle worker nodes and assigns `map` tasks to them.
* A worker node assigned a `map` task reads the contents of the associated input split parses key-value pairs and passes them to the user-defined `map` function. The entries emitted by the map function are buffered in memory and periodically written to the local disk, partitioned into `R` regions using the partitioning function. When a worker node completes a `map` task, it sends the location of the local file to the manager node.
* The manager node assigns `reduce` tasks to worker nodes providing the location to the associated files. These worker nodes then perform **remote procedure calls (RPCs)** to read the data from the local disks of the map workers. The data is first sorted so that all occurrences of the same key are grouped together and then passed into the reduce function.

> If the size is prohibitively large to fit in memory, **external sorting** is used.

* When all `map` and `reduce` tasks are completed, the manager node returns the control to the user program. After successful completion, the output of the MapReduce job is available in the `R` output files that can either be merged or passed as input to a separate MapReduce job.

The manager node communicates with every worker periodically in the background in a form of a **heartbeat**. If no response is received for a specific time, the manager node considers the worker node as failed and re-schedules all its tasks for re-execution.

More specifically, completed `reduce` tasks do not need to be rerun since the output files are stored in an external file system. However, `map` tasks are rerun regardless of whether they were completed since their output is stored on the local disk and is therefore inaccessible to the `reduce` tasks that need it.

> Note that the **network partitions** between the manager node and worker nodes might lead to multiple executions of a single `map` or `reduce` tasks.

Duplicate `map` tasks executions are deduplicated at the manager node, which ignores completion messages for already completed `map` tasks. The `reduce` tasks write their output to a temporary file, atomically renamed when the reduce task completes.

> Note that this atomic rename operation provided by the underlying file system guarantees that the output files will contain just the data produced by a single execution of each `reduce` task. However, if the `map`or `reduce` functions defined by the application code have additional side effects (e.g., writing to external datastores), the framework does not provide any guarantees. The application writer must make sure these side effects are atomic and idempotent since the framework might trigger them more than once as part of a task re-execution.

## Storage[#](#Storage)

Input and output files are usually stored in a distributed file system, such as HDFS or GFS. MapReduce can take advantage of this to perform several optimizations, such as scheduling `map` tasks to worker nodes that contain a replica of the corresponding input to minimize network traffic or aligning the size of input splits to the block size of the file system.

## Guarantees provided by MapReduce[#](#Guarantees-provided-by-MapReduce)

The MapReduce framework guarantees that the intermediate key-value pairs are processed in increasing key order within a given partition. This ordering guarantee makes it easy to produce a sorted output file per partition, which is helpful for use cases that need to support efficient random access lookups by key or need sorted data in general.

Furthermore, some use-cases would benefit from some form of pre-aggregation at the map level to reduce the amount of data transferred between `map` and `reduce` tasks. This was evident in the example presented above. A single map would emit multiple entries for each occurrence of a word instead of a single entry with the number of occurrences. For this reason, the framework allows the application code also to provide a `combine` function. This method has the same type as the `reduce` function and is run as part of the map task in order to pre-aggregate the data locally.

Backlesson

Mark As CompletedComplete

Next

Introduction to MapReduce

Introduction to Apache Spark

Ask

[Steps for the execution of MapReduce](#Steps-for-the-execution-of-MapReduce)

[Storage](#Storage)

[Guarantees provided by MapReduce](#Guarantees-provided-by-MapReduce)

---


# Introduction to Apache Spark

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction to Apache Spark

# Introduction to Apache Spark

Let's have an introduction to Apache Spark and its architecture.

We'll cover the following...

* [Limitation of MapReduce](#Limitation-of-MapReduce)
* [Foundation of Spark](#Foundation-of-Spark)
  + [Resilient Distributed Datasets (RDD)](#Resilient-Distributed-Datasets-RDD)
    - [Types of operations performed on RDDs](#Types-of-operations-performed-on-RDDs)
      * [Transformations](#Transformations)
      * [Actions](#Actions)
  + [Creating an RDD](#Creating-an-RDD)
* [Architecture of Spark](#Architecture-of-Spark)
  + [Cluster manager](#Cluster-manager)
  + [Worker nodes](#Worker-nodes)
  + [Request broker](#Request-broker)
  + [Driver](#Driver)
* [RDD operations](#RDD-operations)

Apache Spark is a data processing system that was initially developed at the University of California by Zaharia et al., and then donated to the Apache Software Foundation.

> Note that Apache Spark was developed in response to some of the limitations of MapReduce…

## Limitation of MapReduce[#](#Limitation-of-MapReduce)

The MapReduce model allowed developing and running embarrassingly parallel computations on a big cluster of machines. Still, every job had to read the input from the disk and write the output to the disk. As a result, there was a lower bound in the latency of job execution, which was determined by disk speeds. So the MapReduce was not a good fit for:

* **Iterative computations**, where
  a single job was executed multiple times or data were passed through multiple jobs.
* **Interactive data analysis**, where a user wants to run multiple ad hoc queries on the same dataset.

> Note that Spark addresses the above two use-cases.

## Foundation of Spark[#](#Foundation-of-Spark)

Spark is based on the concept of **Resilient Distributed Datasets (RDD)**.

### Resilient Distributed Datasets (RDD)[#](#Resilient-Distributed-Datasets-RDD)

RDD is a distributed memory abstraction used to perform in-memory computations on large clusters of machines in a fault-tolerant way. More concretely, an RDD is a read-only, partitioned collection of records.

RDDs can be created through operations on data in stable storage or other RDDs.

#### Types of operations performed on RDDs[#](#Types-of-operations-performed-on-RDDs)

The operations performed on an RDD can be one of the following two types:

##### Transformations[#](#Transformations)

**Transformations** are lazy operations that define a new RDD. Some examples of transformations are map, filter, join, and union.

##### Actions[#](#Actions)

**Actions** trigger a computation to return a value to the program or write data to external storage. Some examples of actions are count, collect, reduce, and save.

### Creating an RDD[#](#Creating-an-RDD)

A typical Spark application will create an RDD by reading some data from a distributed file system. It will then process the data by calculating new RDDs through transformations and storing the results in an output file.

For example, an application used to read some log files from HDFS and count the number of lines that contain the word “sale completed” would look like the following:

```python
lines = spark.textFile("hdfs://...")



completed_sales = lines.filter(_.contains("sale completed"))



number_of_sales = completed_sales.count()
```

The above program can either be submitted as an individual application in the background or each one of the commands can be executed interactively in the Spark interpreter.

> Note that a Spark program is executed from a coordinator process, called the **driver**.

## Architecture of Spark[#](#Architecture-of-Spark)

The Spark cluster contains a **cluster manager node**, and a set of **worker nodes** as shown in the following illustration:

![](images/image_1764834764.9807775.svg)![Architecture of Spark](images/5430567469187072.svg "Architecture of Spark")

Architecture of Spark

The responsibilities between Spark components are split in the following ways:

### Cluster manager[#](#Cluster-manager)

The **cluster manager** manages the resources of the cluster (i.e. the worker nodes) and allocates resources to clients that need to run applications.

### Worker nodes[#](#Worker-nodes)

The worker nodes are the nodes of the cluster that wait to receive applications/jobs to execute.

### Request broker[#](#Request-broker)

Spark also contains a **request broker** that requests resources in the cluster and makes them available to the driver.

> **Note**: Spark supports both a standalone and some clustering modes using third-party cluster management systems, such as YARN, Mesos, and Kubernetes. In the standalone mode, the request broker also performs the functions of the cluster manager. In some of the other clustering modes, such as Mesos and YARN, they are separate processes.

### Driver[#](#Driver)

The **driver** is responsible for:

* Requesting the required resources from the **request broker**.
* Starting a Spark agent process on each node that runs for the entire lifecycle of the application, called the **executor**.
* Analyzing the user’s application code into a **directed acyclic graph (DAG) of stages**
* Partitioning the associated RDDs
* Assigning the corresponding tasks to the executors available to compute them.

The driver is also responsible for managing the overall execution of the application, e.g., receiving **heartbeats** from executors and restarting failed tasks.

> **Note**: In the previous example, the second line `completed_sales = lines.filter(_.contains("sale completed"))`
> is executed without any data being read or processed yet since the `filter` is a transformation. The data is being read from HDFS, filtered, and then counted when the third line is processed, containing the `count` operation, which is an action. To achieve that, the driver maintains the relationship between the various RDDs through a lineage graph. When an action is performed, it triggers the calculation of an RDD and all its ancestors.

## RDD operations[#](#RDD-operations)

RDDs provide the following basic operations:

* `partitions()`: Returns a list of partition objects. For example, an RDD representing an HDFS file has a partition for each block of the file by default. The user can specify a custom number of partitions for an RDD if needed.
* `partitioner()`: Returns metadata determining whether the RDD is **hash/range partitioned**. This is relevant to transformations that join multiple key-value RDDs based on their keys, such as `join` or `groupByKey`. In these cases, hash partitioning is used by default on the keys, but the application can specify a custom range partitioning if needed. An example is provided in Zaharia’s paper, which showed that execution of the PageRank algorithm on Spark can be optimized by providing a custom partitioner that groups all the URLs of a single domain in the same partition.
* `preferredLocations(p)`: Lists nodes where partition `p` are accessed faster due to data locality. This might return nodes that contain the blocks of an HDFS file corresponding to that partition or a node that already contains in memory a partition that needs to be processed.
* `dependencies()`: Returns a list of dependencies on parent RDDs. These dependencies can be classified into two major types: **narrow** and **wide** dependencies:

  + A *narrow dependency* is where a partition of the parent RDD is used by at most one partition of the child RDD, such as map, filter, or union.
  + A *wide dependency* is where multiple child partitions may depend on a single parent partition, such as a `join` or `groupByKey`.

> Note that the `join` of two RDDs can lead to two *narrow dependencies* if both RDDs are partitioned with the same partitioner, as shown in the following illustration.

* `iterator(p, parentIters)`: Computes the elements of a partition `p` given iterators for its parent partitions.

Examples of narrow and wide dependencies, each big rectangle is an RDD with the smaller grey rectangles representing partitions of the RDD

> Note that the framework mainly uses these operations to orchestrate the execution of Spark applications. The applications are not supposed to use these operations, they should use the transformations and actions that were presented previously.

Backlesson

Mark As CompletedComplete

Next

MapReduce's Manager-Worker Architecture

DAG of Stages in Apache Spark

Ask

[Limitation of MapReduce](#Limitation-of-MapReduce)

[Foundation of Spark](#Foundation-of-Spark)

[Resilient Distributed Datasets (RDD)](#Resilient-Distributed-Datasets-RDD)

[Types of operations performed on RDDs](#Types-of-operations-performed-on-RDDs)

[Transformations](#Transformations)

[Actions](#Actions)

[Creating an RDD](#Creating-an-RDD)

[Architecture of Spark](#Architecture-of-Spark)

[Cluster manager](#Cluster-manager)

[Worker nodes](#Worker-nodes)

[Request broker](#Request-broker)

[Driver](#Driver)

[RDD operations](#RDD-operations)

---


# DAG of Stages in Apache Spark

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

DAG of Stages in Apache Spark

# DAG of Stages in Apache Spark

Learn how Apache Spark provides efficient fault tolerance.

We'll cover the following...

* [DAG scheduler of stages](#DAG-scheduler-of-stages)
  + [Tolerating fault](#Tolerating-fault)
  + [Slow recovery](#Slow-recovery)
* [Fast recovery process](#Fast-recovery-process)
  + [Checkpointing capability](#Checkpointing-capability)

As explained in the [previous lesson](https://www.educative.io/courses/distributed-systems-practitioners/introduction-to-apache-spark), the **driver** examines the lineage graph of the application code and builds a **DAG of stages** to execute.

## DAG scheduler of stages[#](#DAG-scheduler-of-stages)

A DAG of Stages is shown in the following illustration:

Example of a DAG of stages computed from a Spark application

* Each **stage** contains as many pipelined transformations with *narrow dependencies* (one-to-one) as possible.
* The **boundaries of each stage** correspond to operations with *wide dependencies* (one-to-many) that require a data shuffle between partitions or any previously computed partitions that have been persisted. And it can short-circuit the computation of ancestor RDDs.

The driver launches tasks to compute missing partitions from each stage until it has computed the target RDD.

> ![](images/recall.png)**Note**: Spark is based on the concept of **Resilient Distributed Datasets (RDD)**, which is a distributed memory abstraction used to perform in-memory computations on large clusters of machines in a *fault-tolerant* way.

The tasks are assigned to executors based on **data locality**. If a task needs to process a partition in memory on a node, it’s submitted to that node. If a task processes a partition for which the containing RDD provides preferred locations (e.g., an HDFS file), it’s submitted to these nodes.

For wide dependencies that require data shuffling, nodes holding parent partitions materialize intermediate records locally that are later pulled by nodes from the next stage, similar to MapReduce.

> **Note**: This graph is the basic building block for efficient *fault tolerance*.

### Tolerating fault[#](#Tolerating-fault)

When an executor fails for some reason, any tasks running on it are re-scheduled on another executor. Along with this, tasks are scheduled for any parent RDDs required to calculate the RDD of this task. Consequently, wide dependencies are much more inefficient than narrow dependencies when recovering from failures, as shown in the following illustration:

The impact of wide dependencies on recovery from failures, the red cross indicates failure of a task calculating a specific partition of an RDD, the black rectangles represent the partitions of RDDs that need to be recomputed, if not persisted

### Slow recovery[#](#Slow-recovery)

Long lineage graphs can make a recovery very slow since many RDDs will need to be recomputed in a potential failure near the end of the graph.

## Fast recovery process[#](#Fast-recovery-process)

Spark provides a checkpointing capability to make fast recovery.

### Checkpointing capability[#](#Checkpointing-capability)

Checkpointing capability is used to store RDDs from specified tasks to stable storage (e.g., a distributed file system). In this way, checkpointed RDDs can be read from stable storage during recovery, thus only having to rerun smaller portions of the graph. Users can call a `persist()` method to indicate which RDDs need to be stored on the disk.

> **Note**: The checkpoint capability is very useful for interactive applications, where a specific RDD is calculated and used in multiple ways to explore a dataset without having to calculate the whole lineage each time.

Backlesson

Mark As CompletedComplete

Next

Introduction to Apache Spark

Perks of Apache Spark

Ask

[DAG scheduler of stages](#DAG-scheduler-of-stages)

[Tolerating fault](#Tolerating-fault)

[Slow recovery](#Slow-recovery)

[Fast recovery process](#Fast-recovery-process)

[Checkpointing capability](#Checkpointing-capability)

---


# Perks of Apache Spark

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Perks of Apache Spark

# Perks of Apache Spark

Let's explore the benefits provided by Apache Spark.

We'll cover the following...

* [Keeps application running](#Keeps-application-running)
  + [Increasing performance](#Increasing-performance)
    - [Example](#Example)
* [Resilient to failures of the request broker](#Resilient-to-failures-of-the-request-broker)
  + [Zookeeper](#Zookeeper)
* [Ensuring data persistence](#Ensuring-data-persistence)
  + [Commit protocol](#Commit-protocol)

## Keeps application running[#](#Keeps-application-running)

Spark provides **graceful degradation** in cases where memory is not enough so that the application does not fail but keeps running with decreased *performance*.

For instance, Spark can recalculate any partitions on demand when they don’t fit in memory or spill them to disk.

### Increasing performance[#](#Increasing-performance)

*Wide dependencies* cause more data to be exchanged between nodes compared to *narrow dependencies*, so performance is increased significantly by reducing wide dependencies, or the amount of data that needs to be shuffled. One way to do this is by pre-aggregating data, also known as **map-side reduction**.

> **Note**: As explained previously, the map-side reduction is a capability provided in the MapReduce framework through combiners.

#### Example[#](#Example)

The following code performs a word count in two different ways:

* The first one will send multiple records of value 1 for each word across the network
* The second one will send one record for each word containing the number of occurrences.

```python
// word count without pre-aggregation



sparkContext.textFile("hdfs://...")



.flatMap(line => line.split(" "))



.map(word => (word,1))



.groupByKey()



.map((x,y) => (x,sum(y)))



// word count with pre-aggregation



sparkContext.textFile("hdfs://...")



.flatMap(line => line.split(" "))



.map(word => (word,1))



.reduceByKey((x,y)=> (x+y))
```

## Resilient to failures of the request broker[#](#Resilient-to-failures-of-the-request-broker)

We can configure Spark in a way that is resilient to failures of the request broker. This is achieved via **Zookeeper**.

### Zookeeper[#](#Zookeeper)

In Zookeeper, all the managers perform leader election, and one of them is elected as the leader, with the rest remaining in standby mode.

When a new worker node is added to the cluster, it registers with the manager node. If failover occurs, the new manager will contact all previously registered worker nodes to inform them of the change in leadership. So, only the scheduling of new applications is affected during a failover; already running applications are unaffected.

When submitting a job to the Spark cluster, the user can specify through a `--supervise` option that the driver needs to be automatically restarted by the manager if it fails with a non-zero exit code.

## Ensuring data persistence[#](#Ensuring-data-persistence)

Spark supports multiple, different systems for data persistence.

### Commit protocol[#](#Commit-protocol)

Spark has a **commit protocol** that aims to provide exactly-once guarantees on the job’s output under specific conditions. It means that no matter how many times worker nodes fail and tasks are rerun, there will be no duplicate or corrupt data in the final output file if a job completes. This might not be the case for every supported storage system, and it’s achieved differently depending on the available capabilities.

For instance, when using HDFS, each task writes the output data to a unique, temporary file (e.g., `targetDirectory/_temp/part-XXXX_attempt-YYYY`). When the write is complete, the file is moved to the final location (e.g., `targetDirectory/part-XXXX`) using an **atomic** rename operation provided by HDFS. As a result, even if a task is executed multiple times due to failures, the final file will contain its output exactly once.

Furthermore, no matter which execution was completed successfully, the output data will be the same as long as the transformations used were deterministic and idempotent. It is true for any transformations that act solely on the data provided by the previous RDDs using deterministic operations.

> **Note**: However, this is not the case if these transformations use data from other systems that might change between executions or if they use non-deterministic actions (e.g., mathematical calculations based on random number generation). Furthermore, if transformations perform side-effects on external systems that are not idempotent, no guarantee is provided since Spark might execute each side-effect more than once.

Backlesson

Mark As CompletedComplete

Next

DAG of Stages in Apache Spark

Apache Flink

Ask

[Keeps application running](#Keeps-application-running)

[Increasing performance](#Increasing-performance)

[Example](#Example)

[Resilient to failures of the request broker](#Resilient-to-failures-of-the-request-broker)

[Zookeeper](#Zookeeper)

[Ensuring data persistence](#Ensuring-data-persistence)

[Commit protocol](#Commit-protocol)

---


# Apache Flink

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Apache Flink

# Apache Flink

Let's have an introduction to Apache Flink and look into its architecture.

We'll cover the following...

* [Basic constructs in Flink](#Basic-constructs-in-Flink)
  + [Stream](#Stream)
  + [Transformation](#Transformation)
* [Additional Flink constructs](#Additional-Flink-constructs)
* [Flow of data in data processing Flink application](#Flow-of-data-in-data-processing-Flink-application)
* [The architecture of Flink](#The-architecture-of-Flink)
* [Avoid making the Job Manager a single point of failure](#Avoid-making-the-Job-Manager-a-single-point-of-failure)

**Apache Flink** is an open-source stream-processing framework developed by Carbone et al. at Apache Software Foundation to provide a high throughput, low latency data processing engine.

> **Note**: This is the main differentiator between **Flink** and **Spark**. Flink processes incoming data as they arrive, which provides sub-second latency that can go down to single-digit millisecond latency. Spark also provides a streaming engine called Spark Streaming. However, that is running some form of micro-batch processing, where an input data stream is split into batches, which are then processed to generate the final results with the associated latency trade-off.

## Basic constructs in Flink[#](#Basic-constructs-in-Flink)

The basic constructs in Flink are **streams** and **transformations**.

### Stream[#](#Stream)

A **stream** is an unbounded flow of data records.

> **Note**: Flink can also execute batch processing applications, where data is treated as a bounded stream. As a result, the mechanisms described in this section are used in this case also with slight variations.

### Transformation[#](#Transformation)

A **transformation** is an operation that takes one or more streams as input and produces one or more output streams as a result.

Flink provides many different APIs that are used to define these transformations. For example:

* The **ProcessFunction API** is a low-level interface that allows the user to define imperatively what each transformation should do by providing the code that will process each record.
* The **DataStream API** is a high-level interface that allows the user to define declaratively the various transformations by re-using basic operations, such as `map`, `flatMap`, `filter`, `union` etc.

## Additional Flink constructs[#](#Additional-Flink-constructs)

Since streams can be unbounded, the application has to produce some intermediate, periodic results. For this purpose, Flink provides some additional constructs, such as **windows**, **timers**, and **local storage** for stateful operators.

Flink provides a set of high-level operators that specify the windows over which data from the stream will be aggregated. These windows can be time-driven (e.g., time intervals) or data-driven (e.g., number of elements). The timer API allows applications to register callbacks to be executed at specific points in time in the future.

## Flow of data in data processing Flink application[#](#Flow-of-data-in-data-processing-Flink-application)

A data processing application in Flink is represented as a **directed acyclic graph (DAG)**, where nodes represent computing tasks and edges represent data subscriptions between tasks.

> **Note**: Flink also supports **cyclic dataflow graphs**, which can be used for use-cases such as iterative algorithms.

Flink is responsible for translating the logical graph corresponding to the application code to the actual physical graph executed. It includes logical data flow optimizations, such as the fusion of multiple operations to a single task (e.g., a combination of two consecutive filters). It also includes partitioning each task into multiple instances that can be executed in parallel in different compute nodes. This process is shown in the following illustration:

A Flink dataflow graph example

## The architecture of Flink[#](#The-architecture-of-Flink)

The high-level architecture of Flink consists of three main components , as shown in the following illustration:

Created with Fabric.js 3.6.6

1 / 8

Three main components of Flink, Flink client, Job manager, and Task manager

Created with Fabric.js 3.6.6

1 / 8

The Flink client receives the program code, transforms it into a dataflow graph, and submits it to the Job manager

Created with Fabric.js 3.6.6

1 / 8

Job manager has two components, the scheduler, and the Checkpoint coordinator

Created with Fabric.js 3.6.6

1 / 8

Job manager schedules tasks on Task managers track their progress, and coordinate checkpoints and recovery from possible failures of tasks

Created with Fabric.js 3.6.6

1 / 8

Task managers execute one or more tasks

The **Flink client** receives the program code, transforms it into a dataflow graph, and submits it to the Job Manager, which coordinates the distributed execution of the dataflow.

The **Job Manager** schedules tasks on Task Managers, tracking their progress, and coordinating checkpoints and recovery from possible tasks failures.

Each **Task Manager** executes one or more tasks that perform user-specified operators that can produce other streams and report their status to the Job Manager along with heartbeats used for failure detection. When processing unbounded streams, these tasks are supposed to be long-lived. If they fail, the Job Manager is responsible for restarting them.

## Avoid making the Job Manager a single point of failure[#](#Avoid-making-the-Job-Manager-a-single-point-of-failure)

To avoid making the Job Manager a single point of failure multiple instances can run in parallel. One of them will be elected leader via Zookeeper and will be responsible for coordinating the execution of applications. The rest will be waiting to take over in case of a leader failure. As a result, the leader Job Manager stores some critical metadata about every application in Zookeeper so that it’s accessible to newly elected leaders.

Backlesson

Mark As CompletedComplete

Next

Perks of Apache Spark

Time and Watermarks in Flink

Ask

[Basic constructs in Flink](#Basic-constructs-in-Flink)

[Stream](#Stream)

[Transformation](#Transformation)

[Additional Flink constructs](#Additional-Flink-constructs)

[Flow of data in data processing Flink application](#Flow-of-data-in-data-processing-Flink-application)

[The architecture of Flink](#The-architecture-of-Flink)

[Avoid making the Job Manager a single point of failure](#Avoid-making-the-Job-Manager-a-single-point-of-failure)

---


# Time and Watermarks in Flink

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Time and Watermarks in Flink

# Time and Watermarks in Flink

Learn about the concept of time and the use of watermarks in Apache Flink.

We'll cover the following...

* [Processing time](#Processing-time)
* [Event time](#Event-time)
* [Processing time trade-offs](#Processing-time-trade-offs)
* [Event time trade-offs](#Event-time-trade-offs)
* [Tracking progress in event time](#Tracking-progress-in-event-time)
  + [Watermarks](#Watermarks)
    - [Generating watermarks](#Generating-watermarks)
      * [Example](#Example)

As explained in the [previous lesson](https://www.educative.io/courses/distributed-systems-practitioners/apache-flink), time is a crucial element that is commonly used to define boundaries on **unbounded streams**.

Like other stream processing systems, such as MillWheel and The Dataflow Model, Flink supports two main notions of time: **processing time** and **event time**.

> **Note**: Flink has a third notion of time called the **ingestion time** which corresponds to the time an event enters Flink. But this section will focus on event and processing time only.

## Processing time[#](#Processing-time)

**Processing time** refers to the system time of the machine that is executing an operation.

## Event time[#](#Event-time)

**Event time** is the time that each event occurred on its producing device.

> We can use *processing time* or *event time* with some trade-offs, which are following.

## Processing time trade-offs[#](#Processing-time-trade-offs)

When a streaming program runs on *processing time*, all time-based operations (e.g., time windows) will use the system clock of the machines that runs the respective operation. It is the simplest notion of time and requires no coordination between the nodes of the system. It also provides good performance and reliably low latency on the produced results.

However, all this comes at the cost of consistency and non-determinism. The system clocks of different machines will differ, and the various nodes of the system will process data at different rates. As a consequence, different nodes might assign the same event to different windows depending on timing.

## Event time trade-offs[#](#Event-time-trade-offs)

When a streaming program runs on *event time*, all time-based operations will use the event time embedded within the stream records to track time, instead of system clocks. It brings consistency and determinism to the execution of the program since nodes will now have a common mechanism to track the progress of time and assign events to windows.

However, it requires some coordination between the various nodes, as we will see below. It also introduces some additional latency since nodes might have to wait for out of order or late events.

## Tracking progress in event time[#](#Tracking-progress-in-event-time)

The main mechanism to track progress in *event time* in Flink is **watermarks**.

### Watermarks[#](#Watermarks)

**Watermarks** are control records that flow as part of a data stream and carry a timestamp `t`.

A `Watermark(t)` record indicates that event time has reached time `t` in that stream, which means there should be no more elements with a timestamp `t' ≤ t`. Once a watermark reaches an operator, the operator can advance its internal event time clock to the value of the watermark.

#### Generating watermarks[#](#Generating-watermarks)

Watermarks are generated either directly in the data stream source or by a **watermark generator** at the beginning of a Flink pipeline.

The operators later in the pipeline are supposed to use the watermarks for their processing (e.g., to trigger calculation of windows) and then emit them downstream to the next operators.

##### Example[#](#Example)

There are many different strategies for generating watermarks. For example the `BoundedOutOfOrdernessGenerator`, which assumes that the latest elements for a certain timestamp `t` will arrive at most `n` milliseconds after the earliest elements for timestamp `t`. Of course, there could be elements that do not satisfy this condition and arrive after the associated watermark has been emitted and the corresponding windows have been calculated. These are called **late elements**.

Flink provides different ways to deal with *late elements*, such as discarding them or re-triggering the calculation of the associated window.

The following illustration shows the flow of watermarks and the progress of *event time* in a flink pipeline.

Event time & watermarks in Flink

Backlesson

Mark As CompletedComplete

Next

Apache Flink

Failure Recovery in Flink

Ask

[Processing time](#Processing-time)

[Event time](#Event-time)

[Processing time trade-offs](#Processing-time-trade-offs)

[Event time trade-offs](#Event-time-trade-offs)

[Tracking progress in event time](#Tracking-progress-in-event-time)

[Watermarks](#Watermarks)

[Generating watermarks](#Generating-watermarks)

[Example](#Example)

---


# Failure Recovery in Flink

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Failure Recovery in Flink

# Failure Recovery in Flink

Let's explore an algorithm used by Flink to recover from failure andAS the guarantees provided by Flink.

We'll cover the following...

* [Asynchronous Barrier Snapshotting (ABS)](#Asynchronous-Barrier-Snapshotting-ABS)
  + [Working](#Working)
* [Subtle points in the checkpoint algorithm](#Subtle-points-in-the-checkpoint-algorithm)
* [Phases of ABS](#Phases-of-ABS)
* [Storing operator’s state](#Storing-operators-state)
* [Integration of Flink with other systems](#Integration-of-Flink-with-other-systems)
  + [Integration with Kafka](#Integration-with-Kafka)
* [Guarantees provided by Flink](#Guarantees-provided-by-Flink)

As mentioned previously, stream processing applications in Flink are supposed to be long-lived. So there must be an efficient way to recover from failures without repeating a lot of work. For this purpose, Flink periodically checkpoints the operators’ state and the position of the consumed stream to generate this state. In case of a failure, an application can be restarted from the latest checkpoint and continue processing from there.

All this is achieved via an algorithm similar to the Chandy-Lamport algorithm for distributed snapshots, called **Asynchronous Barrier Snapshotting (ABS)**.

## Asynchronous Barrier Snapshotting (ABS)[#](#Asynchronous-Barrier-Snapshotting-ABS)

The ABS algorithm operates slightly differently for **acyclic** and **cyclic** graphs, so we will examine the first case here, which is a bit simpler.

### Working[#](#Working)

The algorithm works in the following way:

* The Job Manager periodically injects some control records in the stream, referred to as **stage barriers**. These records are supposed to divide the stream into stages. At the end of a stage, the set of operator states reflects the whole execution history up to the associated barrier. Thus it can be used for a snapshot.
* When a **source task** receives a barrier, it takes a snapshot of its current state and then broadcasts the barrier to all its outputs.
* When a **non-source task** receives a barrier from one of its inputs, it blocks that input until it has received a barrier from all the inputs. It then takes a snapshot of its current state and broadcasts the barrier to its outputs. Finally, it unblocks its inputs. This blocking guarantees that the checkpoint contains the state after processing all the elements before the barrier and no elements after the barrier.

> **Note**: The snapshot taken while the inputs are blocked are logical , where the actual, physical snapshot is happening asynchronously in the background. One way to achieve this is through [copy-on-write techniques](https://en.wikipedia.org/wiki/Copy-on-write). This is done to reduce the duration of this blocking phase to start processing data again as quickly as possible.

* Once the background copy process is completed, each task acknowledges the checkpoint back to the Job Manager.The checkpoint is considered complete after the job manager receives the acknowledgement from all the tasks and can be used for recovery if a failure happens later. At this point, the Job Manager notifies all the tasks that the checkpoint is complete so that they can perform any cleanup or bookkeeping logic required.

## Subtle points in the checkpoint algorithm[#](#Subtle-points-in-the-checkpoint-algorithm)

There are two subtle points in the checkpoint algorithm and the recovery process.

During recovery, tasks will be reset to the last checkpoint and start processing again from the first element after the checkpoint was taken. It means that any state that might have been produced by elements after the last checkpoint will be essentially discarded so that each element is processed **exactly-once**. However, this raises the following questions:

* How is the state produced after the last checkpoint is discarded in practice if it persisted in the operator’s state?
* What happens to sink tasks that interact with external systems and records that might have been emitted after the last checkpoint in case of a failure?
* What happens with sources that do not support the replay of records?

The answers to all these questions partially rely on a core characteristic of the checkpoint algorithm.

## Phases of ABS[#](#Phases-of-ABS)

The ABS algorithm has a **two-phase commit protocol**.

* In the first phase, the job manager instructes all the tasks to create a checkpoint.
* In the second phase, the job manager informs them that all the tasks successfully created a checkpoint.

## Storing operator’s state[#](#Storing-operators-state)

The state of an operator can be stored in different ways, such as in the operator’s memory, in an embedded key-value store, or in an external datastore.

If that datastore supports **multi-version concurrency control (MVCC)**, then all the updates to the state are stored under a version that corresponds to the next checkpoint. During recovery, updates that were performed after the last checkpoint are automatically ignored since reads will return the version corresponding to the last checkpoint.

If the datastore does not support MVCC, all the state changes are maintained temporarily in local storage as a **write-ahead-log (WAL)**, which will be committed to the datastore during the second phase of the checkpoint protocol.

## Integration of Flink with other systems[#](#Integration-of-Flink-with-other-systems)

Flink can also integrate with various other systems such as **Kafka, RabbitMQ,** etc., to retrieve input data from (sources) or send output data to (sinks). Each one of them provides different capabilities…

### Integration with Kafka[#](#Integration-with-Kafka)

Kafka provides an offset-based interface, which makes it very easy to replay data records in case of recovery from a failure. A sink task keeps track of the offset of each checkpoint and starts reading from that offset during recovery. However, message queues do not provide this interface, so Flink uses alternative methods to provide the same guarantees.

> **Note**: In the case of RabbitMQ, messages are acknowledged and removed from the queue only after the associated checkpoint is complete, during the second phase of the protocol

Similarly, a sink needs to coordinate with the checkpoint protocol to provide exactly-once guarantee. Kafka is a system that can support this through the use of its **transactional client**.

When the sink creates a checkpoint, the `flush()` operation is called part of the checkpoint. After the checkpoint completion notification is received from the Job Manager in all operators, the sink calls Kafka’s `commitTransaction` method.

> Note: Flink provides an abstract class called `TwoPhaseCommitSinkFunction` that provides the basic methods that need to be implemented by a sink that wants to provide these guarantees (i.e. `beginTransaction`, `preCommit`, `commit`, `abort`).

## Guarantees provided by Flink[#](#Guarantees-provided-by-Flink)

* Flink provides exactly-once processing semantics even across failures depending on the types of sources and sinks used.
* The user can also optionally downgrade to at-least-once processing semantics, which can provide increased performance.
* The exactly- once guarantees apply to stream records and local state produced using the Flink APIs. If an operator performs additional side effects on systems external to Flink, then no guarantees are provided for them.
* Flink does not provide ordering guarantees after any form of repartitioning or broadcasting. And the responsibility of dealing with out-of-order records is left to the operator implementation.

Now that you’ve gone through the important concepts of distributed data processing systems, test your knowledge by interacting with the AI widget below. The AI will ask a total of six questions focused on the workings of MapReduce, Apache Spark, and Apache Flink. To get started, say hello to Edward in the widget below, and it will lead the way.

Want to know the correct answer?

Powered by AI

14 Prompts Remaining

Prompt AI WidgetOur tool is designed to help you to understand concepts and ask any follow up questions. Ask a question to get started.

Backlesson

Mark As CompletedComplete

Next

Time and Watermarks in Flink

Quiz on Distributed Data Processing Systems

Ask

[Asynchronous Barrier Snapshotting (ABS)](#Asynchronous-Barrier-Snapshotting-ABS)

[Working](#Working)

[Subtle points in the checkpoint algorithm](#Subtle-points-in-the-checkpoint-algorithm)

[Phases of ABS](#Phases-of-ABS)

[Storing operator’s state](#Storing-operators-state)

[Integration of Flink with other systems](#Integration-of-Flink-with-other-systems)

[Integration with Kafka](#Integration-with-Kafka)

[Guarantees provided by Flink](#Guarantees-provided-by-Flink)

---


# Quiz on Distributed Data Processing Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Quiz on Distributed Data Processing Systems

# Quiz on Distributed Data Processing Systems

We'll cover the following...

In the following quiz, you will be tested on concepts you learned in this chapter.

Technical Quiz

1.

Which of the following statements is true for batch processing systems?

A.

Groups individual data items into groups that are processed together

B.

Receives and process data continuously as a stream of individual data items

---

1 / 4

Submit Answer

Backlesson

Mark As CompletedComplete

Next

Failure Recovery in Flink

Introduction

Ask

---


# Introduction

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Introduction

# Introduction

Let's see which practices and patterns we will be looking into in the next chapters.

We'll cover the following...

We will cover common **practices and patterns** used when building and operating distributed systems in the next few chapters. These are not supposed to be exact prescriptions, but they can help you identify some of the basic approaches available to you and the associated trade-offs.

It goes without saying that there are so many practices and patterns that we would never be able to cover them all. As a result, the goal is to cover some of the most fundamental and valuable ones, shown in the following illustration.

Patterns and practices

We will study each of the above practices and pattens one by one in the next chapters.

Backlesson

CompletedCompleted

Next

Quiz on Distributed Data Processing Systems

Creating and Parsing Data

Ask

---


# Creating and Parsing Data

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Creating and Parsing Data

# Creating and Parsing Data

Let's explore the options for creating and parsing the data sent through the network.

We'll cover the following...

* [Serialization and deserialization](#Serialization-and-deserialization)
* [Serializing and deserializing data](#Serializing-and-deserializing-data)
  + [Native support](#Native-support)
    - [Advantages and disadvantages](#Advantages-and-disadvantages)
  + [Libraries](#Libraries)
    - [Advantages and disadvantages](#Advantages-and-disadvantages)
  + [Interface definition languages (IDL)](#Interface-definition-languages-IDL)
    - [Advantages and disadvantages](#Advantages-and-disadvantages)

One of the main differentiating characteristics of distributed systems with other systems is that the various nodes need to exchange data across the network boundary. In this chapter, we will examine how we can achieve this and the trade-offs of each approach.

## Serialization and deserialization[#](#Serialization-and-deserialization)

Every node needs a way to transform data that resides in memory into a format that can be transmitted over the network, and it also needs a way to translate data received from the network back to the appropriate in-memory representation. These processes are called **serialization** and **deserialization**, respectively. The following illustration shows this process:

Serialization and deserialization

> **Note**: Serialization are also used to transform data in a format that’s suitable for **storage**, not only communication.

## Serializing and deserializing data[#](#Serializing-and-deserializing-data)

The various nodes of the system need to agree on a common way to serialize and deserialize data. Otherwise, they will not be able to translate the data they send to each other. There are various options available for this purpose. We will discuss three approaches in this lesson:

### Native support[#](#Native-support)

Some languages provide native support for serialization, such as Java and Python via its `pickle` module.

#### Advantages and disadvantages[#](#Advantages-and-disadvantages)

* The main benefit of this option is **convenience** since there is very little extra code needed to serialize and deserialize an object. However, this comes at the cost of **maintainability**, **security**, and **interoperability**.
* Given the transparent nature of how these serialization methods work, it becomes hard to keep the format stable since it can be affected even by small changes to an object that do not affect the data contained in it (e.g., implementing a new interface).
* Furthermore, some of these mechanisms are not very secure since they indirectly allow a remote data sender to initialize any objects they want, thus introducing the risk of remote code execution.
* Last but not least, most of these methods are available only in specific languages, which means systems developed in different programming languages will not be able to communicate.

> **Note**: Some third-party libraries operate in a similar way using reflection or bytecode manipulation, such as [Kryo](https://github.com/EsotericSoftware/kryo). These libraries tend to be subject to the same trade-offs.

### Libraries[#](#Libraries)

Another option is a set of libraries that serialize an in-memory object based on instructions provided by the application. These instructions can be imperative or declarative, i.e., annotating the fields to be serialized instead of explicitly calling operations for every field.

An example of such a library is [Jackson](https://github.com/FasterXML/jackson), which supports many different formats, such as JSON and XML.

#### Advantages and disadvantages[#](#Advantages-and-disadvantages)

* The main benefit of this approach is the ability to interoperate between different languages.
* Most of these libraries also have rather simple rules on what gets serialized, so it’s easier to preserve backwards compatibility when evolving some data, i.e., introducing new optional fields.
* They also tend to be a bit more secure. As they reduce the exploitation surface by reducing the number of types that can be instantiated during deserialization, i.e. only the ones that have been annotated for serialization and thus implicitly whitelisted.
* However, sometimes, they can create additional development efforts since the exact serialization mapping needs to be defined on every application.

### Interface definition languages (IDL)[#](#Interface-definition-languages-IDL)

Interface definition languages (IDL) are specification languages used to define the schema of a data type in a language-independent way.

#### Advantages and disadvantages[#](#Advantages-and-disadvantages)

* These definitions can dynamically generate code in different languages that will perform serialization and deserialization when included in the application. It allows applications built in different programming languages to interoperate, depending on the languages supported by the IDL. In addition, each IDL allows for different forms of evolution of the underlying data types.
* They also reduce duplicate development effort, but they require adjusting build processes so that they can integrate with the code generation mechanisms. Some examples of IDLs are [Protocol Buffers](https://github.com/protocolbuffers/protobuf), [Avro](https://avro.apache.org/), and [Thrift](https://thrift.apache.org/).

The difference between the library and the interface definition languages (IDL) approach, using Jackson and Protocol Buffers, is shown in the following illustration:

Jackson and Protocol Buffers

Backlesson

Mark As CompletedComplete

Next

Introduction

Transfer of Data

Ask

[Serialization and deserialization](#Serialization-and-deserialization)

[Serializing and deserializing data](#Serializing-and-deserializing-data)

[Native support](#Native-support)

[Advantages and disadvantages](#Advantages-and-disadvantages)

[Libraries](#Libraries)

[Advantages and disadvantages](#Advantages-and-disadvantages)

[Interface definition languages (IDL)](#Interface-definition-languages-IDL)

[Advantages and disadvantages](#Advantages-and-disadvantages)

---


# Transfer of Data

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Transfer of Data

# Transfer of Data

Learn about the ways data is transferred over the network and its associated trade-offs.

We'll cover the following...

* [Synchronous and asynchronous communication](#Synchronous-and-asynchronous-communication)
  + [Example](#Example)
* [Implementing synchronous and asynchronous communication](#Implementing-synchronous-and-asynchronous-communication)

In the previous lesson we studied the options for creating and parsing the data sent through the network. However, the main ways this data is sent and received and the associated trade-offs remain unanswered.

The above question does not refer to the underlying transfer protocols that are used, such as Ethernet, IP, TCP, UDP, etc. Instead, it refers to the two basic, high-level forms of communication, **synchronous** and **asynchronous** communication.

## Synchronous and asynchronous communication[#](#Synchronous-and-asynchronous-communication)

If node A is communicating *synchronously* with node B, node A will wait until it has received a response from node B before proceeding with subsequent tasks.

If node A is communicating *asynchronously* instead, this means that it does not have to wait until that request is complete; it can proceed and perform other tasks at the same time.

The Following illustration shows the difference between synchronous and asynchronous communication:

Synchronous and asynchronous communication

### Example[#](#Example)

**Synchronous** communication is typically used in cases where node A needs to retrieve some data to execute the next task, or it needs to be sure a side-effect has been performed successfully on node B’s system before proceeding.

**Asynchronous** communication is preferred in cases where the operation performed in node B can be executed independently without blocking other operations from making progress.

For example, an e-commerce system might need to know that a payment was performed successfully before dispatching an item, thus using synchronous communication. However, after dispatching the order, the process that sends the appropriate notification e-mail to the customer can be triggered asynchronously.

## Implementing synchronous and asynchronous communication[#](#Implementing-synchronous-and-asynchronous-communication)

Synchronous communication is usually implemented on top of the existing protocols, such as using HTTP to transmit data in JSON or some other serialization formats (e.g., protocol buffers)…

In the case of asynchronous communication between two nodes, there is usually a need to store incoming requests until they are processed persistently. This is needed so that requests are not lost even if the recipient node fails for some reason.

> **Note**: This is not necessarily needed in synchronous communication because if the recipient crashes before processing a request, the sender will notice at some point, and it can retry the request. Even when using asynchronous communication, there can be cases where losing requests is not a big problem. For example, the autocomplete functionality of a search engine can be done asynchronously in the background, and losing some requests will lead to fewer suggestions to the user so that it might be acceptable.

These requests can be stored in an intermediate datastore to prevent loss in case of failures. The datastores that are typically used for this purpose belong in two main categories:

* Message queues
* Event logs

> We will discuss these categories in detail in the [next](https://www.educative.io/courses/distributed-systems-practitioners/datastores-for-asynchronous-communication) lesson.

Backlesson

Mark As CompletedComplete

Next

Creating and Parsing Data

Datastores for Asynchronous Communication

Ask

[Synchronous and asynchronous communication](#Synchronous-and-asynchronous-communication)

[Example](#Example)

[Implementing synchronous and asynchronous communication](#Implementing-synchronous-and-asynchronous-communication)

---


# Datastores for Asynchronous Communication

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Datastores for Asynchronous Communication

# Datastores for Asynchronous Communication

Discover the datastores we can use for asynchronous communication.

We'll cover the following...

* [Message Queues](#Message-Queues)
  + [Coping with failed consumers](#Coping-with-failed-consumers)
* [Event log](#Event-log)

In the previous lesson we learned that to achieve asynchronous communication, we need to store requests in datastores, and these datastores belong to two main categories: **message queues** and **event logs**.

## Message Queues[#](#Message-Queues)

Some commonly used message queues are [ActiveMQ](http://activemq.apache.org), [RabbitMQ](https://www.rabbitmq.com), and [Amazon SQS](https://aws.amazon.com/sqs).

A message queue usually operates with **first-in, first-out (FIFO) semantics**. This means that messages, in general, are added to the tail of the queue and removed from the head.

> **Note**: Multiple producers can send messages to the queue, and multiple consumers can receive messages and process them concurrently.

Depending on how a message queue is configured, messages can be deleted in one of the following two cases.

* As soon as they are delivered to a consumer.
* Only after a consumer has explicitly acknowledged, it has successfully processed a message.

The former essentially provides **at-most-once** guarantees since a consumer might fail after receiving a message but before acknowledging it. The latter can provide **at-least-once** semantics since at least a single consumer must have processed a message before it is removed from the queue.

### Coping with failed consumers[#](#Coping-with-failed-consumers)

Most message queues contain a **timeout** logic on unacknowledged messages to cope with failed consumers ensuring **liveness**.

> **Note**: For example, Amazon SQS achieves that using a per-message visibility timeout. At the same time ActiveMQ and RabbitMQ rely on a connection to timeout to redeliver all the unacknowledged messages of this connection.

This means that unacknowledged messages are being put back to the queue and redelivered to a new consumer. Consequently, there are cases where a message might be delivered more than once to multiple consumers. The application is responsible for converting the at-least-once delivery semantics to **exactly-once** processing semantics. As we have learned already, a typical way to achieve this is by associating every operation with a unique identifier that is used to deduplicate operations originating from the same message.

> **Note**: The side-effects from the operation and the storage of the unique identifier must be done atomically to guarantee exactly-once processing. A simple way to do this is to store both in the same datastore using a transaction.

The following illustration shows a practical example of exactly-once processing through deduplication:

Example of exactly-once processing through deduplication

## Event log[#](#Event-log)

An **event log** provides a slightly different abstraction than a message queue. Messages are still inserted by producers at the tail of the log and stored in an ordered fashion. However, the consumers are free to select the point of the log they want to consume messages from, which is not necessarily the head.

Messages are typically associated with an index that consumers can use to declare where they want to consume from.

Another difference with message queues is that the log is typically immutable, so messages are not removed after they are processed. Instead, a **garbage collection** runs periodically, which removes old messages from the head of the log. The consumers are responsible for keeping track of an offset indicating the part of the log they have already consumed in order to avoid processing the same message twice, thus achieving exactly-once processing semantics. This offset plays the role of the unique identifier for each message similarly as described previously.

Some examples of event logs are [Apache Kafka](https://kafka.apache.org), [Amazon Kinesis](https://aws.amazon.com/kinesis), and [Azure Event Hubs](https://azure.microsoft.com/services/event-hubs).

Backlesson

Mark As CompletedComplete

Next

Transfer of Data

Communication Models

Ask

[Message Queues](#Message-Queues)

[Coping with failed consumers](#Coping-with-failed-consumers)

[Event log](#Event-log)

---


# Communication Models

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Communication Models

# Communication Models

Explore the communication models for asynchronous communication.

We'll cover the following...

* [Communication models](#Communication-models)
  + [The point-to-point model](#The-point-to-point-model)
  + [The publish-subscribe model](#The-publish-subscribe-model)
* [Implementing point-to-point and publish-subscribe models](#Implementing-point-to-point-and-publish-subscribe-models)
  + [Using message queue](#Using-message-queue)
  + [Using event log](#Using-event-log)

## Communication models[#](#Communication-models)

Message queues and event logs can enable two different forms of communication, known as **point-to-point** and **publish-subscribe**.

### The point-to-point model[#](#The-point-to-point-model)

The **point-to-point** model is used when we need to connect only two applications.

> **Note**: Point-to-point refers to the number of applications, not the actual servers. Every application on each side might consist of multiple servers that produce and consume messages concurrently.

### The publish-subscribe model[#](#The-publish-subscribe-model)

The **publish-subscribe** model is used when more than one application might be interested in the messages sent by a single application.

For example, suppose a customer made an order might be needed by an application sending recommendations for similar products, an application that sends the associated invoices, and an application that calculates loyalty points for the customer.

Using a publish-subscribe model, the application handling the order can send a message about this order to all the applications that need to know about it, sometimes without even knowing which these applications are.

## Implementing point-to-point and publish-subscribe models[#](#Implementing-point-to-point-and-publish-subscribe-models)

These two models of communication are implemented slightly differently depending on whether an event log or a message queue is used. This difference is due to the fact that the consumption of messages behaves differently in each system:

### Using message queue[#](#Using-message-queue)

Point-to-point communication is pretty straightforward when using a message queue. Both applications are connected to a single queue, where messages are produced and consumed.

In the publish-subscribe model, the producer application can create and manage one queue, and every consumer application can create its own queue. There also needs to be a background process that receives messages from the producer’s queue and forwards them to the consumers’ queues.

> **Note**: Some systems might provide facilities that provide this functionality out of the box. For example, this is achieved in ActiveMQ via a bridge and in Amazon SQS via a separate AWS service, called Amazon Simple Notification Service (SNS).

Suppose you add a new consumer application that needs the same messages as existing consumers. Using a message queue in a publish-subscribe setup, what change is necessary to ensure it receives messages without modifying the producer? Provide your answer in the widget given below.

Want to know the correct answer?

Adding a New Consumer in Publish-Subscribe Systems

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

### Using event log[#](#Using-event-log)

When using an event log, both models of communication can be implemented in the same way. The producer application writes messages to the log, and multiple consumer applications can be consumed from the log concurrently the same messages maintaining independent offsets.

This difference in implementing these models using the message queue and the event log is shown in the following illustration:

Implementation of point-to-point model

Implementation of publish-subscribe model

Backlesson

Mark As CompletedComplete

Next

Datastores for Asynchronous Communication

Coordination Patterns

Ask

[Communication models](#Communication-models)

[The point-to-point model](#The-point-to-point-model)

[The publish-subscribe model](#The-publish-subscribe-model)

[Implementing point-to-point and publish-subscribe models](#Implementing-point-to-point-and-publish-subscribe-models)

[Using message queue](#Using-message-queue)

[Using event log](#Using-event-log)

---


# Coordination Patterns

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Coordination Patterns

# Coordination Patterns

Learn about the two basic approaches used to coordinate different systems.

We'll cover the following...

* [Orchestration](#Orchestration)
* [Choreography](#Choreography)
* [The behavior of coordination patterns](#The-behavior-of-coordination-patterns)
  + [A function with no side-effects](#A-function-with-no-side-effects)
  + [A function with side-effects](#A-function-with-side-effects)
* [Ensuring atomicity](#Ensuring-atomicity)

In many cases, a business function is performed by many different systems that cooperate with each other to perform some part of the overall function. For example, displaying a product page might require combining functionality from different systems, such as an advertising system, a recommendation system, a pricing system, etc.

The previous chapter examined the basic ways in which two different systems can communicate. Now we will explore the two basic approaches that can be used to coordinate different systems to perform a common goal: **orchestration** and **choreography**.

## Orchestration[#](#Orchestration)

In **orchestration**, a single, central system is responsible for coordinating the execution of the various other systems, thus resembling a star topology, as shown in the following illustration. That central system is referred to as the **orchestrator**. It needs to know about all the other systems and their capabilities. But these systems can be unaware of each other.

Orchestration

## Choreography[#](#Choreography)

In **choreography**, systems coordinate with each other without the need for an external coordinator. They are essentially placed in a chain, where each system is aware of the previous and the next system in the topology. A request is successively passed through the chain from each system to the next one. We can see this process in the following illustration:

Choreography

**Note**: The communication link between two systems can be of any of the two forms described in the previous section. The systems can either communicate **synchronously** (i.e., using RPC calls) or **asynchronously** (i.e., via an intermediary message queue).

> Each option is subject to different trade-offs, some of which we will discuss in the next chapters.

## The behavior of coordination patterns[#](#The-behavior-of-coordination-patterns)

The patterns mentioned above will behave differently depending on whether the function performed has side-effects or not.

### A function with no side-effects[#](#A-function-with-no-side-effects)

Displaying a product page is most likely a function that does not have side effects. This means that partial failures can be treated simply by retrying any failed requests until they all succeed. Alternatively, if some requests continuously fail, they are abandoned, and the original request is forced to fail.

### A function with side-effects[#](#A-function-with-side-effects)

Processing a customer order is most likely an operation with side effects, which might need to be performed **atomically**. It’s probably undesirable to charge a customer for an order that cannot be processed or send an order to a customer who cannot pay.

## Ensuring atomicity[#](#Ensuring-atomicity)

Each of the patterns mentioned above needs to ensure *atomicity*.

* One way to achieve this would be via a protocol like a two-phase commit.
* An alternative would be to use the concept of saga transactions [described previously in the course](https://www.educative.io/courses/distributed-systems-practitioners/long-lived-transactions-and-sagas).

The first approach would fit better in the orchestrator pattern where the orchestrator plays the role of the coordinator of the two-phase commit protocol, while the second approach could be used in both patterns.

Backlesson

Mark As CompletedComplete

Next

Communication Models

Data Synchronisation

Ask

[Orchestration](#Orchestration)

[Choreography](#Choreography)

[The behavior of coordination patterns](#The-behavior-of-coordination-patterns)

[A function with no side-effects](#A-function-with-no-side-effects)

[A function with side-effects](#A-function-with-side-effects)

[Ensuring atomicity](#Ensuring-atomicity)

---


# Data Synchronisation

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Data Synchronisation

# Data Synchronisation

Learn why we need to store data in multiple places and what is the approach to synchronize data.

We'll cover the following...

* [The need to store data in multiple places](#The-need-to-store-data-in-multiple-places)
* [Synchronizing data using dual writes](#Synchronizing-data-using-dual-writes)
  + [Problems](#Problems)
  + [Solution](#Solution)

## The need to store data in multiple places[#](#The-need-to-store-data-in-multiple-places)

There are cases where we need to store the same data in multiple places and potentially different forms. These are also referred to as [materialized views](https://en.wikipedia.org/wiki/Materialized_view). Below are some examples of such cases:

* Data that resides in a persistent datastore also needs to be cached in a separate in-memory store so that read operations can be processed from the cache with lower latency. Write operations need to update both the persistent datastore and the in-memory store.
* Data stored in a distributed key-value store must also be stored in a separate datastore that provides efficient full-text search, such as [ElasticSearch](https://github.com/elastic/elasticsearch) or [Solr](https://github.com/apache/lucene-solr). Depending on the form of read operations, the appropriate datastore can be used for optimal performance.
* Data stored in a relational database also needs to be stored in a graph database so that graph queries can be performed in a more efficient way.

> **Note**: Given that the data resides in multiple places, we need a mechanism that keeps them in **sync**. This chapter will examine some of the approaches available for this purpose and the associated trade-offs.

## Synchronizing data using dual writes[#](#Synchronizing-data-using-dual-writes)

One approach is to perform writes to all the associated datastores from a single application that receives update operations. This approach is sometimes referred to as **dual writes**. Typically, writes to the associated data stores are performed synchronously to update data in all the locations before responding to the client with a confirmation that the update operation was successful.

Dual writes

### Problems[#](#Problems)

One drawback of this approach is how the system handles partial failures and their impact on *atomicity*. If the application updates the first datastore successfully, but the request to update the second datastore fails, then atomicity is violated. Due to this the overall system becomes inconsistent. It’s also unclear what the response to the client should be in this case since data has been updated, but only in some places.

However, even if we assume that there are no partial failures, there is another pitfall in how concurrent writers handle the race conditions and their impact on **isolation**. Let’s assume two writers submit an update operation for the same item. The application receives them and attempts to update both datastores, but the associated requests are re-ordered, as shown in the following illustration:

Isolation issues with dual writes

In the above illustration, the first datastore contains data from the first request, while the second datastore contains data from the second request. This also leaves the overall system in an inconsistent state.

### Solution[#](#Solution)

An obvious solution to mitigate these issues is to introduce a **distributed transaction protocol** that provides the necessary *atomicity* & *isolation*, such as a combination of **two-phase commit** and **two-phase locking**. To be able to do this, the underlying datastores need to provide support for this. Even in that case, this protocol will have some *performance* and *availability* implications, as explained in the previous chapters.

Backlesson

Mark As CompletedComplete

Next

Coordination Patterns

Event Sourcing

Ask

[The need to store data in multiple places](#The-need-to-store-data-in-multiple-places)

[Synchronizing data using dual writes](#Synchronizing-data-using-dual-writes)

[Problems](#Problems)

[Solution](#Solution)

---


# Event Sourcing

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Event Sourcing

# Event Sourcing

Learn how data is synchronized using the event sourcing approach.

We'll cover the following...

* [Synchronizing data using event sourcing](#Synchronizing-data-using-event-sourcing)
  + [Mitigating the problems of dual writes](#Mitigating-the-problems-of-dual-writes)
  + [Caveat in event sourcing approach](#Caveat-in-event-sourcing-approach)
  + [Problems](#Problems)

## Synchronizing data using event sourcing[#](#Synchronizing-data-using-event-sourcing)

**Event sourcing** is another approach for data synchronization. It writes any update operations to an append-only event log. The interested applications consume events from this log and store the associated data in their preferred datastore. The current state of the system can be derived simply by consuming all the events from the beginning of the log.

However, applications typically save periodical **snapshots** (also known as **checkpoints**) of the state to avoid having to re-consume the whole log in case of failures. In this case, an application that recovers from a failure only needs to replay the events of the log after the latest snapshot.

Event sourcing

### Mitigating the problems of dual writes[#](#Mitigating-the-problems-of-dual-writes)

Event sourcing approach does not violate **atomicity**, which means there is no need for an **atomic commit protocol**. The reason is every application is consuming the log independently, and they will eventually process all the events successfully, restarting from the last consumed event in case of a temporary failure.

The **isolation** problem in the dual writes approach is also mitigated since the applications will be consuming all the events in the same order.

### Caveat in event sourcing approach[#](#Caveat-in-event-sourcing-approach)

There is a small caveat in the event sourcing approach: applications might be consuming the events from the log at different speeds, which means an event will not be reflected instantly on all the applications. This phenomenon can be handled at the application level. For example, if an item is unavailable in the cache, the application can query the other datastores.

A different manifestation of this problem could be a successfully indexed item that was not stored in the authoritative datastore yet, leading to a dangling pointer. This could also be mitigated at the application level by identifying and discarding these items instead of displaying broken links. If no such technique can be applied at the application level, a concurrency control protocol could be used, e.g., a locking protocol with the associated performance and availability costs.

### Problems[#](#Problems)

Some kinds of applications need to perform update operations that require an up-to-date view of the data. The simplest example is a **conditional update operation**, it creates a user if no user with the same username exists already.

> **Note**: The Conditional update operation is also known as a [compare-and-set (CAS) operation](https://en.wikipedia.org/wiki/Compare-and-swap).

It is not easily achievable when using *event sourcing* because the applications consume the log asynchronously, so they are only **eventually consistent**.

> In the [next](https://www.educative.io/courses/distributed-systems-practitioners/change-data-capture-cdc) lesson, we will learn another approach that solves this problem.

Backlesson

Mark As CompletedComplete

Next

Data Synchronisation

Change Data Capture (CDC)

Ask

[Synchronizing data using event sourcing](#Synchronizing-data-using-event-sourcing)

[Mitigating the problems of dual writes](#Mitigating-the-problems-of-dual-writes)

[Caveat in event sourcing approach](#Caveat-in-event-sourcing-approach)

[Problems](#Problems)

---


# Change Data Capture (CDC)

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Change Data Capture (CDC)

# Change Data Capture (CDC)

Learn how CDC solves the problem of event sourcing.

We'll cover the following...

* [Data synchronization using change data capture (CDC)](#Data-synchronization-using-change-data-capture-CDC)
  + [Mitigating the problem of event sourcing](#Mitigating-the-problem-of-event-sourcing)

## Data synchronization using change data capture (CDC)[#](#Data-synchronization-using-change-data-capture-CDC)

Change data capture (CDC) is another approach used for data synchronization. It solves the asynchronous consumption of log of event sourcing, as discussed in the previous lesson.

Change data capture

### Mitigating the problem of event sourcing[#](#Mitigating-the-problem-of-event-sourcing)

In the CDC approach, The application selects a datastore as the authoritative source of data, where all update operations are performed. It then creates an event log from this datastore that is consumed by all the remaining operations the same way as in event sourcing. This primary datastore needs to provide the necessary transactional semantics and a way to monitor changes in the underlying data to produce the event log. Relational databases are usually a good fit for this since most of them provide strong transactional guarantees. In addition, they internally use a **write- ahead-log (WAL)** that imposes an order on the performed operations and can feed an order event log.

> **Note**: An example of such tool is [Debezium](https://debezium.io).

As a result, clients can perform conditional updates on the current state, and the remaining applications can apply these operations independently at their datastores.

Backlesson

Mark As CompletedComplete

Next

Event Sourcing

Sharing Problems and their Solution

Ask

[Data synchronization using change data capture (CDC)](#Data-synchronization-using-change-data-capture-CDC)

[Mitigating the problem of event sourcing](#Mitigating-the-problem-of-event-sourcing)

---


# Benefits and Drawbacks

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Benefits and Drawbacks

# Benefits and Drawbacks

Learn about the benefits and drawbacks of shared-nothing architecture.

We'll cover the following...

* [Benefits](#Benefits)
  + [Scalability](#Scalability)
  + [Availability](#Availability)
  + [Supporting the problems that are amenable to partitioning](#Supporting-the-problems-that-are-amenable-to-partitioning)
    - [Concurrency control](#Concurrency-control)
* [Drawback of a shared-nothing architecture](#Drawback-of-a-shared-nothing-architecture)

## Benefits[#](#Benefits)

The shared-nothing architecture provides many benefits from a **performance** and **fault-tolerance** perspective. It provides scalability and availability guarantees.

### Scalability[#](#Scalability)

All layers of the applications can be incrementally scaled out or in depending on the load.

> **Note**: Scalability is easier and quicker to achieve in the **stateless** components since it requires less data transfer.

### Availability[#](#Availability)

The system is resilient to single-node and multi-node failures.

More specifically, these two different forms of failure impact the **stateless** parts of the system in a similar way. The size of the impact is just different. For example, the remaining nodes might need to handle a bigger load, or more servers might need to be provisioned.

For the **stateful** parts of the architecture, single and multi-node failures have slightly different behaviors.

* Single-node failures are a lot easier to handle since each partition can use a consensus-based technique for replication which can remain fully functional as long as a majority of nodes is healthy.
* However, multi-node failures can affect a majority, thus making a partition unavailable

> **Note**: Even in this case, the good thing is only this partition will be unavailable, and the rest of the system’s data will still be available.

### Supporting the problems that are amenable to partitioning[#](#Supporting-the-problems-that-are-amenable-to-partitioning)

Shared-nothing architecture tends to be a good fit for problems that are amenable to fine-grained partitioning.

Some examples of problems in this space are:

* Managing user sessions
* Managing the products of a catalog

In both cases, data can easily be partitioned in a way where data access operations will need to access a single data item.

* Sessions can be assigned a unique identifier, and this attribute can partition them.
* Products can be partitioned according to a similar product identifier.

If sessions and products are mostly retrieved and updated by their identifier, they can be done efficiently by querying only the nodes with the associated data.

#### Concurrency control[#](#Concurrency-control)

There is also space for some form of limited **concurrency control** in the scope of a partition.

For cases where single-item access is the norm, a common technique is using the **optimistic concurrency control** to reduce overhead and contention. It is be achieved by including a version attribute on every data item. Every writer performs a read before a write to find the current version and then includes the current version in the update as a condition to be satisfied for it to be completed.

Of course, this requires the corresponding datastore to provide support for conditional updates. If a concurrent writer has updated the same item in the meanwhile, the first writer will have to abort and restart by performing a new read to determine whether its initial write should still apply and, if so, retry it.

## Drawback of a shared-nothing architecture[#](#Drawback-of-a-shared-nothing-architecture)

Along with the benefits described above, shared-nothing architecture has some drawbacks also…

The main drawback is **reduced flexibility**. If the application needs access to new data access patterns efficiently, it might be hard to provide it given the system’s data have been partitioned in a specific way.

For example, attempting to query by a secondary attribute that is not the partitioning key might require access to all the nodes of the system. This reduced flexibility might also manifest in a lack of strong transactional semantics.

Applications that need to perform reads of multiple items with strong isolation or write multiple items in a single atomic transaction might not do this under this form of architecture. It might only be possible at the cost of excessive additional overhead.

Backlesson

Mark As CompletedComplete

Next

Sharing Problems and their Solution

Leases in Distributed Systems

Ask

[Benefits](#Benefits)

[Scalability](#Scalability)

[Availability](#Availability)

[Supporting the problems that are amenable to partitioning](#Supporting-the-problems-that-are-amenable-to-partitioning)

[Concurrency control](#Concurrency-control)

[Drawback of a shared-nothing architecture](#Drawback-of-a-shared-nothing-architecture)

---


# Leases in Distributed Systems

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Leases in Distributed Systems

# Leases in Distributed Systems

Learn about the issues with locks and leases in distributed systems.

We'll cover the following...

* [Recalling concurrency](#Recalling-concurrency)
  + [Solution](#Solution)
* [Locks](#Locks)
* [Complication of locking in distributed systems](#Complication-of-locking-in-distributed-systems)
* [Using leases instead of locks](#Using-leases-instead-of-locks)
* [Safety risks in lease](#Safety-risks-in-lease)

## Recalling concurrency[#](#Recalling-concurrency)

In the introductory chapters of the course we learned that concurrency is one of the factors that contribute significantly to the complexity of distributed systems.

A mechanism is needed to ensure that all the various components of a distributed system running concurrently do so in a safe way and does not bring the overall system to an **inconsistent state**.

### Leader election problem

We have already discussed the **leader election** problem, where the system needs to ensure only one node in the system can perform the leader duties at any point in time.

![](images/image_1764835033.4303792.svg)![](images/5503006454972416.svg)

### Solution[#](#Solution)

Amongst the available techniques, **locking** is the simplest solution and one that is used commonly. However, locking techniques are subject to different failure modes when applied in a distributed system.

This chapter will cover common pitfalls in locks and address them to use locking safely in a distributed system.

## Locks[#](#Locks)

The main property derived from the use of locks is **mutual exclusion**. Multiple concurrent actors can be sure that only one will perform a critical operation at a time.

All actors follow the same sequence of operations, first they acquire the lock, perform that critical operation, and then release the lock so that other workers can proceed.

![](images/image_1764835033.6261067.svg)![](images/5177996288851968.svg)

This sequence of operation is usually simple to implement when all actors are running inside the same application sharing a single memory address space and the same lifecycle. However, doing the same in a distributed system is much more complicated, mostly due to the potential of partial failures.

## Complication of locking in distributed systems[#](#Complication-of-locking-in-distributed-systems)

The main complication of locking in a distributed system is that the various system nodes can fail independently. As a result, a node that is currently holding a lock might fail before it releases the lock. This would bring the system to a halt until that lock is released via some other means (i.e., via an operator), thus reducing *availability* significantly. A timeout mechanism can be used to cope with this issue.

## Using leases instead of locks[#](#Using-leases-instead-of-locks)

A lease is essentially a lock with an **expiry timeout,** after which the lock is automatically released by the system responsible for managing the locks. By using leases instead of locks, the system can automatically recover from failures of nodes that have acquired locks by releasing them and allowing other nodes to acquire them to make progress.

## Safety risks in lease[#](#Safety-risks-in-lease)

Leases introduce new **safety** risks.There are now two different nodes in the system that have different views about the state of the system, specifically the nodes that hold a lock. This is because these nodes have **different clocks**, so the time of expiry can differ between them. And because a **failure detector** cannot be perfect, as explained earlier in the course.

The fact that part of the system considers a node that can fail does not necessarily mean this node will fail. It could be a **network partition** that prevents some messages from being exchanged between some nodes, or that node might be busy processing something unrelated. As a result, that node might think it still holds the lock even though it has expired and is automatically released by the system.

The following illustration shows an example, where nodes A and B are trying to acquire a lease in order to perform some operations in a separate system.

Created with Fabric.js 3.6.6

1 / 12

A distributed system of two nodes A, and B, a locking system and a protected system

Created with Fabric.js 3.6.6

1 / 12

Node A tries to acquire a lease, sends acquire lease request to locking system

Created with Fabric.js 3.6.6

1 / 12

Node A successfully acquires the lease, Locking system acknowledges the Node A about the lease

Created with Fabric.js 3.6.6

1 / 12

Before performing the associated operation for which Node A acquired the lease, there occurs a significant delay, and the lease acquired by Node A expires

Created with Fabric.js 3.6.6

1 / 12

Lease for Node A was released by the locking system, in the meanwhile, Node B tries to acquire the lease and sends acquire lease request to locking system

Node A manages to acquire a lease first successfully. However, there is a significant delay between acquiring the lease and performing the associated operation. This delay could be due to various reasons, such as:

* Long garbage collection pause
* Scheduling delays
* Network delays

In the meanwhile, the lease has expired. It was released by the system and acquired by node B, which has also managed to perform the operation that’s protected by the lock. After a while, the operation from node A also reaches the system, and it’s executed even though the lease is not held anymore by that node violating the basic invariant that was supposed to be protected by the lease mechanism.

Ensuring that the lease is still held by simply performing another check before initiating the operation in node A would not solve the problem since the same delays can occur between this check and the initiation of the operation or even the delivery of the operation to the system.

> **Note**: One simple technique called fencing can solve the issues with distributed leases. We will discuss it in the next lesson.

Backlesson

Mark As CompletedComplete

Next

Benefits and Drawbacks

Preventing Safety Risks in Leases

Ask

[Recalling concurrency](#Recalling-concurrency)

[Solution](#Solution)

[Locks](#Locks)

[Complication of locking in distributed systems](#Complication-of-locking-in-distributed-systems)

[Using leases instead of locks](#Using-leases-instead-of-locks)

[Safety risks in lease](#Safety-risks-in-lease)

---


# Preventing Safety Risks in Leases

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Preventing Safety Risks in Leases

# Preventing Safety Risks in Leases

Explore how fencing prevents issues with distributed leases.

We'll cover the following...

* [Fencing](#Fencing)
  + [Purpose](#Purpose)
  + [How it works](#How-it-works)

## Fencing[#](#Fencing)

Fencing is a simple technique used to prevent [safety risks in leases](https://www.educative.io/collection/page/10370001/4891237377638400/4791441455316992#leases-risks).

### Purpose[#](#Purpose)

The main idea of fencing is to allow the system to block some nodes from performing some operations when these nodes are malfunctioning.

> **Note**: In our previous example, nodes are malfunctioning in the sense that they think they hold a lease, while they don’t.

### How it works[#](#How-it-works)

The locking subsystem can associate every lease with a monotonically increasing number. All the other systems can then use this number to keep track of the node that has performed an operation with the most recent lease. If a node with an older lease attempts to perform an operation, the system can detect that and reject it while also notifying the node that it’s not the lease owner anymore. The following illustration shows how fencing would work in practice:

Created with Fabric.js 3.6.6

1 / 12

A distributed system of two nodes A, and B, a locking system and a protected system, protected system has performed an operation with lease identifier equals 3

Created with Fabric.js 3.6.6

1 / 12

Node A tries to acquire a lease, sends acquire lease request to the Locking system

Created with Fabric.js 3.6.6

1 / 12

Node A successfully acquires the lease, Locking system assigns monotonically increasing identifier to the lease, and acknowledges the Node A about the lease and the assigned identifier

Created with Fabric.js 3.6.6

1 / 12

Before performing the associated operation for which Node A acquired the lease, there occurs a significant delay, and the lease acquired by Node A expires

Created with Fabric.js 3.6.6

1 / 12

Lease for Node A was released by the locking system, in the meanwhile, Node B tries to acquire the lease and sends acquire lease request to the Locking system

This means lock management cannot be performed by a single part of the system in a distributed system, but it has to be done collectively by all the parts of the system that are protected by this lock. For this to be possible, the various components of the system need to provide the following basic capabilities:

* The locking subsystem needs to provide a monotonically increasing identifier for every lock acquisition. Some examples of systems that provide this are **Zookeeper** via the `zxid` or the `znode` version number and `Hazelcast` as part of the fenced token provided via the FencedLock API.
* Any external systems protected by the locks need to provide conditional updates with linearizability guarantees.

Backlesson

Mark As CompletedComplete

Next

Leases in Distributed Systems

Backwards Compatibility

Ask

[Fencing](#Fencing)

[Purpose](#Purpose)

[How it works](#How-it-works)

---


# Backwards Compatibility

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Backwards Compatibility

# Backwards Compatibility

Let's inspect some software versioning issues in a distributed system that lead to the backwards and forward compatibility properties.

We'll cover the following...

* [Rolling deployments](#Rolling-deployments)
  + [Example](#Example)
* [Implications of rolling deployments](#Implications-of-rolling-deployments)
* [Examples](#Examples)

![](images/recall.png)As explained earlier, a defining characteristic of distributed systems is composed of **multiple nodes**. It is useful to allow the various nodes of such a system to operate independently for various reasons. A typical requirement for some applications in real life is to deploy new versions of the software with zero downtime.

## Rolling deployments[#](#Rolling-deployments)

The simplest way to deploy new versions of the software with zero downtime is to perform **rolling deployments** instead of deploying in lockstep the software to all the servers at the same time.

> **Note**: In some cases, this is not just a nice-to-have but an inherent characteristic of the system.

### Example[#](#Example)

Mobile applications (e.g., Android applications), where user consent is required to perform an upgrade, imply that users are deploying the new version of the software at their own pace. As a result, the various nodes of a distributed system can run different software versions at any time.

> This chapter will examine the implications of rolling deployment and some techniques that will help to manage this complication.

## Implications of rolling deployments[#](#Implications-of-rolling-deployments)

When the system performs rolling deployments, it manifests in many different ways. One of the most common ways is when two different applications communicate with each other. At the same time each one of them evolves independently by deploying new versions of its software.

For example, one of the applications might want to expose more data at some point. If this is not done carefully, the other application might not understand the new data making the whole interaction between the applications fail. Two very useful properties related to this are **backwards compatibility** and **forward compatibility**.

* *Backwards* compatibility is a property of a system that provides interoperability with an earlier version of itself or other systems.
* *Forward* compatibility is a property of a system that provides interoperability with a later version of itself or other systems.

> These two properties essentially reflect a single characteristic viewed from different perspectives, those of the sender and the recipient of data.

## Examples[#](#Examples)

Let’s consider an example of two systems, *S* and *R*, where the former sends some data to the latter. We can say that a change on system “S” is backwards compatible if older versions of “R” will be able to communicate successfully with a new version of S. We can also say that the system R is designed in a forward compatible way so that it will be able to understand new versions of S. Let’s discuss some examples in detail.

Let’s assume system S needs to change the data type of a specific attribute. Changing the data type of an existing attribute is not a backwards compatible change in general. System R would expect a different type for this attribute, and it would fail to understand the data. However, this change could be decomposed into the following sub-changes that preserve compatibility between the two systems.

The system R can deploy a new version of the software capable of reading that data either from the new attribute with the new data type or the old attribute with the old data type. The system S can then deploy a new version of the software that stops populating the old attribute and starts populating the new attribute.

> **Note**: Whether a change is backward compatible or not, it can differ depending on the used serialization protocol. [This](https://martin.kleppmann.com/2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html) article explains it nicely.

The previous example demonstrated that the seemingly trivial changes to the software are more complicated when they need to perform in a distributed system safely. As a consequence, maintaining backward compatibility imposes a tradeoff between **agility** and **safety**.

If S must change the data type of an attribute during a rolling deployment, what two-step sequence allows compatibility to be preserved between S and R, and what role does R play in that sequence? Provide your answer in the widget given below.

Want to know the correct answer?

Safe Type Change During Rolling Deploy

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Preventing Safety Risks in Leases

Maintaining Backwards Compatibility

Ask

[Rolling deployments](#Rolling-deployments)

[Example](#Example)

[Implications of rolling deployments](#Implications-of-rolling-deployments)

[Examples](#Examples)

---


# Maintaining Backwards Compatibility

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Maintaining Backwards Compatibility

# Maintaining Backwards Compatibility

Explore some techniques used for maintaining backwards compatibility.

We'll cover the following...

* [Semantic versioning](#Semantic-versioning)
* [Protocol negotiation](#Protocol-negotiation)
  + [Applying semantic versioning to live applications](#Applying-semantic-versioning-to-live-applications)
  + [Application unaware of other applications consuming its data](#Application-unaware-of-other-applications-consuming-its-data)
    - [The publish-subscribe model](#The-publish-subscribe-model)
* [Two-phase deployment](#Two-phase-deployment)

## Semantic versioning[#](#Semantic-versioning)

It’s usually beneficial to version the API of an application since that makes it easier to compare versions of different nodes and applications of the system and determine which versions are compatible with each other or not. Semantic versioning is a very useful convention, where each version number consists of three digits `X.Y.Z`.

## Protocol negotiation[#](#Protocol-negotiation)

**Protocol negotiation** is another technique for maintaining backward compatibility through the use of explicitly versioned software.

Let’s consider an example mentioned previously, where the client of an application is a mobile application. Every version of the application needs to be backward compatible with all the client application versions running on user phones currently. This means that the staged approach described previously cannot be used when making backward incompatible changes since end users cannot be forced to upgrade to a newer version. Instead, the application can identify the version of the client and adjust its behavior accordingly.

For example, consider a feature introduced on version `4.1.2` that is backward incompatible with versions `< 4.x.x.` If the application receives a request from a `3.0.1` client, it can disable that feature to maintain compatibility. If it receives a request from a `4.0.3` client, it can enable the feature.

**Patch version**: This version is incremented when a backwards compatible bug fix is made to the software.

**Minor version**: This version is incremented when new functionality is added in a backward compatible way.

**Major version**: This version is incremented when a backwards incompatible change is made.

As a result, the clients of the software can easily understand the compatibility characteristics of new software and the associated implications.

When providing software as a binary artifact, the version is usually embedded in the artifact. The consumers of the artifact then need to take the necessary actions if it includes a *backwards incompatible* change, e.g., adjusting their application’s code.

### Applying semantic versioning to live applications[#](#Applying-semantic-versioning-to-live-applications)

**Semantic versioning** is implemented slightly differently in live applications. The major version needs to be embedded in the address of the application’s endpoint, while the minor and patch versions can be included in the application’s responses. For an example, see [this](https://developers.facebook.com/docs/graph-api/guides/versioning). This is needed so that clients can automatically upgrade to newer versions of the software if desired, but only if these are backward compatible.

### Application unaware of other applications consuming its data[#](#Application-unaware-of-other-applications-consuming-its-data)

In some cases, an application might not be aware of the other applications consuming its data. An example of this is the **publish-subscribe** model.

#### The publish-subscribe model[#](#The-publish-subscribe-model)

In the publish-subscribe model, the publisher does not necessarily need to know all the subscribers. However, it’s still very important to ensure that the consumers can deserialize and process any produced data successfully as its format changes.

One pattern used here is defining a **schema** for the data used by both producers and consumers. This schema can be embedded in the message itself. Otherwise, to avoid duplication of the schema data, a reference to the schema can be put inside the message, and the schema can be stored in a separate store. For example, this pattern is commonly used in **Kafka** via the [Schema Registry](https://docs.confluent.io/current/schema-registry).

However, it’s important to remember that producers and consumers are evolving independently, even in this case. Hence, consumers are not necessarily using the latest version of the schema used by the producer. So, producers need to preserve compatibility either by ensuring consumers can read data of the new schema using an older schema or by ensuring all consumers have started using the new schema before producing messages with it.

Note that similar considerations need to be made for the compatibility of the new schema with old data. For example, if consumers cannot read old data with the new schema, the producers might have to make sure everyone has consumed all the messages with the previous schema first. Interestingly, the Schema Registry defines different categories of compatibility along these dimensions, which determine what changes are allowed in each category and the upgrade process, e.g., if producers or consumers need to upgrade first. It can also check two different versions of a schema and confirm that they are compatible under one of these categories
to prevent errors later on. See [this](https://docs.confluent.io/current/schema-registry/avro.html#schema-evolution-and-compatibility), for example.

## Two-phase deployment[#](#Two-phase-deployment)

Note that it’s not only changes in data that can break backward compatibility. Slight changes in the behavior or semantics of an API can also have serious consequences in a distributed system. For example, let’s consider a failure detector that uses **heartbeats** to identify failed nodes. Every node sends a heartbeat every one second, and the failure detector considers a node failed if it hasn’t received a single heartbeat in the last three seconds. This causes a lot of network traffic that affects the performance of the application, so we will increase the interval of a heartbeat from one to five seconds and the threshold of the failure detector from three to fifteen seconds.

Suppose we perform a **rolling deployment** of this change. In that case all the servers with the old version of the software will start thinking all the servers with the new version have failed. This is due to the fact that their failure detectors will still have the old deadline of three seconds, while the new servers will send a heartbeat every five seconds.

One way to make this change backward compatible would be to perform an initial change that increases the failure detector threshold from three to fifteen seconds. And then, follow this with a subsequent change that increases the heartbeat interval to five seconds only after the first change has been deployed to all the nodes. This technique of splitting a change into two parts to make it *backward compatible* is commonly used and it’s also known as *two-phase deployment*.

Backlesson

Mark As CompletedComplete

Next

Backwards Compatibility

Failure Handling Techniques

Ask

[Semantic versioning](#Semantic-versioning)

[Protocol negotiation](#Protocol-negotiation)

[Applying semantic versioning to live applications](#Applying-semantic-versioning-to-live-applications)

[Application unaware of other applications consuming its data](#Application-unaware-of-other-applications-consuming-its-data)

[The publish-subscribe model](#The-publish-subscribe-model)

[Two-phase deployment](#Two-phase-deployment)

---


# Failure Handling Techniques

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Failure Handling Techniques

# Failure Handling Techniques

Let’s look into some commonly used hardware failure handling techniques in distributed systems.

We'll cover the following...

* [Hardware failures](#Hardware-failures)
  + [Silent hardware failures](#Silent-hardware-failures)
    - [Example](#Example)
* [Techniques to handle failures](#Techniques-to-handle-failures)
  + [Retransmitting data](#Retransmitting-data)
  + [Storing data to multiple disks](#Storing-data-to-multiple-disks)
  + [Error correcting codes (ECC)](#Error-correcting-codes-ECC)

Failure is the norm in a distributed system, so building a system that can cope with failures is crucial.This chapter will cover principles on dealing with failures and basic patterns for building systems that are resilient to failures.

In distributed systems, dealing with a failure consists of three main parts:
main parts:

* **identifying** the failure
* **recovering** from the failure
* **containing** a failure to reduce its impact, in some cases

## Hardware failures[#](#Hardware-failures)

Hardware failures can be the most damaging ones since they can lead to **data loss** or **corruption**. Also,the probability of a hardware failure is significantly higher in a distributed system due to the bigger number of hardware components involved.

### Silent hardware failures[#](#Silent-hardware-failures)

Silent hardware failures are the ones with the biggest impact since they can potentially affect the behavior of a system without anyone noticing.

#### Example[#](#Example)

A node in the network corrupts some part of a message and the recipient receives data that is different from what the sender originally sent without being able to detect that. Similarly, data written to a disk can be corrupted during the write operation or even a long time after that was completed.

## Techniques to handle failures[#](#Techniques-to-handle-failures)

Following are some techniques that are commonly used to handle the hardware and silent hardware of failures.

### Retransmitting data[#](#Retransmitting-data)

One way to detect these failures when sending a message to another node is to introduce redundancy in the message using a checksum derived from the actual payload. If the message is corrupted, the checksum will not be valid. As a result, the recipient can ask the sender to send the message again.

### Storing data to multiple disks[#](#Storing-data-to-multiple-disks)

When writing data to disk, the retransmitting data technique might not be useful since the corruption will be detected a long time after a write operation has been performed by the client, which means it might not be feasible to rewrite the data. Instead, the application can make sure that data is written to multiple disks so that corrupted data can be discarded later on and the right data can be read from another disk with a valid *checksum*.

### Error correcting codes (ECC)[#](#Error-correcting-codes-ECC)

Error correcting codes (ECC) is used in cases where retransmitting or storing the data multiple times is impossible or costly.

These are similar to *checksums* and are stored alongside the actual payload, but they have the additional property that they can be used to correct **corruption errors** calculating the original payload again.

The downside of error correcting codes is that they are larger than checksums, thus having a higher overhead in terms of data stored or transmitted across the network.

> **Note**: As a distributed system consists of many different parts, these kinds of failures can happen on any of them. So it raises the question of where and how we can use these failure handling techniques.

Backlesson

Mark As CompletedComplete

Next

Maintaining Backwards Compatibility

Applying Failure Handling Techniques

Ask

[Hardware failures](#Hardware-failures)

[Silent hardware failures](#Silent-hardware-failures)

[Example](#Example)

[Techniques to handle failures](#Techniques-to-handle-failures)

[Retransmitting data](#Retransmitting-data)

[Storing data to multiple disks](#Storing-data-to-multiple-disks)

[Error correcting codes (ECC)](#Error-correcting-codes-ECC)

---


# Applying Failure Handling Techniques

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Applying Failure Handling Techniques

# Applying Failure Handling Techniques

Learn where and how to apply failure handling techniques in distributed systems.

We'll cover the following...

* [The end-to-end argument principle](#The-end-to-end-argument-principle)
  + [Implementing error recovery functionality at the application level](#Implementing-error-recovery-functionality-at-the-application-level)
  + [Providing exactly-once guarantees at the application level](#Providing-exactly-once-guarantees-at-the-application-level)
    - [Using TCP](#Using-TCP)
      * [Problems](#Problems)
    - [Solution](#Solution)
  + [Achieving mutual exclusion](#Achieving-mutual-exclusion)

## The end-to-end argument principle[#](#The-end-to-end-argument-principle)

The **end-to-end argument** is a design principle, which suggests that some functions such as the fault tolerance techniques described previously can be implemented completely and correctly only with the knowledge and help of the application standing at the endpoints of the communication system.

A canonical example to illustrate this point is the **careful file transfer** application, where a file needs to be moved from computer A’s storage to computer B’s storage without damage.

As shown in the following illustration, hardware failures can happen in many places during this process, such as:

* The disks of computers
* The software of the file system
* The hardware processors, their local memory
* The communication system

Careful file transfer and possible failures

### Implementing error recovery functionality at the application level[#](#Implementing-error-recovery-functionality-at-the-application-level)

Even if the various subsystems embed error recovery functionality, this can only cover lower levels of the system, and it cannot protect from errors that happen at a higher level of the system.

For example, error detection and recovery implemented at the disk level or in the operating system won’t help if the application has a defect that leads to writing the wrong data in the first place. It means that we can only achieve complete correctness by implementing this function at the **application level**.

This function can be implemented redundantly at lower levels, but this is mostly done as a *performance* optimization.

> Note: An example of this was already presented in the chapter about [networking](https://www.educative.io/courses/distributed-systems-practitioners/introduction-BnQAzgxvLLQ), where we saw that the link layer provides reliable data transfer for wireless links (e.g., Wi-fi) even though this can also be provided at the transport layer (e.g., TCP).

It’s also important to note that this redundant implementation at lower levels is not always beneficial, but it depends on the use case.The literature by Saltzer et al. and Moors et al. covers this trade-off extensively.

### Providing exactly-once guarantees at the application level[#](#Providing-exactly-once-guarantees-at-the-application-level)

The end-to-end argument principle manifests in many different ways when dealing with a distributed system. The most relevant problem we have encountered repeatedly throughout this course is providing **exactly-once** guarantees.

Let’s consider an extremely simplified version of the problem, where application A wants to trigger an operation on application B exactly once, and each application consists of a single server.

#### Using TCP[#](#Using-TCP)

The communication subsystem, specifically **TCP**, can provide reliable data delivery via retries, acknowledgments, and deduplication, which are the techniques already described in this course.

However, TCP is still not sufficient to provide exactly-once guarantees at the application level.

##### Problems[#](#Problems)

The application can encounter the following problems when using TCP to achieve exactly-once guarantees:

* The TCP layer on the side of application B might receive a packet and acknowledge it back to the sender side while buffering it locally to be delivered to the application. However, the application crashes before receiving this packet from the TCP layer and processing it. In this case, the application on the sender side will think the packet has been successfully processed while it wasn’t.
* The TCP layer on the side of application B might receive a packet and deliver it successfully to the application, which processes it successfully. However, a failure happens at this point, and the applications on both sides are forced to establish a new TCP connection. Application A had not received an application acknowledgment for the last message, so it attempts to resend it on the new connection.
* Unfortunately, TCP provides reliable transfer only in the scope of a single connection, so it will not be able to detect if this packet has been received and processed in a previous connection. As a result, a packet will be processed by the application more than once.

#### Solution[#](#Solution)

The main takeaway from the above problems is that any functionality needed for exactly-once semantics (e.g., retries, acknowledgments, and deduplication), needs to be implemented at the **application level** in order to be correct and safe against all kinds of failures.

### Achieving mutual exclusion[#](#Achieving-mutual-exclusion)

The end-to-end principle manifests in a slightly different shade to achieve **mutual exclusion** in a distributed system.

The [fencing](https://www.educative.io/collection/page/10370001/4891237377638400/5849777368989696#fencing) technique discussed previously extends mutual exclusion function to all the involved ends of the application.

> **Note**: The goal of this chapter is not to explore all the problems where the end-to-end argument is applicable. Instead, the goal is to raise awareness and make the reader appreciate its value on system design to consider if and when need be

Backlesson

Mark As CompletedComplete

Next

Failure Handling Techniques

Retries

Ask

[The end-to-end argument principle](#The-end-to-end-argument-principle)

[Implementing error recovery functionality at the application level](#Implementing-error-recovery-functionality-at-the-application-level)

[Providing exactly-once guarantees at the application level](#Providing-exactly-once-guarantees-at-the-application-level)

[Using TCP](#Using-TCP)

[Problems](#Problems)

[Solution](#Solution)

[Achieving mutual exclusion](#Achieving-mutual-exclusion)

---


# Retries

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Retries

# Retries

Learn how stateless and stateful systems recover from failures.

We'll cover the following...

* [Using retries in stateless systems](#Using-retries-in-stateless-systems)
* [Using retries in stateful systems](#Using-retries-in-stateful-systems)

The stateless and stateful systems use the technique of **retries** to recover from the failures.

## Using retries in stateless systems[#](#Using-retries-in-stateless-systems)

In the case of a **stateless system**, the application of *retries* is pretty simple since all the application nodes are identical from the client’s perspective, so it could retry a request on any node.

> **Note**: In some cases, retries are done in a fully transparent way to the client.

For example, suppose the application is fronted by a load balancer that receives all the requests under a single domain. In that case it’s responsible for forwarding the requests to the various nodes of the application. In this way, the client would only have to retry the request to the same endpoint, and the load balancer would take care of balancing the requests across all the available nodes.

## Using retries in stateful systems[#](#Using-retries-in-stateful-systems)

In stateful systems, retries get slightly more complicated since nodes are not identical, and retries need to be directed to the right one.

For example, when using a system with leader-follower replication, a failure of the leader node must be followed by failover to a follower node that is now the new leader , and new requests should be going there. There are different mechanisms to achieve this, depending on the technology used. The same applies to consensus-based replication, where a new leader election might need to happen, and write operations must be directed to the current leader.

Backlesson

Mark As CompletedComplete

Next

Applying Failure Handling Techniques

Containing Impact of Failure

Ask

[Using retries in stateless systems](#Using-retries-in-stateless-systems)

[Using retries in stateful systems](#Using-retries-in-stateful-systems)

---


# Containing Impact of Failure

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Containing Impact of Failure

# Containing Impact of Failure

Let's look at some techniques to contain the impact of failure in distributed systems

We'll cover the following...

* [Fault isolation](#Fault-isolation)
  + [Balancing the trade-off between availability and latency](#Balancing-the-trade-off-between-availability-and-latency)
* [Graceful degradation](#Graceful-degradation)

Most of the techniques described in this chapter are used to identify failure and recover from it. It’s also useful to contain the impact of a failure, so we will now discuss some techniques for this purpose. This can be done via technical means, such as **fault isolation**.

## Fault isolation[#](#Fault-isolation)

One common way to contain the impact of the failure is to deploy an application redundantly in multiple facilities that are physically isolated and have independent failure modes. So, when an incident affects one of these facilities, the other facilities are not impacted and continue functioning as normal.

> **Note**: Fault isolation introduces a trade-off between *availability* and *latency* since physical isolation increases network distance and latency.

### Balancing the trade-off between availability and latency[#](#Balancing-the-trade-off-between-availability-and-latency)

Most cloud providers provide multiple physically isolated datacenters and are all located close to each other in a single region to strike a good balance in this trade-off. These are commonly known as **availability zones**.

## Graceful degradation[#](#Graceful-degradation)

Graceful degradation is another technique to contain failure, where an application reduces the quality of its service to avoid failing completely.

For example, suppose a service that provides the capabilities of a search engine by calling **downstream services**. And one of these services which shows the advertisements for each query is having some issues. The top-level service can just render the results of a search term without any advertisements instead of returning an error message or completely empty response.

Techniques to contain failure are broadly categorized into two main groups:

* Those performed at the client-side
* Those performed at the server-side

Backlesson

Mark As CompletedComplete

Next

Retries

Backpressure

Ask

[Fault isolation](#Fault-isolation)

[Balancing the trade-off between availability and latency](#Balancing-the-trade-off-between-availability-and-latency)

[Graceful degradation](#Graceful-degradation)

---


# Backpressure

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Backpressure

# Backpressure

Learn the concept of backpressure in distributed systems and how applications exert backpressure.

We'll cover the following...

* [Implicit backpressure](#Implicit-backpressure)
* [Explicit backpressure](#Explicit-backpressure)
* [Techniques used by applications to exert backpressure](#Techniques-used-by-applications-to-exert-backpressure)
  + [Load shedding](#Load-shedding)
  + [Selective client throttling](#Selective-client-throttling)

**Backpressure** is a very useful concept in the field of distributed systems. It is essentially a resistance to the desired flow of data through a system. This resistance can manifest in different ways, such as increased latency of requests or failed requests.

Backpressure can also be **implicit** or **explicit**.

## Implicit backpressure[#](#Implicit-backpressure)

Implicit backpressure arises in a system that is overloaded by a traffic surge and becomes extremely slow.

## Explicit backpressure[#](#Explicit-backpressure)

A system that rejects some requests during a traffic surge to maintain a good quality service essentially exerts explicit backpressure to its clients.

> **Note**: Most of the techniques used to contain failure reflect how applications exert backpressure and how their clients handle backpressure.

Let’s learn how applications can exert backpressure.

## Techniques used by applications to exert backpressure[#](#Techniques-used-by-applications-to-exert-backpressure)

It is useful for a system to know its limits and exert backpressure when they are reached instead of relying on implicit backpressure. Otherwise, there can be many unexpected failure modes, which are harder to deal with when they happen.

### Load shedding[#](#Load-shedding)

The main technique to exert backpressure is **load shedding**. An application is aware of the maximum load it can handle and rejects any requests that cross this threshold to keep operating at the desired levels.

### Selective client throttling[#](#Selective-client-throttling)

A more specialized form of load shedding is **selective client throttling**, where an application assigns different quotas to each of its clients.

This technique can also be used to prioritize traffic from some more important clients.

Let’s consider a service responsible for serving the prices of products, which is used both by systems responsible for displaying product pages and systems responsible for receiving purchases and charging the customer. In case of a failure, that service could throttle the former type of system more than the latter since purchases are considered more important for a business. They also tend to constitute a smaller percentage of the overall traffic.

> **Note**: In the case of asynchronous systems that use message queues, load shedding can be performed by imposing an upper bound on the size of the queue. There is a common misconception that message queues can help absorb any form of backpressure without any consequences. However, this comes at the cost of an increased backlog of messages, leading to increased processing latency or even failure of the messaging system in extreme cases.

Backlesson

Mark As CompletedComplete

Next

Containing Impact of Failure

Reacting to Backpressure

Ask

[Implicit backpressure](#Implicit-backpressure)

[Explicit backpressure](#Explicit-backpressure)

[Techniques used by applications to exert backpressure](#Techniques-used-by-applications-to-exert-backpressure)

[Load shedding](#Load-shedding)

[Selective client throttling](#Selective-client-throttling)

---


# Reacting to Backpressure

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Reacting to Backpressure

# Reacting to Backpressure

Learn how applications react to backpressure.

We'll cover the following...

* [Retries](#Retries)
  + [Issue with retries](#Issue-with-retries)
    - [Overloading a service](#Overloading-a-service)
  + [Mitigating service overloading issue](#Mitigating-service-overloading-issue)
    - [Retry failed requests at the highest level possible](#Retry-failed-requests-at-the-highest-level-possible)
    - [Use exponential backoff when retrying a request](#Use-exponential-backoff-when-retrying-a-request)
    - [Use circuit breaker](#Use-circuit-breaker)
      * [Benefits](#Benefits)
    - [Embed timeout hints](#Embed-timeout-hints)

Clients of an application should be able to react properly to the **backpressure** emitted by an application.

## Retries[#](#Retries)

The most typical way to react to failures in a distributed system is **retries**. Retries are performed because we assume that a failure is temporary, so retrying a request is expected to have a better outcome.

### Issue with retries[#](#Issue-with-retries)

Retries can have adverse effects, the one is described below:

#### Overloading a service[#](#Overloading-a-service)

Think about the whole architecture of the systems and the various applications involved to determine where retries will be performed. Performing retries at multiple levels can significantly amplify the traffic coming from customers, which can overload services and cause issues.

For example, let’s assume we have four services A, B, C, and D that call each other in order, as shown in the following illustration:

Load amplification due to retries

If each service performs three retries for every failed request, then a temporary issue at service D will cause every request to be retried 27 times, thus creating a lot of additional load to service D during a period it’s already experiencing issues.

### Mitigating service overloading issue[#](#Mitigating-service-overloading-issue)

Following are some approaches that help overcome the service overloading issue:

#### Retry failed requests at the highest level possible[#](#Retry-failed-requests-at-the-highest-level-possible)

Retrying failed requests at the highest level is a conventional approach, which contains additional context around the business function of the request and whether it’s worth retrying.

#### Use exponential backoff when retrying a request[#](#Use-exponential-backoff-when-retrying-a-request)

In this approach, the system waits a bit more every time before performing the next retry. It gives the downstream system a better opportunity to recover from any temporary issues.

> **Note**: Ideally, exponential backoff is also combined with some **jitter**, which is a small incremental delay in data transfer. So retries from various servers of service are distributed evenly, and they do not produce sudden spikes of traffic that can also cause overload issues…

#### Use circuit breaker[#](#Use-circuit-breaker)

Clients of an application can also perform some form of load shedding to help downstream applications recover using a circuit breaker.

A circuit breaker essentially monitors the percentage of failed requests. When a specific threshold is crossed, this is interpreted as a permanent failure of the downstream application. As a result, the circuit breaker rejects all the requests locally without sending them to the downstream application.

The circuit breaker allows sending just a few requests periodically, and if a good percentage of them is successful, it starts sending load again.

##### Benefits[#](#Benefits)

Circuit breakers are beneficial in two ways:

* It gives the downstream service a chance to recover from overload situations or other kinds of permanent failures.
* It improves the customer experience by reducing request latency when the response from downstream is not necessary.

> **Note**: An example of this technique was described [previously](https://www.educative.io/collection/page/10370001/4891237377638400/4582641623367680#graceful-degradation) when explaining the concept of graceful degradation.

#### Embed timeout hints[#](#Embed-timeout-hints)

Clients can embed timeout hints in their requests to help downstream applications. These hints inform downstream applications about when a response to a request is not useful anymore. In this way, downstream applications can discard requests waiting for a long time in message queues or in memory buffers due to resource exhaustion, thus speeding up the processing of accumulated backlogs.

Put your knowledge to the test by engaging with the AI widget below. You’ll answer six questions covering various techniques for dealing with failure in distributed systems. To begin, say hello to Edward in the widget below, and it will lead the way.

Want to know the correct answer?

Powered by AI

14 Prompts Remaining

Prompt AI WidgetOur tool is designed to help you to understand concepts and ask any follow up questions. Ask a question to get started.

Backlesson

Mark As CompletedComplete

Next

Backpressure

Recording Program's Execution

Ask

[Retries](#Retries)

[Issue with retries](#Issue-with-retries)

[Overloading a service](#Overloading-a-service)

[Mitigating service overloading issue](#Mitigating-service-overloading-issue)

[Retry failed requests at the highest level possible](#Retry-failed-requests-at-the-highest-level-possible)

[Use exponential backoff when retrying a request](#Use-exponential-backoff-when-retrying-a-request)

[Use circuit breaker](#Use-circuit-breaker)

[Benefits](#Benefits)

[Embed timeout hints](#Embed-timeout-hints)

---


# Recording Program's Execution

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Recording Program's Execution

# Recording Program's Execution

Learn about tracing for a single and multiple programs in distributed systems.

We'll cover the following...

* [Achieving tracing](#Achieving-tracing)
* [Collating traces from multiple programs](#Collating-traces-from-multiple-programs)
  + [Problem](#Problem)
  + [Solution](#Solution)
    - [Correlation identifier](#Correlation-identifier)

Tracing refers to the particular use of logging to record information about a program’s execution, used for troubleshooting or diagnostic purposes.

## Achieving tracing[#](#Achieving-tracing)

We can achieve tracing in its simplest form by associating every request to the program with a unique identifier and recording logs for the most important operations of the program alongside the request identifier.

In this way, when we try to diagnose a specific customer issue, the logs can easily be filtered down to only include a chronologically ordered list of operation logs of the associated request identifier. These logs can provide a summary of the various operations the program executed and the steps it went through.

## Collating traces from multiple programs[#](#Collating-traces-from-multiple-programs)

A distributed system serves every client request through multiple, different applications. As a result, one needs to collate traces from multiple programs to fully understand how a request was served and where something might have gone wrong.

### Problem[#](#Problem)

Collating traces from multiple programs is not that simple because every application might be using its own request identifiers, and the applications are most likely processing multiple requests concurrently. This makes it harder to determine which requests correspond to a specific client request.

### Solution[#](#Solution)

We can solve the above problem through the use of **correlation identifiers**.

#### Correlation identifier[#](#Correlation-identifier)

A correlation identifier is a unique identifier that corresponds to a top-level client request. This identifier might be automatically generated, or some external system or manual process might provide it. It is then propagated through the various applications that are involved in serving this request. These applications can then include that correlation identifier in their logs along with their request identifiers. In this way, it is easier to identify all the operations across all applications corresponding to a specific client request by filtering their logs based on this correlation identifier.

> **Note**: By incorporating timing data in this logging, one can use this technique to also retrieve performance data, such as the time spent on every operation.

The following illustration shows distributed tracing via correlation IDs and an example of a trace that shows latency contribution of every application:

Distributed tracing via correlation IDs

In the above illustration, the colorful horizontal lines are the latencies of each request as indicated by their labels, e.g., the green one corresponds to the request of service A that took 870 milliseconds.

There are several libraries and tools for implementing distributed tracing, such as [OpenTracing](https://opentracing.io) or [Zipkin](https://zipkin.io).

Suppose service A generates a correlation identifier for a client request and passes it to services B and C, each of which also generates its own local request IDs. If you need to diagnose a user-reported error that spans A, B, and C, which identifier should you filter logs on first, and why? Provide your answer in the widget given below.

Want to know the correct answer?

Using Correlation IDs for Multi-Service Error Diagnosis

Enter your answer here

﻿

Evaluate

Beta

800 characters left

Save

Reset

Backlesson

Mark As CompletedComplete

Next

Reacting to Backpressure

Recap of the Course

Ask

[Achieving tracing](#Achieving-tracing)

[Collating traces from multiple programs](#Collating-traces-from-multiple-programs)

[Problem](#Problem)

[Solution](#Solution)

[Correlation identifier](#Correlation-identifier)

---


# Recap of the Course

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Recap of the Course

# Recap of the Course

Let's look at what we have learned so far in this course.

We'll cover the following...

* [Recap](#Recap)

This course has helped you understand:

* How distributed systems can be useful
* What challenges you may face when building distributed systems
* How to overcome these challenges

Building or using a distributed system is a serious undertaking that one should take only when necessary.

We will recap some key learnings from this course and will also highlight topics that we did not cover. In this way, those willing to dive deeper into some areas will have some starting points to do so.

## Recap[#](#Recap)

First of all, we introduced some of the basic areas where distributed systems can help: **performance**, **scalability**, and **availability**.

![](images/image_1764835178.9693692.svg)![](images/6723281230102528.svg)

We analyzed basic mechanisms that can help in these areas throughout the course, such as **partitioning** and **replication**. It also became evident that these mechanisms introduce tension between the characteristics mentioned above and other properties, such as **consistency**. This tension is formalized by basic theorems, such as the **CAP theorem** and the **FLP result**.

This tension manifests in various ways. For example, the decision on whether replication operates **synchronously** or **asynchronously** can be a trade-off between *performance* and *availability* or *durability*.

We explained the difference between **liveness** and **safety** properties and provided an overview of the basic **consistency models** that help formalise the behaviour of a distributed system and facilitate reasoning about its interaction with other systems.

![](images/image_1764835179.1763806.svg)![](images/5868859964915712.svg)

> **Note**: However, there are many more models we omitted in this course in the interest of time and simplicity, such as **read-your-writes**, **monotonic reads** and **monotonic writes consistency models** by Viotti et al..

We also introduced the concept of **failure detection** and gave an example of a simplistic failure detector that makes use of **heartbeats** and **timeouts**.

![](images/image_1764835179.349019.svg)![](images/6524746199072768.svg)

In reality, failure detectors deal with many more practical problems and need to be quite more complex. This mean they:

* Avoid using timeouts in order to be applicable to **quiescent algorithms**.
  See the paper by Kawazoe et al. who achieved this.
* Operate using a **gossip protocol** to improve scalability and fault-tolerance. See the paper by Renesse et al. who did this.

Output a suspicion level on a continuous scale instead of a binary value. See the paper by Hayashibara et al.

> **Note**: Gossip protocols were also not covered in this course and they can be considered a whole topic on their own. For the details about gossip protocols, you are advised to read this paper.

After that, we explored several **partitioning techniques**.

![](images/image_1764835179.524571.svg)![](images/6263523737993216.svg)

Next, we introduced the **problem of consensus** and explained the two major algorithms that solve it, **Paxos** and **Raft**.

![](images/image_1764835179.717215.svg)![](images/5053696110100480.svg)

The topic of consensus is very old, but still, very useful research is conducted in this area. For example, the original Paxos algorithm operated under the assumption that all quorums need to be majority quorums to maintain the algorithm’s safety properties. However, Howard et al. actually demonstrated that this is not necessary.

The algorithm just needs to ensure quorums from the first phase overlap with quorums from the second phase. This allows one to size the quorums of each phase accordingly depending on the performance requirements and fault tolerance during the steady state or during recovery.

As described by Castro et al. and Lamport, solving consensus under the presence of byzantine failures is a much more challenging task and is subject to different constraints.

The next two chapters introduced the notions of **time** and **order** and their relationship.

![](images/image_1764835179.943875.svg)![](images/5723875190112256.svg)

First, we explained the difference between **total and partial order**, which is important in distributed systems. While consensus can be considered the problem of establishing total order amongst all events of a system, some systems do not need such strict requirements and can also operate successfully under a partial order. **Vector clocks** is one mechanism outlined in the course that allows a system to keep track of such a partial order that preserves **causality relationships** between events.

Then, we covered the topics of **networking** and **security**.

![](images/image_1764835180.1022243.svg)![](images/5449757056172032.svg)

Networking is core to how the various nodes of a distributed system communicate. So, it is important to understand the various networking protocols and technologies available when designing a distributed system. The breadth of knowledge can help you see the big picture and make the right design decision, but depth of knowledge is still valuable to get the small details right and troubleshoot issues efficiently when things go wrong. The analysis of [this](https://www.usenix.org/node/195676) article shows a good example of how such knowledge can be useful in mitigating and preventing issues.

We gave you a quick but complete overview of the basic protocols and technologies in this course, and we would urge you to study further the areas that you didn’t feel familiar with.

Networks themselves can be designed following the same principles outlined in this course, so that distributed systems can run on top of them at scale.

Security is also a crucial aspect of distributed systems that is frequently neglected, unfortunately. That is why we dedicated two chapters to cover the basic concepts and techniques you can use to build secure distributed systems. However, we only discussed the main idea of the basic cryptographic primitives and did not go into much detail since it’s a vast field.

Lastly, we will advise you to always stick with existing standards and cryptanalysis libraries and battle-tested solutions instead of rolling out your own.

We believe it is a lot easier for someone to understand **theory** when it is put into context by demonstrating how it is used in **practical** systems. This is the reason we included several chapters of **case studies** about real systems and how they use algorithms and techniques presented in the course.

![](images/image_1764835180.294723.svg)![](images/4658213541773312.svg)

The last chapters on **practices and patterns** were written under the same spirit and subject to similar time constraints.We will advise our readers to study the papers by Nishtala et al., Bronson et al., Sigelman et al, Verbitski et al, and Verbitski et al. for a deeper understanding of how theory can be put into practice.

Backlesson

Mark As CompletedComplete

Next

Recording Program's Execution

Some More Things to Discover

Ask

[Recap](#Recap)

---


# Some More Things to Discover

[Distributed Systems for Practitioners](/courses/distributed-systems-practitioners)/

...

/

Some More Things to Discover

# Some More Things to Discover

Besides the things we highlighted in the previous lesson, look at some more things to discover.

We'll cover the following...

* [Next steps](#Next-steps)

At the risk of being unfair to other systems and material out there, we would like to mention [CockroachDB](https://github.com/cockroachdb/cockroach) as one system that has a lot of public material demonstrating how they have used theoretical concepts in practice. Some concrete examples are implementation of [pipelined consensus](https://www.cockroachlabs.com/blog/transaction-pipelining) and a [parallelized version of two-phase commit](https://www.cockroachlabs.com/blog/parallel-commits) that required a single round-trip instead of two before acknowledging a commit. Some resources that contain a lot of practical information to build and operate distributed systems are the [Amazon Builders Library](https://aws.amazon.com/builders-library) and papers by Hamilton and Brewer, with learnings of practitioners that have built large-scale systems.

The chapters on practices and patterns discussed about how systems can deal with failure. Unfortunately, two types of failure are frequently neglected when building or operating distributed systems, even though they are quite common:

* Gray failures
* Partial failures

**Gray failures** do not manifest cleanly as a binary indication . They are more subtle and can be observed differently by different parts of a system.
**Partial failures** are those in which only parts of a system fail in a way that has serious consequences equivalent to a full failure of the system, sometimes due to a defect in the design.

These types of failures can be very common in distributed systems due to many moving parts. They can have serious consequences, so it is essential for people who build and run distributed systems to internalize these concepts and look out for them in the systems they build and operate.

> **Note**: Another important topic that we did not cover at all is the **formal verification** of systems.

We can use many formal verification techniques and tools to prove **safety** and **liveness** properties of systems with TLA+. It is one of the most commonly used across the software industry, Amazon is another one.

It is important to note that users of these formal verification methods have acknowledged publicly that these methods have helped them discover bugs in their designs but have also helped them significantly reason about the behavior of their systems in a better way.

## Next steps[#](#Next-steps)

Now that you’ve learned what distributed systems are, we recommend applying that knowledge by taking the following two courses:

* [**Grokking Modern System Design Interview for Engineers and Managers:**](https://www.educative.io/courses/grokking-modern-system-design-interview-for-engineers-managers) This course teaches you to design large-scale distributed systems by employing building blocks such as load balancers, rate limiters, messaging queues, CDNs, etc. You will learn how to design 13 real-world systems and evaluate your understanding simultaneously.
* [**Grokking the Product Architecture Design Interview:**](https://www.educative.io/courses/grokking-the-api-design-interview) Product architecture design is essential to ensure that the services you build can effectively communicate with other systems. Mastering API design principles is critical for creating reliable and compatible APIs that support modern software architectures.

Backlesson

Mark As CompletedComplete

Recap of the Course

Ask

[Next steps](#Next-steps)

---

